{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lz4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmHSKZHWAGD5",
        "outputId": "34ef1c67-a271-4eff-bc33-e904fa1fa75e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.7/dist-packages (4.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ray"
      ],
      "metadata": {
        "id": "DmeqIoXewIuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f6680b-eaaf-45d2-cf65-89e95c64a37c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (1.13.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.43.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.2.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.0)\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray) (20.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray) (2.5.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray) (0.3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "ray.init(num_gpus=2, num_cpus=80,ignore_reinit_error=True)"
      ],
      "metadata": {
        "id": "gpU0Ekk4uhnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c88f44-b113-44d1-8ea3-96660dba4dec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.7.13', ray_version='1.13.0', ray_commit='e4ce38d001dbbe09cd21c497fedd03d692b2be3e', address_info={'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-07-04_18-50-38_945916_1512/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-04_18-50-38_945916_1512/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-07-04_18-50-38_945916_1512', 'metrics_export_port': 63270, 'gcs_address': '172.28.0.2:45175', 'address': '172.28.0.2:45175', 'node_id': '9617753d37bc8a9abcc7d09ed77ace65b766b3367e3f1d715852c60a'})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray.rllib.agents.dqn as dqn"
      ],
      "metadata": {
        "id": "qSARSd4Xuil9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install \"ray[tune]\""
      ],
      "metadata": {
        "id": "bpXL8Y6F4ATY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune"
      ],
      "metadata": {
        "id": "H51SznLXxUEA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execute this, only when you want to save Trained Checkpoints**"
      ],
      "metadata": {
        "id": "3lcYMGAW5o6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "metadata": {
        "id": "t4VUC-sxWE3V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopper(trial_id, result):\n",
        "    return result[\"training_iteration\"] >= 100"
      ],
      "metadata": {
        "id": "12C9RspjWHWb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = tune.run(\n",
        "    \"DQN\",\n",
        "    checkpoint_at_end=True,\n",
        "    mode=\"max\",\n",
        "    stop=stopper,\n",
        "    config={\"env\":\"CartPole-v0\"},\n",
        ")\n",
        "\n",
        "dfs = analysis.trial_dataframes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P314R9PAWe7i",
        "outputId": "5c454af5-061d-4c4a-fee6-7e25b5db8815"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-04 18:51:34,030\tINFO logger.py:630 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2022-07-04 18:51:34,033\tWARNING callback.py:106 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:39,932\tINFO trainer.py:2333 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:39,934\tINFO simple_q.py:188 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:39,934\tINFO trainer.py:906 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:41,610\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:51:41 (running for 00:00:07.58)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:41,691\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `RepayBuffer.add()` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:41,709\tWARNING multi_agent_prioritized_replay_buffer.py:187 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
            "\u001b[2m\u001b[36m(DQNTrainer pid=1867)\u001b[0m 2022-07-04 18:51:41,710\tWARNING deprecation.py:47 -- DeprecationWarning: `replay` has been deprecated. Use `sample` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 1000\n",
            "  counters:\n",
            "    last_target_update_ts: 1000\n",
            "    num_agent_steps_sampled: 1000\n",
            "    num_agent_steps_trained: 32\n",
            "    num_env_steps_sampled: 1000\n",
            "    num_env_steps_trained: 32\n",
            "    num_target_updates: 1\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-51-43\n",
            "  done: false\n",
            "  episode_len_mean: 20.479166666666668\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 51.0\n",
            "  episode_reward_mean: 20.479166666666668\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 48\n",
            "  episodes_total: 48\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 1000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 1.215288758277893\n",
            "          mean_q: 0.35784098505973816\n",
            "          mean_td_error: -0.5564054250717163\n",
            "          min_q: -0.07965049147605896\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.4353073537349701\n",
            "        - 0.12601888179779053\n",
            "        - -0.9819271564483643\n",
            "        - -0.7507875561714172\n",
            "        - -0.04874920845031738\n",
            "        - -0.4708687961101532\n",
            "        - -0.7369397878646851\n",
            "        - -0.29587143659591675\n",
            "        - -0.3920745551586151\n",
            "        - -0.33847880363464355\n",
            "        - -0.8670706748962402\n",
            "        - -0.895796000957489\n",
            "        - -0.6379512548446655\n",
            "        - -0.6462292671203613\n",
            "        - -1.0080006122589111\n",
            "        - -0.7328464388847351\n",
            "        - -0.8283366560935974\n",
            "        - -0.1593729853630066\n",
            "        - -0.29988646507263184\n",
            "        - -0.686423122882843\n",
            "        - -0.17530673742294312\n",
            "        - -0.5506623983383179\n",
            "        - -0.6843165159225464\n",
            "        - -0.7683428525924683\n",
            "        - -0.3648265600204468\n",
            "        - -0.5782386064529419\n",
            "        - -0.3907456696033478\n",
            "        - -0.8263939619064331\n",
            "        - -0.49192047119140625\n",
            "        - -0.7636644840240479\n",
            "        - -0.2944214344024658\n",
            "        - -0.8292346000671387\n",
            "    num_agent_steps_sampled: 1000\n",
            "    num_agent_steps_trained: 32\n",
            "    num_env_steps_sampled: 1000\n",
            "    num_env_steps_trained: 32\n",
            "    num_target_updates: 1\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 1000\n",
            "  num_agent_steps_trained: 32\n",
            "  num_env_steps_sampled: 1000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 32\n",
            "  num_env_steps_trained_this_iter: 32\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 59.925000000000004\n",
            "    ram_util_percent: 15.675\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.10038517810009816\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.07480198329502528\n",
            "    mean_inference_ms: 1.2976701681192344\n",
            "    mean_raw_obs_processing_ms: 0.20455528091598343\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 20.479166666666668\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 51.0\n",
            "    episode_reward_mean: 20.479166666666668\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 48\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 19\n",
            "      - 10\n",
            "      - 14\n",
            "      - 9\n",
            "      - 12\n",
            "      - 23\n",
            "      - 14\n",
            "      - 22\n",
            "      - 12\n",
            "      - 18\n",
            "      - 43\n",
            "      - 22\n",
            "      - 51\n",
            "      - 43\n",
            "      - 13\n",
            "      - 19\n",
            "      - 12\n",
            "      - 11\n",
            "      - 24\n",
            "      - 11\n",
            "      - 18\n",
            "      - 39\n",
            "      - 11\n",
            "      - 11\n",
            "      - 47\n",
            "      - 17\n",
            "      - 13\n",
            "      - 22\n",
            "      - 14\n",
            "      - 17\n",
            "      - 14\n",
            "      - 41\n",
            "      - 16\n",
            "      - 11\n",
            "      - 22\n",
            "      - 12\n",
            "      - 14\n",
            "      - 11\n",
            "      - 18\n",
            "      - 37\n",
            "      - 10\n",
            "      - 15\n",
            "      - 20\n",
            "      - 41\n",
            "      - 47\n",
            "      - 18\n",
            "      - 12\n",
            "      - 13\n",
            "      episode_reward:\n",
            "      - 19.0\n",
            "      - 10.0\n",
            "      - 14.0\n",
            "      - 9.0\n",
            "      - 12.0\n",
            "      - 23.0\n",
            "      - 14.0\n",
            "      - 22.0\n",
            "      - 12.0\n",
            "      - 18.0\n",
            "      - 43.0\n",
            "      - 22.0\n",
            "      - 51.0\n",
            "      - 43.0\n",
            "      - 13.0\n",
            "      - 19.0\n",
            "      - 12.0\n",
            "      - 11.0\n",
            "      - 24.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 39.0\n",
            "      - 11.0\n",
            "      - 11.0\n",
            "      - 47.0\n",
            "      - 17.0\n",
            "      - 13.0\n",
            "      - 22.0\n",
            "      - 14.0\n",
            "      - 17.0\n",
            "      - 14.0\n",
            "      - 41.0\n",
            "      - 16.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 12.0\n",
            "      - 14.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 37.0\n",
            "      - 10.0\n",
            "      - 15.0\n",
            "      - 20.0\n",
            "      - 41.0\n",
            "      - 47.0\n",
            "      - 18.0\n",
            "      - 12.0\n",
            "      - 13.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.10038517810009816\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.07480198329502528\n",
            "      mean_inference_ms: 1.2976701681192344\n",
            "      mean_raw_obs_processing_ms: 0.20455528091598343\n",
            "  time_since_restore: 2.266113519668579\n",
            "  time_this_iter_s: 2.266113519668579\n",
            "  time_total_s: 2.266113519668579\n",
            "  timers:\n",
            "    learn_throughput: 128.545\n",
            "    learn_time_ms: 248.94\n",
            "    load_throughput: 249475.331\n",
            "    load_time_ms: 0.128\n",
            "    synch_weights_time_ms: 0.074\n",
            "    training_iteration_time_ms: 41.828\n",
            "  timestamp: 1656960703\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 1000\n",
            "  training_iteration: 1\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:51:43 (running for 00:00:09.88)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.26611</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 20.4792</td><td style=\"text-align: right;\">                  51</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">           20.4792</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 3000\n",
            "  counters:\n",
            "    last_target_update_ts: 3000\n",
            "    num_agent_steps_sampled: 3000\n",
            "    num_agent_steps_trained: 16032\n",
            "    num_env_steps_sampled: 3000\n",
            "    num_env_steps_trained: 16032\n",
            "    num_target_updates: 5\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-51-53\n",
            "  done: false\n",
            "  episode_len_mean: 19.73\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 64.0\n",
            "  episode_reward_mean: 19.73\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 45\n",
            "  episodes_total: 148\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 3000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 7.650724411010742\n",
            "          mean_q: 4.126380920410156\n",
            "          mean_td_error: 0.18538179993629456\n",
            "          min_q: 2.318976402282715\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 1.6525812149047852\n",
            "        - 1.7657387256622314\n",
            "        - -0.23691511154174805\n",
            "        - -0.28229379653930664\n",
            "        - 1.357226848602295\n",
            "        - 1.4885859489440918\n",
            "        - -0.4136323928833008\n",
            "        - -0.1386122703552246\n",
            "        - -0.10151147842407227\n",
            "        - -0.03473949432373047\n",
            "        - 1.6921639442443848\n",
            "        - -0.6123137474060059\n",
            "        - -0.027964115142822266\n",
            "        - -0.10620307922363281\n",
            "        - 0.13896512985229492\n",
            "        - 0.11411046981811523\n",
            "        - 0.3262753486633301\n",
            "        - 1.357226848602295\n",
            "        - -0.1585988998413086\n",
            "        - 0.3388032913208008\n",
            "        - -0.5106775760650635\n",
            "        - 0.024396419525146484\n",
            "        - -0.6631219387054443\n",
            "        - 0.006798267364501953\n",
            "        - -0.7278141975402832\n",
            "        - -1.1033735275268555\n",
            "        - -0.024447917938232422\n",
            "        - -1.0014877319335938\n",
            "        - 1.3751893043518066\n",
            "        - -0.1102151870727539\n",
            "        - 0.673882007598877\n",
            "        - -0.12580347061157227\n",
            "    num_agent_steps_sampled: 3000\n",
            "    num_agent_steps_trained: 16032\n",
            "    num_env_steps_sampled: 3000\n",
            "    num_env_steps_trained: 16032\n",
            "    num_target_updates: 5\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 3000\n",
            "  num_agent_steps_trained: 16032\n",
            "  num_env_steps_sampled: 3000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 16032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.72857142857143\n",
            "    ram_util_percent: 15.799999999999999\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11820618587597602\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0887013194467583\n",
            "    mean_inference_ms: 1.3839761537748523\n",
            "    mean_raw_obs_processing_ms: 0.22760613609018066\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 19.73\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 64.0\n",
            "    episode_reward_mean: 19.73\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 45\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 30\n",
            "      - 17\n",
            "      - 15\n",
            "      - 44\n",
            "      - 22\n",
            "      - 27\n",
            "      - 13\n",
            "      - 19\n",
            "      - 13\n",
            "      - 13\n",
            "      - 10\n",
            "      - 43\n",
            "      - 15\n",
            "      - 16\n",
            "      - 27\n",
            "      - 14\n",
            "      - 21\n",
            "      - 16\n",
            "      - 25\n",
            "      - 20\n",
            "      - 12\n",
            "      - 9\n",
            "      - 19\n",
            "      - 16\n",
            "      - 16\n",
            "      - 19\n",
            "      - 33\n",
            "      - 13\n",
            "      - 10\n",
            "      - 11\n",
            "      - 12\n",
            "      - 14\n",
            "      - 20\n",
            "      - 12\n",
            "      - 18\n",
            "      - 12\n",
            "      - 20\n",
            "      - 15\n",
            "      - 14\n",
            "      - 11\n",
            "      - 10\n",
            "      - 16\n",
            "      - 21\n",
            "      - 12\n",
            "      - 21\n",
            "      - 25\n",
            "      - 13\n",
            "      - 16\n",
            "      - 29\n",
            "      - 12\n",
            "      - 28\n",
            "      - 21\n",
            "      - 14\n",
            "      - 10\n",
            "      - 41\n",
            "      - 15\n",
            "      - 17\n",
            "      - 16\n",
            "      - 9\n",
            "      - 50\n",
            "      - 16\n",
            "      - 22\n",
            "      - 17\n",
            "      - 16\n",
            "      - 13\n",
            "      - 29\n",
            "      - 19\n",
            "      - 13\n",
            "      - 13\n",
            "      - 20\n",
            "      - 22\n",
            "      - 31\n",
            "      - 15\n",
            "      - 17\n",
            "      - 12\n",
            "      - 25\n",
            "      - 11\n",
            "      - 19\n",
            "      - 29\n",
            "      - 11\n",
            "      - 24\n",
            "      - 11\n",
            "      - 22\n",
            "      - 23\n",
            "      - 64\n",
            "      - 11\n",
            "      - 18\n",
            "      - 23\n",
            "      - 36\n",
            "      - 14\n",
            "      - 31\n",
            "      - 31\n",
            "      - 13\n",
            "      - 17\n",
            "      - 34\n",
            "      - 10\n",
            "      - 34\n",
            "      - 9\n",
            "      - 18\n",
            "      - 38\n",
            "      episode_reward:\n",
            "      - 30.0\n",
            "      - 17.0\n",
            "      - 15.0\n",
            "      - 44.0\n",
            "      - 22.0\n",
            "      - 27.0\n",
            "      - 13.0\n",
            "      - 19.0\n",
            "      - 13.0\n",
            "      - 13.0\n",
            "      - 10.0\n",
            "      - 43.0\n",
            "      - 15.0\n",
            "      - 16.0\n",
            "      - 27.0\n",
            "      - 14.0\n",
            "      - 21.0\n",
            "      - 16.0\n",
            "      - 25.0\n",
            "      - 20.0\n",
            "      - 12.0\n",
            "      - 9.0\n",
            "      - 19.0\n",
            "      - 16.0\n",
            "      - 16.0\n",
            "      - 19.0\n",
            "      - 33.0\n",
            "      - 13.0\n",
            "      - 10.0\n",
            "      - 11.0\n",
            "      - 12.0\n",
            "      - 14.0\n",
            "      - 20.0\n",
            "      - 12.0\n",
            "      - 18.0\n",
            "      - 12.0\n",
            "      - 20.0\n",
            "      - 15.0\n",
            "      - 14.0\n",
            "      - 11.0\n",
            "      - 10.0\n",
            "      - 16.0\n",
            "      - 21.0\n",
            "      - 12.0\n",
            "      - 21.0\n",
            "      - 25.0\n",
            "      - 13.0\n",
            "      - 16.0\n",
            "      - 29.0\n",
            "      - 12.0\n",
            "      - 28.0\n",
            "      - 21.0\n",
            "      - 14.0\n",
            "      - 10.0\n",
            "      - 41.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 16.0\n",
            "      - 9.0\n",
            "      - 50.0\n",
            "      - 16.0\n",
            "      - 22.0\n",
            "      - 17.0\n",
            "      - 16.0\n",
            "      - 13.0\n",
            "      - 29.0\n",
            "      - 19.0\n",
            "      - 13.0\n",
            "      - 13.0\n",
            "      - 20.0\n",
            "      - 22.0\n",
            "      - 31.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 12.0\n",
            "      - 25.0\n",
            "      - 11.0\n",
            "      - 19.0\n",
            "      - 29.0\n",
            "      - 11.0\n",
            "      - 24.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 23.0\n",
            "      - 64.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 23.0\n",
            "      - 36.0\n",
            "      - 14.0\n",
            "      - 31.0\n",
            "      - 31.0\n",
            "      - 13.0\n",
            "      - 17.0\n",
            "      - 34.0\n",
            "      - 10.0\n",
            "      - 34.0\n",
            "      - 9.0\n",
            "      - 18.0\n",
            "      - 38.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11820618587597602\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.0887013194467583\n",
            "      mean_inference_ms: 1.3839761537748523\n",
            "      mean_raw_obs_processing_ms: 0.22760613609018066\n",
            "  time_since_restore: 12.03965139389038\n",
            "  time_this_iter_s: 4.894604444503784\n",
            "  time_total_s: 12.03965139389038\n",
            "  timers:\n",
            "    learn_throughput: 5355.748\n",
            "    learn_time_ms: 5.975\n",
            "    load_throughput: 217180.79\n",
            "    load_time_ms: 0.147\n",
            "    synch_weights_time_ms: 0.055\n",
            "    training_iteration_time_ms: 17.607\n",
            "  timestamp: 1656960713\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 3000\n",
            "  training_iteration: 3\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:51:53 (running for 00:00:19.70)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.0397</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">   19.73</td><td style=\"text-align: right;\">                  64</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             19.73</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 5000\n",
            "  counters:\n",
            "    last_target_update_ts: 5000\n",
            "    num_agent_steps_sampled: 5000\n",
            "    num_agent_steps_trained: 32032\n",
            "    num_env_steps_sampled: 5000\n",
            "    num_env_steps_trained: 32032\n",
            "    num_target_updates: 9\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-02\n",
            "  done: false\n",
            "  episode_len_mean: 33.11\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 33.11\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 14\n",
            "  episodes_total: 185\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 5000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 9.969917297363281\n",
            "          mean_q: 8.075909614562988\n",
            "          mean_td_error: 0.4871125817298889\n",
            "          min_q: 3.534071207046509\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.15053749084472656\n",
            "        - -0.23163795471191406\n",
            "        - 0.2529182434082031\n",
            "        - 4.702332496643066\n",
            "        - -0.08688831329345703\n",
            "        - -0.34688282012939453\n",
            "        - 0.21661853790283203\n",
            "        - 7.319790840148926\n",
            "        - -0.9117732048034668\n",
            "        - -0.7085056304931641\n",
            "        - -0.07049417495727539\n",
            "        - 0.28450441360473633\n",
            "        - 0.2344074249267578\n",
            "        - -0.2195758819580078\n",
            "        - -0.07412052154541016\n",
            "        - -0.5262365341186523\n",
            "        - 0.05433845520019531\n",
            "        - 0.12616920471191406\n",
            "        - 2.534071207046509\n",
            "        - 0.24677324295043945\n",
            "        - 4.395696640014648\n",
            "        - -0.2566032409667969\n",
            "        - 0.3006258010864258\n",
            "        - 0.19020366668701172\n",
            "        - -0.06960940361022949\n",
            "        - 0.2682828903198242\n",
            "        - 0.08311128616333008\n",
            "        - -1.1447343826293945\n",
            "        - -0.15591812133789062\n",
            "        - -0.1490192413330078\n",
            "        - -0.7152585983276367\n",
            "        - 0.19555377960205078\n",
            "    num_agent_steps_sampled: 5000\n",
            "    num_agent_steps_trained: 32032\n",
            "    num_env_steps_sampled: 5000\n",
            "    num_env_steps_trained: 32032\n",
            "    num_target_updates: 9\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 5000\n",
            "  num_agent_steps_trained: 32032\n",
            "  num_env_steps_sampled: 5000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 32032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.13333333333333\n",
            "    ram_util_percent: 15.816666666666668\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11980906098612872\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.09066787054321299\n",
            "    mean_inference_ms: 1.3855640109044196\n",
            "    mean_raw_obs_processing_ms: 0.22772174604493314\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 33.11\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 33.11\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 14\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 15\n",
            "      - 14\n",
            "      - 11\n",
            "      - 10\n",
            "      - 16\n",
            "      - 21\n",
            "      - 12\n",
            "      - 21\n",
            "      - 25\n",
            "      - 13\n",
            "      - 16\n",
            "      - 29\n",
            "      - 12\n",
            "      - 28\n",
            "      - 21\n",
            "      - 14\n",
            "      - 10\n",
            "      - 41\n",
            "      - 15\n",
            "      - 17\n",
            "      - 16\n",
            "      - 9\n",
            "      - 50\n",
            "      - 16\n",
            "      - 22\n",
            "      - 17\n",
            "      - 16\n",
            "      - 13\n",
            "      - 29\n",
            "      - 19\n",
            "      - 13\n",
            "      - 13\n",
            "      - 20\n",
            "      - 22\n",
            "      - 31\n",
            "      - 15\n",
            "      - 17\n",
            "      - 12\n",
            "      - 25\n",
            "      - 11\n",
            "      - 19\n",
            "      - 29\n",
            "      - 11\n",
            "      - 24\n",
            "      - 11\n",
            "      - 22\n",
            "      - 23\n",
            "      - 64\n",
            "      - 11\n",
            "      - 18\n",
            "      - 23\n",
            "      - 36\n",
            "      - 14\n",
            "      - 31\n",
            "      - 31\n",
            "      - 13\n",
            "      - 17\n",
            "      - 34\n",
            "      - 10\n",
            "      - 34\n",
            "      - 9\n",
            "      - 18\n",
            "      - 38\n",
            "      - 72\n",
            "      - 35\n",
            "      - 54\n",
            "      - 18\n",
            "      - 11\n",
            "      - 22\n",
            "      - 18\n",
            "      - 49\n",
            "      - 32\n",
            "      - 15\n",
            "      - 121\n",
            "      - 18\n",
            "      - 18\n",
            "      - 80\n",
            "      - 42\n",
            "      - 28\n",
            "      - 29\n",
            "      - 37\n",
            "      - 13\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      episode_reward:\n",
            "      - 15.0\n",
            "      - 14.0\n",
            "      - 11.0\n",
            "      - 10.0\n",
            "      - 16.0\n",
            "      - 21.0\n",
            "      - 12.0\n",
            "      - 21.0\n",
            "      - 25.0\n",
            "      - 13.0\n",
            "      - 16.0\n",
            "      - 29.0\n",
            "      - 12.0\n",
            "      - 28.0\n",
            "      - 21.0\n",
            "      - 14.0\n",
            "      - 10.0\n",
            "      - 41.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 16.0\n",
            "      - 9.0\n",
            "      - 50.0\n",
            "      - 16.0\n",
            "      - 22.0\n",
            "      - 17.0\n",
            "      - 16.0\n",
            "      - 13.0\n",
            "      - 29.0\n",
            "      - 19.0\n",
            "      - 13.0\n",
            "      - 13.0\n",
            "      - 20.0\n",
            "      - 22.0\n",
            "      - 31.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 12.0\n",
            "      - 25.0\n",
            "      - 11.0\n",
            "      - 19.0\n",
            "      - 29.0\n",
            "      - 11.0\n",
            "      - 24.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 23.0\n",
            "      - 64.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 23.0\n",
            "      - 36.0\n",
            "      - 14.0\n",
            "      - 31.0\n",
            "      - 31.0\n",
            "      - 13.0\n",
            "      - 17.0\n",
            "      - 34.0\n",
            "      - 10.0\n",
            "      - 34.0\n",
            "      - 9.0\n",
            "      - 18.0\n",
            "      - 38.0\n",
            "      - 72.0\n",
            "      - 35.0\n",
            "      - 54.0\n",
            "      - 18.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 18.0\n",
            "      - 49.0\n",
            "      - 32.0\n",
            "      - 15.0\n",
            "      - 121.0\n",
            "      - 18.0\n",
            "      - 18.0\n",
            "      - 80.0\n",
            "      - 42.0\n",
            "      - 28.0\n",
            "      - 29.0\n",
            "      - 37.0\n",
            "      - 13.0\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11980906098612872\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.09066787054321299\n",
            "      mean_inference_ms: 1.3855640109044196\n",
            "      mean_raw_obs_processing_ms: 0.22772174604493314\n",
            "  time_since_restore: 20.905951023101807\n",
            "  time_this_iter_s: 4.285810947418213\n",
            "  time_total_s: 20.905951023101807\n",
            "  timers:\n",
            "    learn_throughput: 5504.426\n",
            "    learn_time_ms: 5.814\n",
            "    load_throughput: 229471.24\n",
            "    load_time_ms: 0.139\n",
            "    synch_weights_time_ms: 0.049\n",
            "    training_iteration_time_ms: 17.556\n",
            "  timestamp: 1656960722\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 5000\n",
            "  training_iteration: 5\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:02 (running for 00:00:28.69)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          20.906</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">   33.11</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             33.11</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 7000\n",
            "  counters:\n",
            "    last_target_update_ts: 7000\n",
            "    num_agent_steps_sampled: 7000\n",
            "    num_agent_steps_trained: 48032\n",
            "    num_env_steps_sampled: 7000\n",
            "    num_env_steps_trained: 48032\n",
            "    num_target_updates: 13\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-11\n",
            "  done: false\n",
            "  episode_len_mean: 50.41\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 50.41\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 8\n",
            "  episodes_total: 200\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 7000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 14.043004035949707\n",
            "          mean_q: 11.684186935424805\n",
            "          mean_td_error: -0.023912936449050903\n",
            "          min_q: -0.033339500427246094\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.13097190856933594\n",
            "        - 0.7898120880126953\n",
            "        - -0.4316368103027344\n",
            "        - -1.033339500427246\n",
            "        - -0.14531803131103516\n",
            "        - -0.28619384765625\n",
            "        - -0.19179630279541016\n",
            "        - -1.6564226150512695\n",
            "        - -0.09473609924316406\n",
            "        - -0.38005828857421875\n",
            "        - -0.28461265563964844\n",
            "        - -0.042144775390625\n",
            "        - 0.07231998443603516\n",
            "        - -0.04387378692626953\n",
            "        - 0.7970218658447266\n",
            "        - 0.10813617706298828\n",
            "        - -0.30347442626953125\n",
            "        - -2.1878042221069336\n",
            "        - 0.05095958709716797\n",
            "        - 0.0817403793334961\n",
            "        - -1.3793268203735352\n",
            "        - -0.5183591842651367\n",
            "        - 0.11031246185302734\n",
            "        - 4.603471755981445\n",
            "        - -0.3053436279296875\n",
            "        - -0.25601768493652344\n",
            "        - -0.4221477508544922\n",
            "        - -0.03924751281738281\n",
            "        - 3.8218631744384766\n",
            "        - -0.4183330535888672\n",
            "        - -0.4144287109375\n",
            "        - -0.4972076416015625\n",
            "    num_agent_steps_sampled: 7000\n",
            "    num_agent_steps_trained: 48032\n",
            "    num_env_steps_sampled: 7000\n",
            "    num_env_steps_trained: 48032\n",
            "    num_target_updates: 13\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 7000\n",
            "  num_agent_steps_trained: 48032\n",
            "  num_env_steps_sampled: 7000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 48032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.03333333333335\n",
            "    ram_util_percent: 15.9\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.12005913071480279\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.09120127882597426\n",
            "    mean_inference_ms: 1.37971299353176\n",
            "    mean_raw_obs_processing_ms: 0.22650970882671623\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 50.41\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 50.41\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 8\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 14\n",
            "      - 10\n",
            "      - 41\n",
            "      - 15\n",
            "      - 17\n",
            "      - 16\n",
            "      - 9\n",
            "      - 50\n",
            "      - 16\n",
            "      - 22\n",
            "      - 17\n",
            "      - 16\n",
            "      - 13\n",
            "      - 29\n",
            "      - 19\n",
            "      - 13\n",
            "      - 13\n",
            "      - 20\n",
            "      - 22\n",
            "      - 31\n",
            "      - 15\n",
            "      - 17\n",
            "      - 12\n",
            "      - 25\n",
            "      - 11\n",
            "      - 19\n",
            "      - 29\n",
            "      - 11\n",
            "      - 24\n",
            "      - 11\n",
            "      - 22\n",
            "      - 23\n",
            "      - 64\n",
            "      - 11\n",
            "      - 18\n",
            "      - 23\n",
            "      - 36\n",
            "      - 14\n",
            "      - 31\n",
            "      - 31\n",
            "      - 13\n",
            "      - 17\n",
            "      - 34\n",
            "      - 10\n",
            "      - 34\n",
            "      - 9\n",
            "      - 18\n",
            "      - 38\n",
            "      - 72\n",
            "      - 35\n",
            "      - 54\n",
            "      - 18\n",
            "      - 11\n",
            "      - 22\n",
            "      - 18\n",
            "      - 49\n",
            "      - 32\n",
            "      - 15\n",
            "      - 121\n",
            "      - 18\n",
            "      - 18\n",
            "      - 80\n",
            "      - 42\n",
            "      - 28\n",
            "      - 29\n",
            "      - 37\n",
            "      - 13\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      episode_reward:\n",
            "      - 14.0\n",
            "      - 10.0\n",
            "      - 41.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 16.0\n",
            "      - 9.0\n",
            "      - 50.0\n",
            "      - 16.0\n",
            "      - 22.0\n",
            "      - 17.0\n",
            "      - 16.0\n",
            "      - 13.0\n",
            "      - 29.0\n",
            "      - 19.0\n",
            "      - 13.0\n",
            "      - 13.0\n",
            "      - 20.0\n",
            "      - 22.0\n",
            "      - 31.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 12.0\n",
            "      - 25.0\n",
            "      - 11.0\n",
            "      - 19.0\n",
            "      - 29.0\n",
            "      - 11.0\n",
            "      - 24.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 23.0\n",
            "      - 64.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 23.0\n",
            "      - 36.0\n",
            "      - 14.0\n",
            "      - 31.0\n",
            "      - 31.0\n",
            "      - 13.0\n",
            "      - 17.0\n",
            "      - 34.0\n",
            "      - 10.0\n",
            "      - 34.0\n",
            "      - 9.0\n",
            "      - 18.0\n",
            "      - 38.0\n",
            "      - 72.0\n",
            "      - 35.0\n",
            "      - 54.0\n",
            "      - 18.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 18.0\n",
            "      - 49.0\n",
            "      - 32.0\n",
            "      - 15.0\n",
            "      - 121.0\n",
            "      - 18.0\n",
            "      - 18.0\n",
            "      - 80.0\n",
            "      - 42.0\n",
            "      - 28.0\n",
            "      - 29.0\n",
            "      - 37.0\n",
            "      - 13.0\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.12005913071480279\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.09120127882597426\n",
            "      mean_inference_ms: 1.37971299353176\n",
            "      mean_raw_obs_processing_ms: 0.22650970882671623\n",
            "  time_since_restore: 29.730047941207886\n",
            "  time_this_iter_s: 4.404265403747559\n",
            "  time_total_s: 29.730047941207886\n",
            "  timers:\n",
            "    learn_throughput: 5286.202\n",
            "    learn_time_ms: 6.053\n",
            "    load_throughput: 217391.85\n",
            "    load_time_ms: 0.147\n",
            "    synch_weights_time_ms: 0.057\n",
            "    training_iteration_time_ms: 18.453\n",
            "  timestamp: 1656960731\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 7000\n",
            "  training_iteration: 7\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:11 (running for 00:00:37.50)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">           29.73</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">   50.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             50.41</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 9000\n",
            "  counters:\n",
            "    last_target_update_ts: 9000\n",
            "    num_agent_steps_sampled: 9000\n",
            "    num_agent_steps_trained: 64032\n",
            "    num_env_steps_sampled: 9000\n",
            "    num_env_steps_trained: 64032\n",
            "    num_target_updates: 17\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-20\n",
            "  done: false\n",
            "  episode_len_mean: 67.47\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 67.47\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 9\n",
            "  episodes_total: 215\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 9000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 18.108858108520508\n",
            "          mean_q: 15.498712539672852\n",
            "          mean_td_error: 1.4355617761611938\n",
            "          min_q: 6.7267656326293945\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.6833591461181641\n",
            "        - -0.025661468505859375\n",
            "        - 0.2811307907104492\n",
            "        - -0.5812530517578125\n",
            "        - -0.10512542724609375\n",
            "        - 0.27588653564453125\n",
            "        - -3.07541561126709\n",
            "        - 0.6023273468017578\n",
            "        - 0.6077289581298828\n",
            "        - 0.2201671600341797\n",
            "        - 0.6201572418212891\n",
            "        - -0.7113275527954102\n",
            "        - 2.295665740966797\n",
            "        - 0.15393829345703125\n",
            "        - 0.6991291046142578\n",
            "        - 0.3683147430419922\n",
            "        - -0.6370096206665039\n",
            "        - 0.916203498840332\n",
            "        - 0.5979404449462891\n",
            "        - 5.7267656326293945\n",
            "        - 0.6305084228515625\n",
            "        - 0.3469219207763672\n",
            "        - 11.761903762817383\n",
            "        - -1.1802873611450195\n",
            "        - 1.2075042724609375\n",
            "        - 14.752439498901367\n",
            "        - 0.2374114990234375\n",
            "        - 0.5696315765380859\n",
            "        - -0.47772979736328125\n",
            "        - 0.23464107513427734\n",
            "        - 9.460382461547852\n",
            "        - 0.8484420776367188\n",
            "    num_agent_steps_sampled: 9000\n",
            "    num_agent_steps_trained: 64032\n",
            "    num_env_steps_sampled: 9000\n",
            "    num_env_steps_trained: 64032\n",
            "    num_target_updates: 17\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 9000\n",
            "  num_agent_steps_trained: 64032\n",
            "  num_env_steps_sampled: 9000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 64032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 68.06666666666666\n",
            "    ram_util_percent: 15.9\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11955315243685302\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.09087315523160802\n",
            "    mean_inference_ms: 1.368124516423057\n",
            "    mean_raw_obs_processing_ms: 0.22416608906692723\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 67.47\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 67.47\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 9\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 13\n",
            "      - 13\n",
            "      - 20\n",
            "      - 22\n",
            "      - 31\n",
            "      - 15\n",
            "      - 17\n",
            "      - 12\n",
            "      - 25\n",
            "      - 11\n",
            "      - 19\n",
            "      - 29\n",
            "      - 11\n",
            "      - 24\n",
            "      - 11\n",
            "      - 22\n",
            "      - 23\n",
            "      - 64\n",
            "      - 11\n",
            "      - 18\n",
            "      - 23\n",
            "      - 36\n",
            "      - 14\n",
            "      - 31\n",
            "      - 31\n",
            "      - 13\n",
            "      - 17\n",
            "      - 34\n",
            "      - 10\n",
            "      - 34\n",
            "      - 9\n",
            "      - 18\n",
            "      - 38\n",
            "      - 72\n",
            "      - 35\n",
            "      - 54\n",
            "      - 18\n",
            "      - 11\n",
            "      - 22\n",
            "      - 18\n",
            "      - 49\n",
            "      - 32\n",
            "      - 15\n",
            "      - 121\n",
            "      - 18\n",
            "      - 18\n",
            "      - 80\n",
            "      - 42\n",
            "      - 28\n",
            "      - 29\n",
            "      - 37\n",
            "      - 13\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      episode_reward:\n",
            "      - 13.0\n",
            "      - 13.0\n",
            "      - 20.0\n",
            "      - 22.0\n",
            "      - 31.0\n",
            "      - 15.0\n",
            "      - 17.0\n",
            "      - 12.0\n",
            "      - 25.0\n",
            "      - 11.0\n",
            "      - 19.0\n",
            "      - 29.0\n",
            "      - 11.0\n",
            "      - 24.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 23.0\n",
            "      - 64.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 23.0\n",
            "      - 36.0\n",
            "      - 14.0\n",
            "      - 31.0\n",
            "      - 31.0\n",
            "      - 13.0\n",
            "      - 17.0\n",
            "      - 34.0\n",
            "      - 10.0\n",
            "      - 34.0\n",
            "      - 9.0\n",
            "      - 18.0\n",
            "      - 38.0\n",
            "      - 72.0\n",
            "      - 35.0\n",
            "      - 54.0\n",
            "      - 18.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 18.0\n",
            "      - 49.0\n",
            "      - 32.0\n",
            "      - 15.0\n",
            "      - 121.0\n",
            "      - 18.0\n",
            "      - 18.0\n",
            "      - 80.0\n",
            "      - 42.0\n",
            "      - 28.0\n",
            "      - 29.0\n",
            "      - 37.0\n",
            "      - 13.0\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11955315243685302\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.09087315523160802\n",
            "      mean_inference_ms: 1.368124516423057\n",
            "      mean_raw_obs_processing_ms: 0.22416608906692723\n",
            "  time_since_restore: 38.69114899635315\n",
            "  time_this_iter_s: 4.447423696517944\n",
            "  time_total_s: 38.69114899635315\n",
            "  timers:\n",
            "    learn_throughput: 5775.836\n",
            "    learn_time_ms: 5.54\n",
            "    load_throughput: 151453.09\n",
            "    load_time_ms: 0.211\n",
            "    synch_weights_time_ms: 0.052\n",
            "    training_iteration_time_ms: 17.125\n",
            "  timestamp: 1656960740\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 9000\n",
            "  training_iteration: 9\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:20 (running for 00:00:46.51)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         38.6911</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">   67.47</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             67.47</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 11000\n",
            "  counters:\n",
            "    last_target_update_ts: 11000\n",
            "    num_agent_steps_sampled: 11000\n",
            "    num_agent_steps_trained: 80032\n",
            "    num_env_steps_sampled: 11000\n",
            "    num_env_steps_trained: 80032\n",
            "    num_target_updates: 21\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-29\n",
            "  done: false\n",
            "  episode_len_mean: 84.91\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 84.91\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 6\n",
            "  episodes_total: 228\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 11000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 21.626956939697266\n",
            "          mean_q: 16.573646545410156\n",
            "          mean_td_error: 1.08284592628479\n",
            "          min_q: -3.4192354679107666\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.11715507507324219\n",
            "        - 0.2721099853515625\n",
            "        - -4.4192352294921875\n",
            "        - -0.37131500244140625\n",
            "        - -0.6032752990722656\n",
            "        - 0.01319122314453125\n",
            "        - -0.8180322647094727\n",
            "        - -0.25435638427734375\n",
            "        - 0.13327789306640625\n",
            "        - 0.3432636260986328\n",
            "        - -0.19671249389648438\n",
            "        - 0.7788925170898438\n",
            "        - 17.201372146606445\n",
            "        - 7.873845100402832\n",
            "        - -0.6276798248291016\n",
            "        - 0.09756660461425781\n",
            "        - -0.2483673095703125\n",
            "        - 0.2187347412109375\n",
            "        - -0.07733726501464844\n",
            "        - 1.696627140045166\n",
            "        - 0.09844207763671875\n",
            "        - -0.1838054656982422\n",
            "        - -0.480194091796875\n",
            "        - -1.0669450759887695\n",
            "        - -0.07733726501464844\n",
            "        - 0.1308269500732422\n",
            "        - 0.19115734100341797\n",
            "        - -0.478790283203125\n",
            "        - -0.07548713684082031\n",
            "        - -0.13741111755371094\n",
            "        - 0.11942863464355469\n",
            "        - 15.481460571289062\n",
            "    num_agent_steps_sampled: 11000\n",
            "    num_agent_steps_trained: 80032\n",
            "    num_env_steps_sampled: 11000\n",
            "    num_env_steps_trained: 80032\n",
            "    num_target_updates: 21\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 11000\n",
            "  num_agent_steps_trained: 80032\n",
            "  num_env_steps_sampled: 11000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 80032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.67142857142856\n",
            "    ram_util_percent: 16.0\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11886787862486006\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.09036709518168964\n",
            "    mean_inference_ms: 1.356114031392869\n",
            "    mean_raw_obs_processing_ms: 0.22181619989374976\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 84.91\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 84.91\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 6\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 24\n",
            "      - 11\n",
            "      - 22\n",
            "      - 23\n",
            "      - 64\n",
            "      - 11\n",
            "      - 18\n",
            "      - 23\n",
            "      - 36\n",
            "      - 14\n",
            "      - 31\n",
            "      - 31\n",
            "      - 13\n",
            "      - 17\n",
            "      - 34\n",
            "      - 10\n",
            "      - 34\n",
            "      - 9\n",
            "      - 18\n",
            "      - 38\n",
            "      - 72\n",
            "      - 35\n",
            "      - 54\n",
            "      - 18\n",
            "      - 11\n",
            "      - 22\n",
            "      - 18\n",
            "      - 49\n",
            "      - 32\n",
            "      - 15\n",
            "      - 121\n",
            "      - 18\n",
            "      - 18\n",
            "      - 80\n",
            "      - 42\n",
            "      - 28\n",
            "      - 29\n",
            "      - 37\n",
            "      - 13\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 24.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 23.0\n",
            "      - 64.0\n",
            "      - 11.0\n",
            "      - 18.0\n",
            "      - 23.0\n",
            "      - 36.0\n",
            "      - 14.0\n",
            "      - 31.0\n",
            "      - 31.0\n",
            "      - 13.0\n",
            "      - 17.0\n",
            "      - 34.0\n",
            "      - 10.0\n",
            "      - 34.0\n",
            "      - 9.0\n",
            "      - 18.0\n",
            "      - 38.0\n",
            "      - 72.0\n",
            "      - 35.0\n",
            "      - 54.0\n",
            "      - 18.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 18.0\n",
            "      - 49.0\n",
            "      - 32.0\n",
            "      - 15.0\n",
            "      - 121.0\n",
            "      - 18.0\n",
            "      - 18.0\n",
            "      - 80.0\n",
            "      - 42.0\n",
            "      - 28.0\n",
            "      - 29.0\n",
            "      - 37.0\n",
            "      - 13.0\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11886787862486006\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.09036709518168964\n",
            "      mean_inference_ms: 1.356114031392869\n",
            "      mean_raw_obs_processing_ms: 0.22181619989374976\n",
            "  time_since_restore: 47.681477785110474\n",
            "  time_this_iter_s: 4.555440187454224\n",
            "  time_total_s: 47.681477785110474\n",
            "  timers:\n",
            "    learn_throughput: 5436.734\n",
            "    learn_time_ms: 5.886\n",
            "    load_throughput: 231849.591\n",
            "    load_time_ms: 0.138\n",
            "    synch_weights_time_ms: 0.057\n",
            "    training_iteration_time_ms: 17.528\n",
            "  timestamp: 1656960749\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 11000\n",
            "  training_iteration: 11\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:29 (running for 00:00:55.63)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         47.6815</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">   84.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             84.91</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 13000\n",
            "  counters:\n",
            "    last_target_update_ts: 13000\n",
            "    num_agent_steps_sampled: 13000\n",
            "    num_agent_steps_trained: 96032\n",
            "    num_env_steps_sampled: 13000\n",
            "    num_env_steps_trained: 96032\n",
            "    num_target_updates: 25\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-38\n",
            "  done: false\n",
            "  episode_len_mean: 100.76\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 100.76\n",
            "  episode_reward_min: 9.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 241\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 13000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 24.40104866027832\n",
            "          mean_q: 20.220401763916016\n",
            "          mean_td_error: 0.7952315807342529\n",
            "          min_q: 0.9887267351150513\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.29440879821777344\n",
            "        - 0.35461997985839844\n",
            "        - 0.127899169921875\n",
            "        - -0.01127326488494873\n",
            "        - -0.3663482666015625\n",
            "        - -0.47127437591552734\n",
            "        - -0.12749671936035156\n",
            "        - -0.2693138122558594\n",
            "        - -0.8597831726074219\n",
            "        - -0.3409404754638672\n",
            "        - -0.7298183441162109\n",
            "        - 0.51129150390625\n",
            "        - -0.1757049560546875\n",
            "        - -0.014087677001953125\n",
            "        - -0.40975189208984375\n",
            "        - 0.5384063720703125\n",
            "        - 0.7533016204833984\n",
            "        - 19.550764083862305\n",
            "        - 0.5422897338867188\n",
            "        - 0.7341766357421875\n",
            "        - -0.2694549560546875\n",
            "        - 0.9279212951660156\n",
            "        - 0.03652381896972656\n",
            "        - -0.47363853454589844\n",
            "        - 4.499898910522461\n",
            "        - 0.07880592346191406\n",
            "        - 1.2828521728515625\n",
            "        - -0.1423015594482422\n",
            "        - -0.2439861297607422\n",
            "        - -0.015926361083984375\n",
            "        - 0.7390384674072266\n",
            "        - -0.01486968994140625\n",
            "    num_agent_steps_sampled: 13000\n",
            "    num_agent_steps_trained: 96032\n",
            "    num_env_steps_sampled: 13000\n",
            "    num_env_steps_trained: 96032\n",
            "    num_target_updates: 25\n",
            "  iterations_since_restore: 13\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 13000\n",
            "  num_agent_steps_trained: 96032\n",
            "  num_env_steps_sampled: 13000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 96032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.62857142857145\n",
            "    ram_util_percent: 16.02857142857143\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11817737265506902\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08986564492664854\n",
            "    mean_inference_ms: 1.3444435973415343\n",
            "    mean_raw_obs_processing_ms: 0.21933794670093051\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 100.76\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 100.76\n",
            "    episode_reward_min: 9.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 17\n",
            "      - 34\n",
            "      - 10\n",
            "      - 34\n",
            "      - 9\n",
            "      - 18\n",
            "      - 38\n",
            "      - 72\n",
            "      - 35\n",
            "      - 54\n",
            "      - 18\n",
            "      - 11\n",
            "      - 22\n",
            "      - 18\n",
            "      - 49\n",
            "      - 32\n",
            "      - 15\n",
            "      - 121\n",
            "      - 18\n",
            "      - 18\n",
            "      - 80\n",
            "      - 42\n",
            "      - 28\n",
            "      - 29\n",
            "      - 37\n",
            "      - 13\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      episode_reward:\n",
            "      - 17.0\n",
            "      - 34.0\n",
            "      - 10.0\n",
            "      - 34.0\n",
            "      - 9.0\n",
            "      - 18.0\n",
            "      - 38.0\n",
            "      - 72.0\n",
            "      - 35.0\n",
            "      - 54.0\n",
            "      - 18.0\n",
            "      - 11.0\n",
            "      - 22.0\n",
            "      - 18.0\n",
            "      - 49.0\n",
            "      - 32.0\n",
            "      - 15.0\n",
            "      - 121.0\n",
            "      - 18.0\n",
            "      - 18.0\n",
            "      - 80.0\n",
            "      - 42.0\n",
            "      - 28.0\n",
            "      - 29.0\n",
            "      - 37.0\n",
            "      - 13.0\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11817737265506902\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08986564492664854\n",
            "      mean_inference_ms: 1.3444435973415343\n",
            "      mean_raw_obs_processing_ms: 0.21933794670093051\n",
            "  time_since_restore: 56.86051034927368\n",
            "  time_this_iter_s: 4.593744516372681\n",
            "  time_total_s: 56.86051034927368\n",
            "  timers:\n",
            "    learn_throughput: 4438.916\n",
            "    learn_time_ms: 7.209\n",
            "    load_throughput: 198870.541\n",
            "    load_time_ms: 0.161\n",
            "    synch_weights_time_ms: 0.056\n",
            "    training_iteration_time_ms: 20.587\n",
            "  timestamp: 1656960758\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 13000\n",
            "  training_iteration: 13\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:38 (running for 00:01:04.78)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         56.8605</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">  100.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">            100.76</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 15000\n",
            "  counters:\n",
            "    last_target_update_ts: 15000\n",
            "    num_agent_steps_sampled: 15000\n",
            "    num_agent_steps_trained: 112032\n",
            "    num_env_steps_sampled: 15000\n",
            "    num_env_steps_trained: 112032\n",
            "    num_target_updates: 29\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-48\n",
            "  done: false\n",
            "  episode_len_mean: 118.26\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 118.26\n",
            "  episode_reward_min: 11.0\n",
            "  episodes_this_iter: 8\n",
            "  episodes_total: 254\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 15000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 29.011154174804688\n",
            "          mean_q: 24.81344985961914\n",
            "          mean_td_error: 1.1696321964263916\n",
            "          min_q: 11.944540977478027\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.19737625122070312\n",
            "        - 0.15086746215820312\n",
            "        - -0.8873786926269531\n",
            "        - -0.19031715393066406\n",
            "        - 0.5603790283203125\n",
            "        - 0.6129322052001953\n",
            "        - -2.5510196685791016\n",
            "        - -0.29760169982910156\n",
            "        - -0.5994987487792969\n",
            "        - 0.6943187713623047\n",
            "        - 0.05881500244140625\n",
            "        - -0.22599411010742188\n",
            "        - -0.7578926086425781\n",
            "        - -0.3906402587890625\n",
            "        - 0.013097763061523438\n",
            "        - 0.10074806213378906\n",
            "        - 0.35545825958251953\n",
            "        - -0.0076465606689453125\n",
            "        - -0.5864677429199219\n",
            "        - 22.58130645751953\n",
            "        - -0.047245025634765625\n",
            "        - -0.07476997375488281\n",
            "        - -0.7651519775390625\n",
            "        - -0.24351119995117188\n",
            "        - 0.2784404754638672\n",
            "        - 16.074283599853516\n",
            "        - 0.6944770812988281\n",
            "        - 1.6737937927246094\n",
            "        - 0.6445369720458984\n",
            "        - -0.027479171752929688\n",
            "        - 0.5300006866455078\n",
            "        - 0.2547645568847656\n",
            "    num_agent_steps_sampled: 15000\n",
            "    num_agent_steps_trained: 112032\n",
            "    num_env_steps_sampled: 15000\n",
            "    num_env_steps_trained: 112032\n",
            "    num_target_updates: 29\n",
            "  iterations_since_restore: 15\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 15000\n",
            "  num_agent_steps_trained: 112032\n",
            "  num_env_steps_sampled: 15000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 112032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.21666666666668\n",
            "    ram_util_percent: 16.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11750610711204144\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08936818049440898\n",
            "    mean_inference_ms: 1.3342041510386151\n",
            "    mean_raw_obs_processing_ms: 0.21696089883560116\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 118.26\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 118.26\n",
            "    episode_reward_min: 11.0\n",
            "    episodes_this_iter: 8\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 18\n",
            "      - 49\n",
            "      - 32\n",
            "      - 15\n",
            "      - 121\n",
            "      - 18\n",
            "      - 18\n",
            "      - 80\n",
            "      - 42\n",
            "      - 28\n",
            "      - 29\n",
            "      - 37\n",
            "      - 13\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      episode_reward:\n",
            "      - 18.0\n",
            "      - 49.0\n",
            "      - 32.0\n",
            "      - 15.0\n",
            "      - 121.0\n",
            "      - 18.0\n",
            "      - 18.0\n",
            "      - 80.0\n",
            "      - 42.0\n",
            "      - 28.0\n",
            "      - 29.0\n",
            "      - 37.0\n",
            "      - 13.0\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11750610711204144\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08936818049440898\n",
            "      mean_inference_ms: 1.3342041510386151\n",
            "      mean_raw_obs_processing_ms: 0.21696089883560116\n",
            "  time_since_restore: 66.25374174118042\n",
            "  time_this_iter_s: 4.609807729721069\n",
            "  time_total_s: 66.25374174118042\n",
            "  timers:\n",
            "    learn_throughput: 5303.686\n",
            "    learn_time_ms: 6.034\n",
            "    load_throughput: 202440.012\n",
            "    load_time_ms: 0.158\n",
            "    synch_weights_time_ms: 0.065\n",
            "    training_iteration_time_ms: 18.605\n",
            "  timestamp: 1656960768\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 15000\n",
            "  training_iteration: 15\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:48 (running for 00:01:14.22)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         66.2537</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">  118.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            118.26</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 17000\n",
            "  counters:\n",
            "    last_target_update_ts: 17000\n",
            "    num_agent_steps_sampled: 17000\n",
            "    num_agent_steps_trained: 128032\n",
            "    num_env_steps_sampled: 17000\n",
            "    num_env_steps_trained: 128032\n",
            "    num_target_updates: 33\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-52-57\n",
            "  done: false\n",
            "  episode_len_mean: 132.77\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 132.77\n",
            "  episode_reward_min: 11.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 267\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 17000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 31.582395553588867\n",
            "          mean_q: 27.110576629638672\n",
            "          mean_td_error: 0.11363962292671204\n",
            "          min_q: 4.161185264587402\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.15491676330566406\n",
            "        - -0.49817466735839844\n",
            "        - -0.4515666961669922\n",
            "        - 0.14101600646972656\n",
            "        - -0.026113510131835938\n",
            "        - 0.23050880432128906\n",
            "        - -0.5910739898681641\n",
            "        - -0.3303394317626953\n",
            "        - -2.634737014770508\n",
            "        - -3.5928096771240234\n",
            "        - 0.4405479431152344\n",
            "        - 0.6485233306884766\n",
            "        - -0.6455173492431641\n",
            "        - 0.5608844757080078\n",
            "        - 0.5604476928710938\n",
            "        - -2.6537418365478516\n",
            "        - 21.52227020263672\n",
            "        - -0.70343017578125\n",
            "        - 0.3657684326171875\n",
            "        - -0.32067298889160156\n",
            "        - -1.038501262664795\n",
            "        - 0.12461280822753906\n",
            "        - 0.17031478881835938\n",
            "        - -2.199024200439453\n",
            "        - 0.08131027221679688\n",
            "        - -0.027158737182617188\n",
            "        - -0.06151580810546875\n",
            "        - -3.371058464050293\n",
            "        - -1.2266845703125\n",
            "        - -0.0691680908203125\n",
            "        - -0.23621559143066406\n",
            "        - -0.3773155212402344\n",
            "    num_agent_steps_sampled: 17000\n",
            "    num_agent_steps_trained: 128032\n",
            "    num_env_steps_sampled: 17000\n",
            "    num_env_steps_trained: 128032\n",
            "    num_target_updates: 33\n",
            "  iterations_since_restore: 17\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 17000\n",
            "  num_agent_steps_trained: 128032\n",
            "  num_env_steps_sampled: 17000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 128032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.60000000000001\n",
            "    ram_util_percent: 16.185714285714287\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11688144409101171\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0889146990222508\n",
            "    mean_inference_ms: 1.3256344679169874\n",
            "    mean_raw_obs_processing_ms: 0.21478571865578178\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 132.77\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 132.77\n",
            "    episode_reward_min: 11.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 11\n",
            "      - 87\n",
            "      - 106\n",
            "      - 34\n",
            "      - 101\n",
            "      - 97\n",
            "      - 75\n",
            "      - 38\n",
            "      - 75\n",
            "      - 65\n",
            "      - 50\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      episode_reward:\n",
            "      - 11.0\n",
            "      - 87.0\n",
            "      - 106.0\n",
            "      - 34.0\n",
            "      - 101.0\n",
            "      - 97.0\n",
            "      - 75.0\n",
            "      - 38.0\n",
            "      - 75.0\n",
            "      - 65.0\n",
            "      - 50.0\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11688144409101171\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.0889146990222508\n",
            "      mean_inference_ms: 1.3256344679169874\n",
            "      mean_raw_obs_processing_ms: 0.21478571865578178\n",
            "  time_since_restore: 75.47232460975647\n",
            "  time_this_iter_s: 4.541980028152466\n",
            "  time_total_s: 75.47232460975647\n",
            "  timers:\n",
            "    learn_throughput: 5423.969\n",
            "    learn_time_ms: 5.9\n",
            "    load_throughput: 206425.297\n",
            "    load_time_ms: 0.155\n",
            "    synch_weights_time_ms: 0.055\n",
            "    training_iteration_time_ms: 18.023\n",
            "  timestamp: 1656960777\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 17000\n",
            "  training_iteration: 17\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:52:57 (running for 00:01:23.59)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         75.4723</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">  132.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            132.77</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 19000\n",
            "  counters:\n",
            "    last_target_update_ts: 19000\n",
            "    num_agent_steps_sampled: 19000\n",
            "    num_agent_steps_trained: 144032\n",
            "    num_env_steps_sampled: 19000\n",
            "    num_env_steps_trained: 144032\n",
            "    num_target_updates: 37\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-53-06\n",
            "  done: false\n",
            "  episode_len_mean: 144.58\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 144.58\n",
            "  episode_reward_min: 15.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 278\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 19000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 35.202327728271484\n",
            "          mean_q: 28.197612762451172\n",
            "          mean_td_error: 1.0561689138412476\n",
            "          min_q: -3.730813980102539\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.2898368835449219\n",
            "        - 0.27782440185546875\n",
            "        - 0.44412994384765625\n",
            "        - 0.2397613525390625\n",
            "        - 0.16108322143554688\n",
            "        - 0.31256675720214844\n",
            "        - -0.11612701416015625\n",
            "        - 4.790597915649414\n",
            "        - -0.10149383544921875\n",
            "        - 0.1852741241455078\n",
            "        - 0.15090560913085938\n",
            "        - -0.32134056091308594\n",
            "        - -0.9035835266113281\n",
            "        - -0.02597808837890625\n",
            "        - 0.1465911865234375\n",
            "        - 4.428655624389648\n",
            "        - -0.3990631103515625\n",
            "        - 0.4778594970703125\n",
            "        - 0.05293464660644531\n",
            "        - 0.2584953308105469\n",
            "        - 2.836667776107788\n",
            "        - 0.3108978271484375\n",
            "        - 2.182514190673828\n",
            "        - -0.19329452514648438\n",
            "        - 0.263916015625\n",
            "        - -0.10498046875\n",
            "        - -4.730813980102539\n",
            "        - 23.135934829711914\n",
            "        - -0.4391593933105469\n",
            "        - 0.02773284912109375\n",
            "        - -0.06906890869140625\n",
            "        - 0.22813034057617188\n",
            "    num_agent_steps_sampled: 19000\n",
            "    num_agent_steps_trained: 144032\n",
            "    num_env_steps_sampled: 19000\n",
            "    num_env_steps_trained: 144032\n",
            "    num_target_updates: 37\n",
            "  iterations_since_restore: 19\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 19000\n",
            "  num_agent_steps_trained: 144032\n",
            "  num_env_steps_sampled: 19000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 144032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.28571428571429\n",
            "    ram_util_percent: 16.2\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11651655333491494\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08870060219036019\n",
            "    mean_inference_ms: 1.3208436937677397\n",
            "    mean_raw_obs_processing_ms: 0.21326864452088848\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 144.58\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 144.58\n",
            "    episode_reward_min: 15.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 73\n",
            "      - 42\n",
            "      - 21\n",
            "      - 35\n",
            "      - 200\n",
            "      - 153\n",
            "      - 49\n",
            "      - 189\n",
            "      - 15\n",
            "      - 176\n",
            "      - 81\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 73.0\n",
            "      - 42.0\n",
            "      - 21.0\n",
            "      - 35.0\n",
            "      - 200.0\n",
            "      - 153.0\n",
            "      - 49.0\n",
            "      - 189.0\n",
            "      - 15.0\n",
            "      - 176.0\n",
            "      - 81.0\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11651655333491494\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08870060219036019\n",
            "      mean_inference_ms: 1.3208436937677397\n",
            "      mean_raw_obs_processing_ms: 0.21326864452088848\n",
            "  time_since_restore: 84.53884935379028\n",
            "  time_this_iter_s: 4.509071588516235\n",
            "  time_total_s: 84.53884935379028\n",
            "  timers:\n",
            "    learn_throughput: 5075.123\n",
            "    learn_time_ms: 6.305\n",
            "    load_throughput: 218062.921\n",
            "    load_time_ms: 0.147\n",
            "    synch_weights_time_ms: 0.057\n",
            "    training_iteration_time_ms: 18.681\n",
            "  timestamp: 1656960786\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 19000\n",
            "  training_iteration: 19\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:53:06 (running for 00:01:32.61)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         84.5388</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">  144.58</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">            144.58</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 21000\n",
            "  counters:\n",
            "    last_target_update_ts: 21000\n",
            "    num_agent_steps_sampled: 21000\n",
            "    num_agent_steps_trained: 160032\n",
            "    num_env_steps_sampled: 21000\n",
            "    num_env_steps_trained: 160032\n",
            "    num_target_updates: 41\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-53-15\n",
            "  done: false\n",
            "  episode_len_mean: 154.35\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 154.35\n",
            "  episode_reward_min: 39.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 289\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 21000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 37.90911865234375\n",
            "          mean_q: 30.457164764404297\n",
            "          mean_td_error: 1.3103725910186768\n",
            "          min_q: 13.515413284301758\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.6071968078613281\n",
            "        - 0.6922130584716797\n",
            "        - -0.10303115844726562\n",
            "        - 1.4599838256835938\n",
            "        - -0.08756637573242188\n",
            "        - -0.4326324462890625\n",
            "        - 24.744768142700195\n",
            "        - 0.21438980102539062\n",
            "        - -0.5135517120361328\n",
            "        - 0.02475738525390625\n",
            "        - 0.1617584228515625\n",
            "        - -0.1090545654296875\n",
            "        - -4.488010406494141\n",
            "        - 0.30588531494140625\n",
            "        - 0.2752418518066406\n",
            "        - -0.14936256408691406\n",
            "        - 2.199657440185547\n",
            "        - 0.8520965576171875\n",
            "        - -0.40362548828125\n",
            "        - -0.3985137939453125\n",
            "        - -0.04121208190917969\n",
            "        - -1.0288314819335938\n",
            "        - -4.249290466308594\n",
            "        - -0.17900848388671875\n",
            "        - 25.8580379486084\n",
            "        - 0.11128044128417969\n",
            "        - -0.4154624938964844\n",
            "        - -0.13459014892578125\n",
            "        - -0.22676849365234375\n",
            "        - -0.8615570068359375\n",
            "        - -0.2995185852050781\n",
            "        - -0.23936080932617188\n",
            "    num_agent_steps_sampled: 21000\n",
            "    num_agent_steps_trained: 160032\n",
            "    num_env_steps_sampled: 21000\n",
            "    num_env_steps_trained: 160032\n",
            "    num_target_updates: 41\n",
            "  iterations_since_restore: 21\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 21000\n",
            "  num_agent_steps_trained: 160032\n",
            "  num_env_steps_sampled: 21000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 160032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.72857142857143\n",
            "    ram_util_percent: 16.3\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11623988322009227\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08855224423332116\n",
            "    mean_inference_ms: 1.3178403526559053\n",
            "    mean_raw_obs_processing_ms: 0.2120853042687949\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 154.35\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 154.35\n",
            "    episode_reward_min: 39.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 173\n",
            "      - 200\n",
            "      - 130\n",
            "      - 160\n",
            "      - 182\n",
            "      - 200\n",
            "      - 60\n",
            "      - 71\n",
            "      - 77\n",
            "      - 140\n",
            "      - 140\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      episode_reward:\n",
            "      - 173.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 160.0\n",
            "      - 182.0\n",
            "      - 200.0\n",
            "      - 60.0\n",
            "      - 71.0\n",
            "      - 77.0\n",
            "      - 140.0\n",
            "      - 140.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11623988322009227\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08855224423332116\n",
            "      mean_inference_ms: 1.3178403526559053\n",
            "      mean_raw_obs_processing_ms: 0.2120853042687949\n",
            "  time_since_restore: 93.54653573036194\n",
            "  time_this_iter_s: 4.418795585632324\n",
            "  time_total_s: 93.54653573036194\n",
            "  timers:\n",
            "    learn_throughput: 5671.811\n",
            "    learn_time_ms: 5.642\n",
            "    load_throughput: 200026.42\n",
            "    load_time_ms: 0.16\n",
            "    synch_weights_time_ms: 0.049\n",
            "    training_iteration_time_ms: 16.916\n",
            "  timestamp: 1656960795\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 21000\n",
            "  training_iteration: 21\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:53:15 (running for 00:01:41.67)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         93.5465</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">  154.35</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  39</td><td style=\"text-align: right;\">            154.35</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 23000\n",
            "  counters:\n",
            "    last_target_update_ts: 23000\n",
            "    num_agent_steps_sampled: 23000\n",
            "    num_agent_steps_trained: 176032\n",
            "    num_env_steps_sampled: 23000\n",
            "    num_env_steps_trained: 176032\n",
            "    num_target_updates: 45\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-53-24\n",
            "  done: false\n",
            "  episode_len_mean: 159.31\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 159.31\n",
            "  episode_reward_min: 39.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 300\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 23000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 39.60074996948242\n",
            "          mean_q: 33.643402099609375\n",
            "          mean_td_error: 1.694856882095337\n",
            "          min_q: 4.889168739318848\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.7780628204345703\n",
            "        - -0.5426025390625\n",
            "        - -0.200469970703125\n",
            "        - -2.5842628479003906\n",
            "        - -0.3079414367675781\n",
            "        - -0.3102836608886719\n",
            "        - -0.20349884033203125\n",
            "        - -0.3880157470703125\n",
            "        - -0.3012847900390625\n",
            "        - -0.062591552734375\n",
            "        - -0.08677291870117188\n",
            "        - -3.143566131591797\n",
            "        - -1.0815200805664062\n",
            "        - -0.11902618408203125\n",
            "        - 1.9062025547027588\n",
            "        - -0.17536163330078125\n",
            "        - -0.24379730224609375\n",
            "        - -0.24068450927734375\n",
            "        - -0.7216606140136719\n",
            "        - 0.3449440002441406\n",
            "        - 25.971158981323242\n",
            "        - -0.14108657836914062\n",
            "        - 13.847555160522461\n",
            "        - -0.09585952758789062\n",
            "        - -0.3860130310058594\n",
            "        - 0.1519794464111328\n",
            "        - -0.3498954772949219\n",
            "        - 0.17223358154296875\n",
            "        - -0.5362129211425781\n",
            "        - -0.345947265625\n",
            "        - -0.3792839050292969\n",
            "        - 25.567047119140625\n",
            "    num_agent_steps_sampled: 23000\n",
            "    num_agent_steps_trained: 176032\n",
            "    num_env_steps_sampled: 23000\n",
            "    num_env_steps_trained: 176032\n",
            "    num_target_updates: 45\n",
            "  iterations_since_restore: 23\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 23000\n",
            "  num_agent_steps_trained: 176032\n",
            "  num_env_steps_sampled: 23000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 176032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.01428571428572\n",
            "    ram_util_percent: 16.3\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11599399624003354\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0883872099811408\n",
            "    mean_inference_ms: 1.3163829037485448\n",
            "    mean_raw_obs_processing_ms: 0.21122806275165407\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 159.31\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 159.31\n",
            "    episode_reward_min: 39.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 132\n",
            "      - 200\n",
            "      - 122\n",
            "      - 200\n",
            "      - 200\n",
            "      - 110\n",
            "      - 200\n",
            "      - 115\n",
            "      - 93\n",
            "      - 145\n",
            "      - 138\n",
            "      - 90\n",
            "      - 142\n",
            "      - 84\n",
            "      - 39\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 122.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 110.0\n",
            "      - 200.0\n",
            "      - 115.0\n",
            "      - 93.0\n",
            "      - 145.0\n",
            "      - 138.0\n",
            "      - 90.0\n",
            "      - 142.0\n",
            "      - 84.0\n",
            "      - 39.0\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11599399624003354\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.0883872099811408\n",
            "      mean_inference_ms: 1.3163829037485448\n",
            "      mean_raw_obs_processing_ms: 0.21122806275165407\n",
            "  time_since_restore: 102.62579870223999\n",
            "  time_this_iter_s: 4.53131365776062\n",
            "  time_total_s: 102.62579870223999\n",
            "  timers:\n",
            "    learn_throughput: 4821.056\n",
            "    learn_time_ms: 6.638\n",
            "    load_throughput: 229746.197\n",
            "    load_time_ms: 0.139\n",
            "    synch_weights_time_ms: 0.051\n",
            "    training_iteration_time_ms: 18.885\n",
            "  timestamp: 1656960804\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 23000\n",
            "  training_iteration: 23\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:53:24 (running for 00:01:50.88)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         102.626</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">  159.31</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  39</td><td style=\"text-align: right;\">            159.31</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 25000\n",
            "  counters:\n",
            "    last_target_update_ts: 25000\n",
            "    num_agent_steps_sampled: 25000\n",
            "    num_agent_steps_trained: 192032\n",
            "    num_env_steps_sampled: 25000\n",
            "    num_env_steps_trained: 192032\n",
            "    num_target_updates: 49\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-53-33\n",
            "  done: false\n",
            "  episode_len_mean: 159.57\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 159.57\n",
            "  episode_reward_min: 52.0\n",
            "  episodes_this_iter: 9\n",
            "  episodes_total: 315\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 25000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 42.30274200439453\n",
            "          mean_q: 36.13924789428711\n",
            "          mean_td_error: 4.698179244995117\n",
            "          min_q: 19.550979614257812\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 35.91712188720703\n",
            "        - -3.464862823486328\n",
            "        - 0.4709453582763672\n",
            "        - 0.08381271362304688\n",
            "        - 0.5381221771240234\n",
            "        - 18.550979614257812\n",
            "        - 0.33463478088378906\n",
            "        - -0.1026458740234375\n",
            "        - -0.11154556274414062\n",
            "        - 0.010707855224609375\n",
            "        - -0.14116668701171875\n",
            "        - 0.050495147705078125\n",
            "        - 0.6078147888183594\n",
            "        - 0.5259323120117188\n",
            "        - 25.780031204223633\n",
            "        - 34.6904182434082\n",
            "        - -0.9424896240234375\n",
            "        - 0.06002044677734375\n",
            "        - -0.14495086669921875\n",
            "        - -1.6605110168457031\n",
            "        - 25.780031204223633\n",
            "        - 12.396309852600098\n",
            "        - -0.010555267333984375\n",
            "        - 0.09950637817382812\n",
            "        - 0.32013702392578125\n",
            "        - 0.06866073608398438\n",
            "        - -0.10763168334960938\n",
            "        - 0.28316497802734375\n",
            "        - -0.2762603759765625\n",
            "        - 0.062137603759765625\n",
            "        - 0.2967338562011719\n",
            "        - 0.3766441345214844\n",
            "    num_agent_steps_sampled: 25000\n",
            "    num_agent_steps_trained: 192032\n",
            "    num_env_steps_sampled: 25000\n",
            "    num_env_steps_trained: 192032\n",
            "    num_target_updates: 49\n",
            "  iterations_since_restore: 25\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 25000\n",
            "  num_agent_steps_trained: 192032\n",
            "  num_env_steps_sampled: 25000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 192032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.31666666666668\n",
            "    ram_util_percent: 16.400000000000002\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11558346422198702\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08813474757013381\n",
            "    mean_inference_ms: 1.315018718329321\n",
            "    mean_raw_obs_processing_ms: 0.21023934275483783\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 159.57\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 159.57\n",
            "    episode_reward_min: 52.0\n",
            "    episodes_this_iter: 9\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 87\n",
            "      - 82\n",
            "      - 160\n",
            "      - 148\n",
            "      - 200\n",
            "      - 165\n",
            "      - 132\n",
            "      - 126\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 107\n",
            "      - 200\n",
            "      - 177\n",
            "      - 134\n",
            "      - 120\n",
            "      - 190\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      episode_reward:\n",
            "      - 87.0\n",
            "      - 82.0\n",
            "      - 160.0\n",
            "      - 148.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 132.0\n",
            "      - 126.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 177.0\n",
            "      - 134.0\n",
            "      - 120.0\n",
            "      - 190.0\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11558346422198702\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08813474757013381\n",
            "      mean_inference_ms: 1.315018718329321\n",
            "      mean_raw_obs_processing_ms: 0.21023934275483783\n",
            "  time_since_restore: 111.53886318206787\n",
            "  time_this_iter_s: 4.420464992523193\n",
            "  time_total_s: 111.53886318206787\n",
            "  timers:\n",
            "    learn_throughput: 5917.811\n",
            "    learn_time_ms: 5.407\n",
            "    load_throughput: 230456.264\n",
            "    load_time_ms: 0.139\n",
            "    synch_weights_time_ms: 0.051\n",
            "    training_iteration_time_ms: 16.582\n",
            "  timestamp: 1656960813\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 25000\n",
            "  training_iteration: 25\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:53:33 (running for 00:01:59.76)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         111.539</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">  159.57</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  52</td><td style=\"text-align: right;\">            159.57</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 27000\n",
            "  counters:\n",
            "    last_target_update_ts: 27000\n",
            "    num_agent_steps_sampled: 27000\n",
            "    num_agent_steps_trained: 208032\n",
            "    num_env_steps_sampled: 27000\n",
            "    num_env_steps_trained: 208032\n",
            "    num_target_updates: 53\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-53-42\n",
            "  done: false\n",
            "  episode_len_mean: 153.94\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 153.94\n",
            "  episode_reward_min: 52.0\n",
            "  episodes_this_iter: 9\n",
            "  episodes_total: 332\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 27000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 44.84622573852539\n",
            "          mean_q: 36.318397521972656\n",
            "          mean_td_error: 1.7272822856903076\n",
            "          min_q: 0.2745981216430664\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.3605003356933594\n",
            "        - 0.0388641357421875\n",
            "        - -0.0635223388671875\n",
            "        - 0.6129493713378906\n",
            "        - 0.11231231689453125\n",
            "        - 0.06626129150390625\n",
            "        - 25.02167320251465\n",
            "        - 0.10073089599609375\n",
            "        - -0.14089584350585938\n",
            "        - -0.2244110107421875\n",
            "        - -0.0410614013671875\n",
            "        - -0.0168609619140625\n",
            "        - 22.001413345336914\n",
            "        - 0.17978668212890625\n",
            "        - -0.059963226318359375\n",
            "        - -3.111469268798828\n",
            "        - 2.814357280731201\n",
            "        - 0.022357940673828125\n",
            "        - 0.09981918334960938\n",
            "        - 7.391091346740723\n",
            "        - 0.4889945983886719\n",
            "        - 0.12633132934570312\n",
            "        - -0.22831344604492188\n",
            "        - -0.3108673095703125\n",
            "        - -0.0532073974609375\n",
            "        - 2.1169939041137695\n",
            "        - -0.0561370849609375\n",
            "        - -0.2651329040527344\n",
            "        - -0.6711406707763672\n",
            "        - -0.02463531494140625\n",
            "        - 0.14449310302734375\n",
            "        - -0.43727874755859375\n",
            "    num_agent_steps_sampled: 27000\n",
            "    num_agent_steps_trained: 208032\n",
            "    num_env_steps_sampled: 27000\n",
            "    num_env_steps_trained: 208032\n",
            "    num_target_updates: 53\n",
            "  iterations_since_restore: 27\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 27000\n",
            "  num_agent_steps_trained: 208032\n",
            "  num_env_steps_sampled: 27000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 208032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.13333333333334\n",
            "    ram_util_percent: 16.400000000000002\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1151770759819409\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08786318934792794\n",
            "    mean_inference_ms: 1.3143734979336117\n",
            "    mean_raw_obs_processing_ms: 0.20929227730134392\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 153.94\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 153.94\n",
            "    episode_reward_min: 52.0\n",
            "    episodes_this_iter: 9\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 125\n",
            "      - 157\n",
            "      - 185\n",
            "      - 142\n",
            "      - 124\n",
            "      - 184\n",
            "      - 52\n",
            "      - 156\n",
            "      - 160\n",
            "      - 194\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      episode_reward:\n",
            "      - 125.0\n",
            "      - 157.0\n",
            "      - 185.0\n",
            "      - 142.0\n",
            "      - 124.0\n",
            "      - 184.0\n",
            "      - 52.0\n",
            "      - 156.0\n",
            "      - 160.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1151770759819409\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08786318934792794\n",
            "      mean_inference_ms: 1.3143734979336117\n",
            "      mean_raw_obs_processing_ms: 0.20929227730134392\n",
            "  time_since_restore: 120.54612398147583\n",
            "  time_this_iter_s: 4.465297698974609\n",
            "  time_total_s: 120.54612398147583\n",
            "  timers:\n",
            "    learn_throughput: 5080.772\n",
            "    learn_time_ms: 6.298\n",
            "    load_throughput: 214439.572\n",
            "    load_time_ms: 0.149\n",
            "    synch_weights_time_ms: 0.057\n",
            "    training_iteration_time_ms: 18.619\n",
            "  timestamp: 1656960822\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 27000\n",
            "  training_iteration: 27\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:53:42 (running for 00:02:08.82)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         120.546</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">  153.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  52</td><td style=\"text-align: right;\">            153.94</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 29000\n",
            "  counters:\n",
            "    last_target_update_ts: 29000\n",
            "    num_agent_steps_sampled: 29000\n",
            "    num_agent_steps_trained: 224032\n",
            "    num_env_steps_sampled: 29000\n",
            "    num_env_steps_trained: 224032\n",
            "    num_target_updates: 57\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-53-51\n",
            "  done: false\n",
            "  episode_len_mean: 158.19\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 158.19\n",
            "  episode_reward_min: 97.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 342\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 29000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 47.73762130737305\n",
            "          mean_q: 38.99736404418945\n",
            "          mean_td_error: 2.9365503787994385\n",
            "          min_q: -7.770689010620117\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.2131195068359375\n",
            "        - 0.2677497863769531\n",
            "        - 0.37981414794921875\n",
            "        - -0.15559768676757812\n",
            "        - 0.48099517822265625\n",
            "        - -0.11899566650390625\n",
            "        - 0.5744056701660156\n",
            "        - -0.0415496826171875\n",
            "        - 0.014003753662109375\n",
            "        - 0.3589897155761719\n",
            "        - 0.29558563232421875\n",
            "        - -0.046966552734375\n",
            "        - 0.17128753662109375\n",
            "        - 0.027294158935546875\n",
            "        - 0.4164886474609375\n",
            "        - -0.3988151550292969\n",
            "        - -8.770689010620117\n",
            "        - -0.11392593383789062\n",
            "        - 32.84314727783203\n",
            "        - 0.5245132446289062\n",
            "        - -0.3330650329589844\n",
            "        - -0.021511077880859375\n",
            "        - -0.6811599731445312\n",
            "        - -0.22972488403320312\n",
            "        - -0.09092521667480469\n",
            "        - -1.7071518898010254\n",
            "        - 38.36822509765625\n",
            "        - 0.1302337646484375\n",
            "        - -0.24080657958984375\n",
            "        - -0.3983879089355469\n",
            "        - -0.17074203491210938\n",
            "        - 32.850013732910156\n",
            "    num_agent_steps_sampled: 29000\n",
            "    num_agent_steps_trained: 224032\n",
            "    num_env_steps_sampled: 29000\n",
            "    num_env_steps_trained: 224032\n",
            "    num_target_updates: 57\n",
            "  iterations_since_restore: 29\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 29000\n",
            "  num_agent_steps_trained: 224032\n",
            "  num_env_steps_sampled: 29000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 224032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.05000000000001\n",
            "    ram_util_percent: 16.5\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1149032212217007\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0876773724627039\n",
            "    mean_inference_ms: 1.313520430708214\n",
            "    mean_raw_obs_processing_ms: 0.2087696912888089\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 158.19\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 158.19\n",
            "    episode_reward_min: 97.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 146\n",
            "      - 97\n",
            "      - 168\n",
            "      - 200\n",
            "      - 157\n",
            "      - 110\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 97.0\n",
            "      - 168.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 110.0\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1149032212217007\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.0876773724627039\n",
            "      mean_inference_ms: 1.313520430708214\n",
            "      mean_raw_obs_processing_ms: 0.2087696912888089\n",
            "  time_since_restore: 129.602632522583\n",
            "  time_this_iter_s: 4.536273241043091\n",
            "  time_total_s: 129.602632522583\n",
            "  timers:\n",
            "    learn_throughput: 5440.789\n",
            "    learn_time_ms: 5.882\n",
            "    load_throughput: 219166.767\n",
            "    load_time_ms: 0.146\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 17.926\n",
            "  timestamp: 1656960831\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 29000\n",
            "  training_iteration: 29\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:53:52 (running for 00:02:18.00)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         129.603</td><td style=\"text-align: right;\">29000</td><td style=\"text-align: right;\">  158.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            158.19</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 31000\n",
            "  counters:\n",
            "    last_target_update_ts: 31000\n",
            "    num_agent_steps_sampled: 31000\n",
            "    num_agent_steps_trained: 240032\n",
            "    num_env_steps_sampled: 31000\n",
            "    num_env_steps_trained: 240032\n",
            "    num_target_updates: 61\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-01\n",
            "  done: false\n",
            "  episode_len_mean: 161.41\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 161.41\n",
            "  episode_reward_min: 102.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 352\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 31000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 50.00684356689453\n",
            "          mean_q: 41.174503326416016\n",
            "          mean_td_error: -0.8141061663627625\n",
            "          min_q: -8.01601791381836\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.21786117553710938\n",
            "        - -0.13845062255859375\n",
            "        - -2.798015594482422\n",
            "        - -0.27712249755859375\n",
            "        - 0.026432037353515625\n",
            "        - -0.017925262451171875\n",
            "        - 0.021427154541015625\n",
            "        - 0.3940391540527344\n",
            "        - -0.2954597473144531\n",
            "        - -1.2789897918701172\n",
            "        - 0.30414581298828125\n",
            "        - -8.266267776489258\n",
            "        - 0.05867767333984375\n",
            "        - -0.08249664306640625\n",
            "        - 0.03375244140625\n",
            "        - -0.04653167724609375\n",
            "        - 0.3416404724121094\n",
            "        - -1.738412857055664\n",
            "        - -0.4136772155761719\n",
            "        - -0.044002532958984375\n",
            "        - -0.2425079345703125\n",
            "        - 0.06301498413085938\n",
            "        - 0.045848846435546875\n",
            "        - -0.5857162475585938\n",
            "        - -1.1440505981445312\n",
            "        - 0.23726654052734375\n",
            "        - -0.5141754150390625\n",
            "        - -0.25086212158203125\n",
            "        - -9.01601791381836\n",
            "        - 0.00453948974609375\n",
            "        - -0.06175994873046875\n",
            "        - -0.15187835693359375\n",
            "    num_agent_steps_sampled: 31000\n",
            "    num_agent_steps_trained: 240032\n",
            "    num_env_steps_sampled: 31000\n",
            "    num_env_steps_trained: 240032\n",
            "    num_target_updates: 61\n",
            "  iterations_since_restore: 31\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 31000\n",
            "  num_agent_steps_trained: 240032\n",
            "  num_env_steps_sampled: 31000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 240032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.48333333333333\n",
            "    ram_util_percent: 16.53333333333333\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11462852941317024\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08749654945265775\n",
            "    mean_inference_ms: 1.3123265215234639\n",
            "    mean_raw_obs_processing_ms: 0.20831163473553463\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 161.41\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 161.41\n",
            "    episode_reward_min: 102.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 136\n",
            "      - 114\n",
            "      - 137\n",
            "      - 183\n",
            "      - 124\n",
            "      - 138\n",
            "      - 128\n",
            "      - 194\n",
            "      - 200\n",
            "      - 144\n",
            "      - 184\n",
            "      - 200\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 136.0\n",
            "      - 114.0\n",
            "      - 137.0\n",
            "      - 183.0\n",
            "      - 124.0\n",
            "      - 138.0\n",
            "      - 128.0\n",
            "      - 194.0\n",
            "      - 200.0\n",
            "      - 144.0\n",
            "      - 184.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11462852941317024\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08749654945265775\n",
            "      mean_inference_ms: 1.3123265215234639\n",
            "      mean_raw_obs_processing_ms: 0.20831163473553463\n",
            "  time_since_restore: 138.74140763282776\n",
            "  time_this_iter_s: 4.638173341751099\n",
            "  time_total_s: 138.74140763282776\n",
            "  timers:\n",
            "    learn_throughput: 4307.843\n",
            "    learn_time_ms: 7.428\n",
            "    load_throughput: 214063.362\n",
            "    load_time_ms: 0.149\n",
            "    synch_weights_time_ms: 0.056\n",
            "    training_iteration_time_ms: 21.038\n",
            "  timestamp: 1656960841\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 31000\n",
            "  training_iteration: 31\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:01 (running for 00:02:27.12)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         138.741</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">  161.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 102</td><td style=\"text-align: right;\">            161.41</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 33000\n",
            "  counters:\n",
            "    last_target_update_ts: 33000\n",
            "    num_agent_steps_sampled: 33000\n",
            "    num_agent_steps_trained: 256032\n",
            "    num_env_steps_sampled: 33000\n",
            "    num_env_steps_trained: 256032\n",
            "    num_target_updates: 65\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-10\n",
            "  done: false\n",
            "  episode_len_mean: 162.58\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 162.58\n",
            "  episode_reward_min: 100.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 364\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 33000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 52.00952911376953\n",
            "          mean_q: 45.47640609741211\n",
            "          mean_td_error: 7.43696928024292\n",
            "          min_q: 1.1818262338638306\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.6721153259277344\n",
            "        - 0.4169120788574219\n",
            "        - -0.004955291748046875\n",
            "        - 0.18182623386383057\n",
            "        - 0.14584732055664062\n",
            "        - -0.00751495361328125\n",
            "        - 46.04534149169922\n",
            "        - -0.24030303955078125\n",
            "        - 34.119083404541016\n",
            "        - 0.13618087768554688\n",
            "        - 0.10251998901367188\n",
            "        - -0.5711936950683594\n",
            "        - -0.2827568054199219\n",
            "        - -3.85107421875\n",
            "        - -0.13289642333984375\n",
            "        - 0.7308425903320312\n",
            "        - 0.3287239074707031\n",
            "        - -0.052120208740234375\n",
            "        - 0.4261322021484375\n",
            "        - 39.6384162902832\n",
            "        - 0.5933456420898438\n",
            "        - 0.16182708740234375\n",
            "        - -0.6587791442871094\n",
            "        - 0.7715110778808594\n",
            "        - -0.23543167114257812\n",
            "        - -0.24779129028320312\n",
            "        - -0.5979957580566406\n",
            "        - 46.414005279541016\n",
            "        - 0.4384040832519531\n",
            "        - -0.37708282470703125\n",
            "        - 40.69456481933594\n",
            "        - 33.225318908691406\n",
            "    num_agent_steps_sampled: 33000\n",
            "    num_agent_steps_trained: 256032\n",
            "    num_env_steps_sampled: 33000\n",
            "    num_env_steps_trained: 256032\n",
            "    num_target_updates: 65\n",
            "  iterations_since_restore: 33\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 33000\n",
            "  num_agent_steps_trained: 256032\n",
            "  num_env_steps_sampled: 33000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 256032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.83333333333333\n",
            "    ram_util_percent: 16.599999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11426764179901966\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08726341952494376\n",
            "    mean_inference_ms: 1.310461059671114\n",
            "    mean_raw_obs_processing_ms: 0.20777988974652156\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 162.58\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 162.58\n",
            "    episode_reward_min: 100.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 103\n",
            "      - 109\n",
            "      - 107\n",
            "      - 106\n",
            "      - 150\n",
            "      - 169\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 178\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      episode_reward:\n",
            "      - 103.0\n",
            "      - 109.0\n",
            "      - 107.0\n",
            "      - 106.0\n",
            "      - 150.0\n",
            "      - 169.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 178.0\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11426764179901966\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08726341952494376\n",
            "      mean_inference_ms: 1.310461059671114\n",
            "      mean_raw_obs_processing_ms: 0.20777988974652156\n",
            "  time_since_restore: 147.8168957233429\n",
            "  time_this_iter_s: 4.623112678527832\n",
            "  time_total_s: 147.8168957233429\n",
            "  timers:\n",
            "    learn_throughput: 5328.955\n",
            "    learn_time_ms: 6.005\n",
            "    load_throughput: 194096.497\n",
            "    load_time_ms: 0.165\n",
            "    synch_weights_time_ms: 0.056\n",
            "    training_iteration_time_ms: 18.357\n",
            "  timestamp: 1656960850\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 33000\n",
            "  training_iteration: 33\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:10 (running for 00:02:36.25)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         147.817</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  162.58</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            162.58</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 35000\n",
            "  counters:\n",
            "    last_target_update_ts: 35000\n",
            "    num_agent_steps_sampled: 35000\n",
            "    num_agent_steps_trained: 272032\n",
            "    num_env_steps_sampled: 35000\n",
            "    num_env_steps_trained: 272032\n",
            "    num_target_updates: 69\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-19\n",
            "  done: false\n",
            "  episode_len_mean: 166.38\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 166.38\n",
            "  episode_reward_min: 100.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 375\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 35000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 53.387062072753906\n",
            "          mean_q: 45.66093063354492\n",
            "          mean_td_error: 3.521310806274414\n",
            "          min_q: -2.7340445518493652\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 4.175762176513672\n",
            "        - 44.3592529296875\n",
            "        - 0.4471473693847656\n",
            "        - -0.18265914916992188\n",
            "        - 0.4166717529296875\n",
            "        - -1.9221153259277344\n",
            "        - 0.142059326171875\n",
            "        - -0.5789794921875\n",
            "        - 0.2823944091796875\n",
            "        - -0.8453636169433594\n",
            "        - -0.10577392578125\n",
            "        - -0.5765304565429688\n",
            "        - 0.13931655883789062\n",
            "        - -0.1004486083984375\n",
            "        - 1.1139068603515625\n",
            "        - 33.710880279541016\n",
            "        - 36.215423583984375\n",
            "        - 0.412384033203125\n",
            "        - 0.4361686706542969\n",
            "        - 0.345489501953125\n",
            "        - -1.0011749267578125\n",
            "        - -0.06396102905273438\n",
            "        - -0.7020072937011719\n",
            "        - 0.049571990966796875\n",
            "        - 0.4998931884765625\n",
            "        - 0.28974151611328125\n",
            "        - -0.016574859619140625\n",
            "        - 0.3672637939453125\n",
            "        - -3.7340445518493652\n",
            "        - 0.3024482727050781\n",
            "        - -0.08277130126953125\n",
            "        - -1.1114311218261719\n",
            "    num_agent_steps_sampled: 35000\n",
            "    num_agent_steps_trained: 272032\n",
            "    num_env_steps_sampled: 35000\n",
            "    num_env_steps_trained: 272032\n",
            "    num_target_updates: 69\n",
            "  iterations_since_restore: 35\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 35000\n",
            "  num_agent_steps_trained: 272032\n",
            "  num_env_steps_sampled: 35000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 272032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 64.68571428571428\n",
            "    ram_util_percent: 16.671428571428574\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11394826736748527\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08706127096182101\n",
            "    mean_inference_ms: 1.3086211008694226\n",
            "    mean_raw_obs_processing_ms: 0.20732166662079152\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 166.38\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 166.38\n",
            "    episode_reward_min: 100.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 165\n",
            "      - 200\n",
            "      - 200\n",
            "      - 166\n",
            "      - 199\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 200\n",
            "      - 165\n",
            "      - 175\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 165.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 166.0\n",
            "      - 199.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 200.0\n",
            "      - 165.0\n",
            "      - 175.0\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11394826736748527\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08706127096182101\n",
            "      mean_inference_ms: 1.3086211008694226\n",
            "      mean_raw_obs_processing_ms: 0.20732166662079152\n",
            "  time_since_restore: 157.16484689712524\n",
            "  time_this_iter_s: 4.951033592224121\n",
            "  time_total_s: 157.16484689712524\n",
            "  timers:\n",
            "    learn_throughput: 5453.633\n",
            "    learn_time_ms: 5.868\n",
            "    load_throughput: 211366.501\n",
            "    load_time_ms: 0.151\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 18.108\n",
            "  timestamp: 1656960859\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 35000\n",
            "  training_iteration: 35\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:19 (running for 00:02:45.72)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         157.165</td><td style=\"text-align: right;\">35000</td><td style=\"text-align: right;\">  166.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            166.38</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 37000\n",
            "  counters:\n",
            "    last_target_update_ts: 37000\n",
            "    num_agent_steps_sampled: 37000\n",
            "    num_agent_steps_trained: 288032\n",
            "    num_env_steps_sampled: 37000\n",
            "    num_env_steps_trained: 288032\n",
            "    num_target_updates: 73\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-28\n",
            "  done: false\n",
            "  episode_len_mean: 166.06\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 166.06\n",
            "  episode_reward_min: 100.0\n",
            "  episodes_this_iter: 6\n",
            "  episodes_total: 386\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 37000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 55.34458541870117\n",
            "          mean_q: 43.9482307434082\n",
            "          mean_td_error: 0.857223391532898\n",
            "          min_q: 1.1315019130706787\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.409515380859375\n",
            "        - 0.3212394714355469\n",
            "        - 0.9697036743164062\n",
            "        - 0.0196533203125\n",
            "        - 0.19067764282226562\n",
            "        - -0.043506622314453125\n",
            "        - -2.7826805114746094\n",
            "        - 0.19353485107421875\n",
            "        - -0.1339111328125\n",
            "        - 0.3107452392578125\n",
            "        - 0.2513694763183594\n",
            "        - 0.10818099975585938\n",
            "        - -0.5218467712402344\n",
            "        - 0.11757278442382812\n",
            "        - 32.76704406738281\n",
            "        - 0.06893539428710938\n",
            "        - 0.17770767211914062\n",
            "        - -0.7262153625488281\n",
            "        - 0.09838485717773438\n",
            "        - -0.14918899536132812\n",
            "        - -2.3718185424804688\n",
            "        - -11.813081741333008\n",
            "        - 0.0324859619140625\n",
            "        - 0.24612808227539062\n",
            "        - 0.6072921752929688\n",
            "        - 11.998875617980957\n",
            "        - -0.34037017822265625\n",
            "        - 0.1315019130706787\n",
            "        - 0.44972991943359375\n",
            "        - -0.22650527954101562\n",
            "        - -2.958770751953125\n",
            "        - 0.8477973937988281\n",
            "    num_agent_steps_sampled: 37000\n",
            "    num_agent_steps_trained: 288032\n",
            "    num_env_steps_sampled: 37000\n",
            "    num_env_steps_trained: 288032\n",
            "    num_target_updates: 73\n",
            "  iterations_since_restore: 37\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 37000\n",
            "  num_agent_steps_trained: 288032\n",
            "  num_env_steps_sampled: 37000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 288032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.77142857142857\n",
            "    ram_util_percent: 16.7\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11368678575162428\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08688921862722347\n",
            "    mean_inference_ms: 1.3071673161676827\n",
            "    mean_raw_obs_processing_ms: 0.2069079500434418\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 166.06\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 166.06\n",
            "    episode_reward_min: 100.0\n",
            "    episodes_this_iter: 6\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 171\n",
            "      - 194\n",
            "      - 190\n",
            "      - 188\n",
            "      - 175\n",
            "      - 200\n",
            "      - 197\n",
            "      - 158\n",
            "      - 128\n",
            "      - 188\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 171.0\n",
            "      - 194.0\n",
            "      - 190.0\n",
            "      - 188.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 197.0\n",
            "      - 158.0\n",
            "      - 128.0\n",
            "      - 188.0\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11368678575162428\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08688921862722347\n",
            "      mean_inference_ms: 1.3071673161676827\n",
            "      mean_raw_obs_processing_ms: 0.2069079500434418\n",
            "  time_since_restore: 166.35907363891602\n",
            "  time_this_iter_s: 4.56483793258667\n",
            "  time_total_s: 166.35907363891602\n",
            "  timers:\n",
            "    learn_throughput: 5087.416\n",
            "    learn_time_ms: 6.29\n",
            "    load_throughput: 223175.471\n",
            "    load_time_ms: 0.143\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 19.064\n",
            "  timestamp: 1656960868\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 37000\n",
            "  training_iteration: 37\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:28 (running for 00:02:54.89)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         166.359</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  166.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            166.06</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 39000\n",
            "  counters:\n",
            "    last_target_update_ts: 39000\n",
            "    num_agent_steps_sampled: 39000\n",
            "    num_agent_steps_trained: 304032\n",
            "    num_env_steps_sampled: 39000\n",
            "    num_env_steps_trained: 304032\n",
            "    num_target_updates: 77\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-38\n",
            "  done: false\n",
            "  episode_len_mean: 168.17\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 168.17\n",
            "  episode_reward_min: 100.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 396\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 39000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 56.68163299560547\n",
            "          mean_q: 49.454673767089844\n",
            "          mean_td_error: 3.393179416656494\n",
            "          min_q: 0.6030578017234802\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.2662086486816406\n",
            "        - -0.4802703857421875\n",
            "        - 0.7121391296386719\n",
            "        - -0.3531608581542969\n",
            "        - -0.21921157836914062\n",
            "        - 0.3027801513671875\n",
            "        - 0.2515869140625\n",
            "        - -1.1175918579101562\n",
            "        - 33.81367492675781\n",
            "        - -0.002101898193359375\n",
            "        - -1.2952156066894531\n",
            "        - -0.27416229248046875\n",
            "        - 0.8715667724609375\n",
            "        - -0.2364654541015625\n",
            "        - 0.28791046142578125\n",
            "        - -0.3969421982765198\n",
            "        - 23.965452194213867\n",
            "        - 0.7135505676269531\n",
            "        - -0.001651763916015625\n",
            "        - -1.2186126708984375\n",
            "        - -0.3271446228027344\n",
            "        - 0.2530021667480469\n",
            "        - -0.3087425231933594\n",
            "        - -0.07138442993164062\n",
            "        - -0.458221435546875\n",
            "        - 0.4071006774902344\n",
            "        - -0.056690216064453125\n",
            "        - 52.46918487548828\n",
            "        - 2.453784942626953\n",
            "        - -0.3389167785644531\n",
            "        - -1.6954231262207031\n",
            "        - 0.6657066345214844\n",
            "    num_agent_steps_sampled: 39000\n",
            "    num_agent_steps_trained: 304032\n",
            "    num_env_steps_sampled: 39000\n",
            "    num_env_steps_trained: 304032\n",
            "    num_target_updates: 77\n",
            "  iterations_since_restore: 39\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 39000\n",
            "  num_agent_steps_trained: 304032\n",
            "  num_env_steps_sampled: 39000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 304032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.35714285714286\n",
            "    ram_util_percent: 16.8\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11348118045105847\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08675462480608352\n",
            "    mean_inference_ms: 1.306138625902246\n",
            "    mean_raw_obs_processing_ms: 0.2065798518038654\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 168.17\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 168.17\n",
            "    episode_reward_min: 100.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 195\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 139\n",
            "      - 184\n",
            "      - 131\n",
            "      - 125\n",
            "      - 155\n",
            "      - 170\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 195.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 184.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 155.0\n",
            "      - 170.0\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11348118045105847\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08675462480608352\n",
            "      mean_inference_ms: 1.306138625902246\n",
            "      mean_raw_obs_processing_ms: 0.2065798518038654\n",
            "  time_since_restore: 175.44334745407104\n",
            "  time_this_iter_s: 4.56194806098938\n",
            "  time_total_s: 175.44334745407104\n",
            "  timers:\n",
            "    learn_throughput: 5167.169\n",
            "    learn_time_ms: 6.193\n",
            "    load_throughput: 221225.858\n",
            "    load_time_ms: 0.145\n",
            "    synch_weights_time_ms: 0.058\n",
            "    training_iteration_time_ms: 18.952\n",
            "  timestamp: 1656960878\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 39000\n",
            "  training_iteration: 39\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:38 (running for 00:03:04.03)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         175.443</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  168.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            168.17</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 41000\n",
            "  counters:\n",
            "    last_target_update_ts: 41000\n",
            "    num_agent_steps_sampled: 41000\n",
            "    num_agent_steps_trained: 320032\n",
            "    num_env_steps_sampled: 41000\n",
            "    num_env_steps_trained: 320032\n",
            "    num_target_updates: 81\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-47\n",
            "  done: false\n",
            "  episode_len_mean: 168.59\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 168.59\n",
            "  episode_reward_min: 100.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 407\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 41000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 58.98591995239258\n",
            "          mean_q: 50.750709533691406\n",
            "          mean_td_error: 0.39329421520233154\n",
            "          min_q: 21.5341854095459\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.3419036865234375\n",
            "        - -0.248443603515625\n",
            "        - 0.2425079345703125\n",
            "        - 0.7047500610351562\n",
            "        - 0.11757278442382812\n",
            "        - -0.24998092651367188\n",
            "        - -1.680572509765625\n",
            "        - -0.228546142578125\n",
            "        - -0.36031341552734375\n",
            "        - -0.21679306030273438\n",
            "        - -0.18173980712890625\n",
            "        - -0.0949554443359375\n",
            "        - -0.7041702270507812\n",
            "        - -0.8678436279296875\n",
            "        - 0.34859466552734375\n",
            "        - -0.3259925842285156\n",
            "        - -0.7276954650878906\n",
            "        - 20.5341854095459\n",
            "        - -0.23647689819335938\n",
            "        - -0.52581787109375\n",
            "        - -0.6626663208007812\n",
            "        - 1.2802772521972656\n",
            "        - 0.16618728637695312\n",
            "        - 0.19818878173828125\n",
            "        - -0.20832443237304688\n",
            "        - -0.25380706787109375\n",
            "        - -3.790567398071289\n",
            "        - 0.9717864990234375\n",
            "        - 0.06854629516601562\n",
            "        - -0.15148162841796875\n",
            "        - 0.1280975341796875\n",
            "        - -0.1171875\n",
            "    num_agent_steps_sampled: 41000\n",
            "    num_agent_steps_trained: 320032\n",
            "    num_env_steps_sampled: 41000\n",
            "    num_env_steps_trained: 320032\n",
            "    num_target_updates: 81\n",
            "  iterations_since_restore: 41\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 41000\n",
            "  num_agent_steps_trained: 320032\n",
            "  num_env_steps_sampled: 41000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 320032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.75714285714285\n",
            "    ram_util_percent: 16.8\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11329920261762344\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08665596420776506\n",
            "    mean_inference_ms: 1.3052827279754415\n",
            "    mean_raw_obs_processing_ms: 0.2062889931891883\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 168.59\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 168.59\n",
            "    episode_reward_min: 100.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 155\n",
            "      - 102\n",
            "      - 113\n",
            "      - 104\n",
            "      - 111\n",
            "      - 113\n",
            "      - 111\n",
            "      - 123\n",
            "      - 124\n",
            "      - 110\n",
            "      - 118\n",
            "      - 105\n",
            "      - 108\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 155.0\n",
            "      - 102.0\n",
            "      - 113.0\n",
            "      - 104.0\n",
            "      - 111.0\n",
            "      - 113.0\n",
            "      - 111.0\n",
            "      - 123.0\n",
            "      - 124.0\n",
            "      - 110.0\n",
            "      - 118.0\n",
            "      - 105.0\n",
            "      - 108.0\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11329920261762344\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08665596420776506\n",
            "      mean_inference_ms: 1.3052827279754415\n",
            "      mean_raw_obs_processing_ms: 0.2062889931891883\n",
            "  time_since_restore: 184.61607551574707\n",
            "  time_this_iter_s: 4.624482154846191\n",
            "  time_total_s: 184.61607551574707\n",
            "  timers:\n",
            "    learn_throughput: 4964.151\n",
            "    learn_time_ms: 6.446\n",
            "    load_throughput: 216270.912\n",
            "    load_time_ms: 0.148\n",
            "    synch_weights_time_ms: 0.055\n",
            "    training_iteration_time_ms: 19.311\n",
            "  timestamp: 1656960887\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 41000\n",
            "  training_iteration: 41\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:47 (running for 00:03:13.33)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         184.616</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">  168.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            168.59</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 43000\n",
            "  counters:\n",
            "    last_target_update_ts: 43000\n",
            "    num_agent_steps_sampled: 43000\n",
            "    num_agent_steps_trained: 336032\n",
            "    num_env_steps_sampled: 43000\n",
            "    num_env_steps_trained: 336032\n",
            "    num_target_updates: 85\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-54-56\n",
            "  done: false\n",
            "  episode_len_mean: 173.27\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 173.27\n",
            "  episode_reward_min: 100.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 420\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 43000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 61.80015182495117\n",
            "          mean_q: 48.26218032836914\n",
            "          mean_td_error: 4.9139533042907715\n",
            "          min_q: -8.568523406982422\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -7.922290325164795\n",
            "        - 0.2720184326171875\n",
            "        - -0.19237899780273438\n",
            "        - -0.5396041870117188\n",
            "        - 41.05583572387695\n",
            "        - -2.8719770908355713\n",
            "        - 0.00815582275390625\n",
            "        - 0.39067840576171875\n",
            "        - 0.4617156982421875\n",
            "        - 0.22621917724609375\n",
            "        - 0.7746047973632812\n",
            "        - -0.558349609375\n",
            "        - -0.13039779663085938\n",
            "        - -0.3738212585449219\n",
            "        - 0.4274101257324219\n",
            "        - -0.8874702453613281\n",
            "        - 28.907033920288086\n",
            "        - 1.3473930358886719\n",
            "        - 0.2698974609375\n",
            "        - 0.0797271728515625\n",
            "        - -0.09307861328125\n",
            "        - 53.0390739440918\n",
            "        - 0.6456794738769531\n",
            "        - 0.94183349609375\n",
            "        - 0.12276458740234375\n",
            "        - 47.272647857666016\n",
            "        - -0.007213592529296875\n",
            "        - 0.4496955871582031\n",
            "        - 0.22240829467773438\n",
            "        - 0.19681549072265625\n",
            "        - -5.462249755859375\n",
            "        - -0.8262710571289062\n",
            "    num_agent_steps_sampled: 43000\n",
            "    num_agent_steps_trained: 336032\n",
            "    num_env_steps_sampled: 43000\n",
            "    num_env_steps_trained: 336032\n",
            "    num_target_updates: 85\n",
            "  iterations_since_restore: 43\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 43000\n",
            "  num_agent_steps_trained: 336032\n",
            "  num_env_steps_sampled: 43000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 336032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.26666666666667\n",
            "    ram_util_percent: 16.900000000000002\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11313801477923141\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08657191968548256\n",
            "    mean_inference_ms: 1.3046981387009862\n",
            "    mean_raw_obs_processing_ms: 0.2059603220626505\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 173.27\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 173.27\n",
            "    episode_reward_min: 100.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 124\n",
            "      - 123\n",
            "      - 123\n",
            "      - 126\n",
            "      - 107\n",
            "      - 129\n",
            "      - 133\n",
            "      - 124\n",
            "      - 121\n",
            "      - 115\n",
            "      - 124\n",
            "      - 126\n",
            "      - 150\n",
            "      - 154\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      episode_reward:\n",
            "      - 124.0\n",
            "      - 123.0\n",
            "      - 123.0\n",
            "      - 126.0\n",
            "      - 107.0\n",
            "      - 129.0\n",
            "      - 133.0\n",
            "      - 124.0\n",
            "      - 121.0\n",
            "      - 115.0\n",
            "      - 124.0\n",
            "      - 126.0\n",
            "      - 150.0\n",
            "      - 154.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11313801477923141\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08657191968548256\n",
            "      mean_inference_ms: 1.3046981387009862\n",
            "      mean_raw_obs_processing_ms: 0.2059603220626505\n",
            "  time_since_restore: 193.73303961753845\n",
            "  time_this_iter_s: 4.516125202178955\n",
            "  time_total_s: 193.73303961753845\n",
            "  timers:\n",
            "    learn_throughput: 3835.899\n",
            "    learn_time_ms: 8.342\n",
            "    load_throughput: 106319.493\n",
            "    load_time_ms: 0.301\n",
            "    synch_weights_time_ms: 0.058\n",
            "    training_iteration_time_ms: 22.412\n",
            "  timestamp: 1656960896\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 43000\n",
            "  training_iteration: 43\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:54:56 (running for 00:03:22.42)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         193.733</td><td style=\"text-align: right;\">43000</td><td style=\"text-align: right;\">  173.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            173.27</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 45000\n",
            "  counters:\n",
            "    last_target_update_ts: 45000\n",
            "    num_agent_steps_sampled: 45000\n",
            "    num_agent_steps_trained: 352032\n",
            "    num_env_steps_sampled: 45000\n",
            "    num_env_steps_trained: 352032\n",
            "    num_target_updates: 89\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-05\n",
            "  done: false\n",
            "  episode_len_mean: 173.09\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 173.09\n",
            "  episode_reward_min: 99.0\n",
            "  episodes_this_iter: 9\n",
            "  episodes_total: 436\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 45000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 63.56136703491211\n",
            "          mean_q: 59.26179504394531\n",
            "          mean_td_error: 3.3979177474975586\n",
            "          min_q: 42.838172912597656\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.07128143310546875\n",
            "        - 0.17248916625976562\n",
            "        - -0.2872123718261719\n",
            "        - 0.20152664184570312\n",
            "        - -0.1512451171875\n",
            "        - 0.5354843139648438\n",
            "        - -0.10614776611328125\n",
            "        - 0.07958221435546875\n",
            "        - 54.508975982666016\n",
            "        - -0.2222137451171875\n",
            "        - -0.3063774108886719\n",
            "        - -0.15649032592773438\n",
            "        - -0.30748748779296875\n",
            "        - 0.3833160400390625\n",
            "        - -0.5280990600585938\n",
            "        - 0.09280776977539062\n",
            "        - 0.02889251708984375\n",
            "        - -0.24316787719726562\n",
            "        - 0.00122833251953125\n",
            "        - 0.2959938049316406\n",
            "        - -0.4962348937988281\n",
            "        - 0.001148223876953125\n",
            "        - 55.85453796386719\n",
            "        - -0.13413619995117188\n",
            "        - 0.16146087646484375\n",
            "        - 0.09344100952148438\n",
            "        - -0.20708465576171875\n",
            "        - 0.4535179138183594\n",
            "        - 0.10805892944335938\n",
            "        - -0.228668212890625\n",
            "        - -0.6157417297363281\n",
            "        - -0.17750930786132812\n",
            "    num_agent_steps_sampled: 45000\n",
            "    num_agent_steps_trained: 352032\n",
            "    num_env_steps_sampled: 45000\n",
            "    num_env_steps_trained: 352032\n",
            "    num_target_updates: 89\n",
            "  iterations_since_restore: 45\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 45000\n",
            "  num_agent_steps_trained: 352032\n",
            "  num_env_steps_sampled: 45000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 352032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.38333333333334\n",
            "    ram_util_percent: 16.900000000000002\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1129989839325623\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08654599131348627\n",
            "    mean_inference_ms: 1.3043417350033855\n",
            "    mean_raw_obs_processing_ms: 0.20561909353623067\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 173.09\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 173.09\n",
            "    episode_reward_min: 99.0\n",
            "    episodes_this_iter: 9\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1129989839325623\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08654599131348627\n",
            "      mean_inference_ms: 1.3043417350033855\n",
            "      mean_raw_obs_processing_ms: 0.20561909353623067\n",
            "  time_since_restore: 202.87255263328552\n",
            "  time_this_iter_s: 4.51482367515564\n",
            "  time_total_s: 202.87255263328552\n",
            "  timers:\n",
            "    learn_throughput: 5063.043\n",
            "    learn_time_ms: 6.32\n",
            "    load_throughput: 200056.235\n",
            "    load_time_ms: 0.16\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 19.343\n",
            "  timestamp: 1656960905\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 45000\n",
            "  training_iteration: 45\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:05 (running for 00:03:31.62)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         202.873</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">  173.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            173.09</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 47000\n",
            "  counters:\n",
            "    last_target_update_ts: 47000\n",
            "    num_agent_steps_sampled: 47000\n",
            "    num_agent_steps_trained: 368032\n",
            "    num_env_steps_sampled: 47000\n",
            "    num_env_steps_trained: 368032\n",
            "    num_target_updates: 93\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-14\n",
            "  done: false\n",
            "  episode_len_mean: 165.66\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 165.66\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 449\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 47000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 64.32279205322266\n",
            "          mean_q: 53.20933532714844\n",
            "          mean_td_error: 2.6941583156585693\n",
            "          min_q: -2.4521467685699463\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.18593215942382812\n",
            "        - -0.18988418579101562\n",
            "        - 0.24591064453125\n",
            "        - -0.3723793029785156\n",
            "        - 57.9802131652832\n",
            "        - -3.4521467685699463\n",
            "        - -0.4377937316894531\n",
            "        - -0.4269371032714844\n",
            "        - 0.036067962646484375\n",
            "        - 0.07143402099609375\n",
            "        - -0.4665069580078125\n",
            "        - -0.5684394836425781\n",
            "        - 0.021076202392578125\n",
            "        - -0.18590545654296875\n",
            "        - -0.3093452453613281\n",
            "        - -0.6498222351074219\n",
            "        - 1.5067813396453857\n",
            "        - -0.510467529296875\n",
            "        - -0.30551910400390625\n",
            "        - -0.218536376953125\n",
            "        - -9.46373176574707\n",
            "        - -0.13196182250976562\n",
            "        - -0.18196868896484375\n",
            "        - -0.04776763916015625\n",
            "        - -0.4269218444824219\n",
            "        - -0.10294342041015625\n",
            "        - -2.912740707397461\n",
            "        - 50.214595794677734\n",
            "        - -0.9828643798828125\n",
            "        - -0.7524337768554688\n",
            "        - -0.3765144348144531\n",
            "        - -0.20355224609375\n",
            "    num_agent_steps_sampled: 47000\n",
            "    num_agent_steps_trained: 368032\n",
            "    num_env_steps_sampled: 47000\n",
            "    num_env_steps_trained: 368032\n",
            "    num_target_updates: 93\n",
            "  iterations_since_restore: 47\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 47000\n",
            "  num_agent_steps_trained: 368032\n",
            "  num_env_steps_sampled: 47000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 368032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.23333333333333\n",
            "    ram_util_percent: 17.0\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11293365929262579\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08656042787915404\n",
            "    mean_inference_ms: 1.304368471563401\n",
            "    mean_raw_obs_processing_ms: 0.2054066003919002\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 165.66\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 165.66\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 170\n",
            "      - 180\n",
            "      - 178\n",
            "      - 131\n",
            "      - 200\n",
            "      - 171\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 180.0\n",
            "      - 178.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11293365929262579\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08656042787915404\n",
            "      mean_inference_ms: 1.304368471563401\n",
            "      mean_raw_obs_processing_ms: 0.2054066003919002\n",
            "  time_since_restore: 212.07424092292786\n",
            "  time_this_iter_s: 4.553300857543945\n",
            "  time_total_s: 212.07424092292786\n",
            "  timers:\n",
            "    learn_throughput: 5154.489\n",
            "    learn_time_ms: 6.208\n",
            "    load_throughput: 238482.104\n",
            "    load_time_ms: 0.134\n",
            "    synch_weights_time_ms: 0.052\n",
            "    training_iteration_time_ms: 18.208\n",
            "  timestamp: 1656960914\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 47000\n",
            "  training_iteration: 47\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:14 (running for 00:03:40.95)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         212.074</td><td style=\"text-align: right;\">47000</td><td style=\"text-align: right;\">  165.66</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            165.66</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 49000\n",
            "  counters:\n",
            "    last_target_update_ts: 49000\n",
            "    num_agent_steps_sampled: 49000\n",
            "    num_agent_steps_trained: 384032\n",
            "    num_env_steps_sampled: 49000\n",
            "    num_env_steps_trained: 384032\n",
            "    num_target_updates: 97\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-24\n",
            "  done: false\n",
            "  episode_len_mean: 163.43\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 163.43\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 461\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 49000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 66.92147064208984\n",
            "          mean_q: 54.44144058227539\n",
            "          mean_td_error: 3.804029941558838\n",
            "          min_q: -6.2192888259887695\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.5431938171386719\n",
            "        - -0.15474700927734375\n",
            "        - 0.22845077514648438\n",
            "        - 0.6330474615097046\n",
            "        - -0.17011260986328125\n",
            "        - 0.22420501708984375\n",
            "        - -3.5706748962402344\n",
            "        - -3.136150360107422\n",
            "        - 51.00937271118164\n",
            "        - -0.14661407470703125\n",
            "        - -1.244903564453125\n",
            "        - 38.403282165527344\n",
            "        - 0.49663543701171875\n",
            "        - -0.6732940673828125\n",
            "        - 0.1640472412109375\n",
            "        - 0.7782974243164062\n",
            "        - 0.4656715393066406\n",
            "        - 0.24114227294921875\n",
            "        - 0.03743743896484375\n",
            "        - 45.597007751464844\n",
            "        - -7.2192888259887695\n",
            "        - -0.3645057678222656\n",
            "        - -0.12020111083984375\n",
            "        - -0.24529647827148438\n",
            "        - 0.2571754455566406\n",
            "        - -0.0377655029296875\n",
            "        - -0.193389892578125\n",
            "        - -0.7008590698242188\n",
            "        - -0.5371589660644531\n",
            "        - 0.35161590576171875\n",
            "        - 0.5561714172363281\n",
            "        - 0.257171630859375\n",
            "    num_agent_steps_sampled: 49000\n",
            "    num_agent_steps_trained: 384032\n",
            "    num_env_steps_sampled: 49000\n",
            "    num_env_steps_trained: 384032\n",
            "    num_target_updates: 97\n",
            "  iterations_since_restore: 49\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 49000\n",
            "  num_agent_steps_trained: 384032\n",
            "  num_env_steps_sampled: 49000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 384032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.84285714285714\n",
            "    ram_util_percent: 17.0\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11288650257113603\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08659223685837139\n",
            "    mean_inference_ms: 1.3044543314028132\n",
            "    mean_raw_obs_processing_ms: 0.20523104260561856\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 163.43\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 163.43\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 146\n",
            "      - 123\n",
            "      - 100\n",
            "      - 124\n",
            "      - 200\n",
            "      - 200\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 146.0\n",
            "      - 123.0\n",
            "      - 100.0\n",
            "      - 124.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11288650257113603\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08659223685837139\n",
            "      mean_inference_ms: 1.3044543314028132\n",
            "      mean_raw_obs_processing_ms: 0.20523104260561856\n",
            "  time_since_restore: 221.3092885017395\n",
            "  time_this_iter_s: 4.644887924194336\n",
            "  time_total_s: 221.3092885017395\n",
            "  timers:\n",
            "    learn_throughput: 4588.405\n",
            "    learn_time_ms: 6.974\n",
            "    load_throughput: 187141.283\n",
            "    load_time_ms: 0.171\n",
            "    synch_weights_time_ms: 0.062\n",
            "    training_iteration_time_ms: 20.098\n",
            "  timestamp: 1656960924\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 49000\n",
            "  training_iteration: 49\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:24 (running for 00:03:50.16)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         221.309</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  163.43</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            163.43</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 51000\n",
            "  counters:\n",
            "    last_target_update_ts: 51000\n",
            "    num_agent_steps_sampled: 51000\n",
            "    num_agent_steps_trained: 400032\n",
            "    num_env_steps_sampled: 51000\n",
            "    num_env_steps_trained: 400032\n",
            "    num_target_updates: 101\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-33\n",
            "  done: false\n",
            "  episode_len_mean: 166.05\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 166.05\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 472\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 51000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 70.1964111328125\n",
            "          mean_q: 55.91859817504883\n",
            "          mean_td_error: 5.055724143981934\n",
            "          min_q: -9.988959312438965\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.31694793701171875\n",
            "        - -0.3448028564453125\n",
            "        - 0.8849334716796875\n",
            "        - 0.1007537841796875\n",
            "        - -0.10555267333984375\n",
            "        - -1.9843177795410156\n",
            "        - -0.2738037109375\n",
            "        - -0.5392189025878906\n",
            "        - -10.988959312438965\n",
            "        - 32.31904983520508\n",
            "        - -0.370330810546875\n",
            "        - -0.19295501708984375\n",
            "        - -0.18883132934570312\n",
            "        - -11.907939910888672\n",
            "        - 0.00058746337890625\n",
            "        - -0.451324462890625\n",
            "        - 0.289398193359375\n",
            "        - 0.103851318359375\n",
            "        - -0.26622772216796875\n",
            "        - -1.8914909362792969\n",
            "        - -0.066314697265625\n",
            "        - 0.5941162109375\n",
            "        - -0.05252838134765625\n",
            "        - 1.0047645568847656\n",
            "        - 34.29936218261719\n",
            "        - -0.6837081909179688\n",
            "        - 59.45415496826172\n",
            "        - 0.5636215209960938\n",
            "        - -0.29756927490234375\n",
            "        - 0.47312164306640625\n",
            "        - 1.8204345703125\n",
            "        - 60.797847747802734\n",
            "    num_agent_steps_sampled: 51000\n",
            "    num_agent_steps_trained: 400032\n",
            "    num_env_steps_sampled: 51000\n",
            "    num_env_steps_trained: 400032\n",
            "    num_target_updates: 101\n",
            "  iterations_since_restore: 51\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 51000\n",
            "  num_agent_steps_trained: 400032\n",
            "  num_env_steps_sampled: 51000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 400032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.07142857142857\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11286851645452348\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08662075123124172\n",
            "    mean_inference_ms: 1.304805933026401\n",
            "    mean_raw_obs_processing_ms: 0.20510225599296253\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 166.05\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 166.05\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 150\n",
            "      - 120\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 150.0\n",
            "      - 120.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11286851645452348\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08662075123124172\n",
            "      mean_inference_ms: 1.304805933026401\n",
            "      mean_raw_obs_processing_ms: 0.20510225599296253\n",
            "  time_since_restore: 230.57193326950073\n",
            "  time_this_iter_s: 4.537367820739746\n",
            "  time_total_s: 230.57193326950073\n",
            "  timers:\n",
            "    learn_throughput: 5747.27\n",
            "    learn_time_ms: 5.568\n",
            "    load_throughput: 214954.721\n",
            "    load_time_ms: 0.149\n",
            "    synch_weights_time_ms: 0.05\n",
            "    training_iteration_time_ms: 17.664\n",
            "  timestamp: 1656960933\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 51000\n",
            "  training_iteration: 51\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:33 (running for 00:03:59.47)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         230.572</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">  166.05</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            166.05</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 53000\n",
            "  counters:\n",
            "    last_target_update_ts: 53000\n",
            "    num_agent_steps_sampled: 53000\n",
            "    num_agent_steps_trained: 416032\n",
            "    num_env_steps_sampled: 53000\n",
            "    num_env_steps_trained: 416032\n",
            "    num_target_updates: 105\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-42\n",
            "  done: false\n",
            "  episode_len_mean: 160.62\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 160.62\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 8\n",
            "  episodes_total: 486\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 53000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 70.85389709472656\n",
            "          mean_q: 63.1458740234375\n",
            "          mean_td_error: 4.040889263153076\n",
            "          min_q: 41.93129348754883\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.12818145751953125\n",
            "        - -0.6493682861328125\n",
            "        - 0.163238525390625\n",
            "        - 53.42768478393555\n",
            "        - -0.3585662841796875\n",
            "        - -0.37609100341796875\n",
            "        - -0.562774658203125\n",
            "        - -0.19069671630859375\n",
            "        - -0.005809783935546875\n",
            "        - 0.1040802001953125\n",
            "        - -0.39386749267578125\n",
            "        - 0.285400390625\n",
            "        - -0.7746200561523438\n",
            "        - -0.6498031616210938\n",
            "        - -0.1553497314453125\n",
            "        - -0.0358123779296875\n",
            "        - -0.6688995361328125\n",
            "        - 0.0146942138671875\n",
            "        - 0.12197113037109375\n",
            "        - -0.4678001403808594\n",
            "        - 0.0032958984375\n",
            "        - 6.866455078125e-05\n",
            "        - -0.5403823852539062\n",
            "        - -0.6753387451171875\n",
            "        - -0.6976737976074219\n",
            "        - 0.00638580322265625\n",
            "        - 42.560546875\n",
            "        - -0.028636932373046875\n",
            "        - 40.93129348754883\n",
            "        - 0.2584075927734375\n",
            "        - -1.3512458801269531\n",
            "        - 0.14231109619140625\n",
            "    num_agent_steps_sampled: 53000\n",
            "    num_agent_steps_trained: 416032\n",
            "    num_env_steps_sampled: 53000\n",
            "    num_env_steps_trained: 416032\n",
            "    num_target_updates: 105\n",
            "  iterations_since_restore: 53\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 53000\n",
            "  num_agent_steps_trained: 416032\n",
            "  num_env_steps_sampled: 53000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 416032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.39999999999999\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11284309822836441\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08665774638547692\n",
            "    mean_inference_ms: 1.3050886740406529\n",
            "    mean_raw_obs_processing_ms: 0.20497103547161616\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 160.62\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 160.62\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 8\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 151\n",
            "      - 125\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 151.0\n",
            "      - 125.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11284309822836441\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08665774638547692\n",
            "      mean_inference_ms: 1.3050886740406529\n",
            "      mean_raw_obs_processing_ms: 0.20497103547161616\n",
            "  time_since_restore: 239.7067232131958\n",
            "  time_this_iter_s: 4.5758514404296875\n",
            "  time_total_s: 239.7067232131958\n",
            "  timers:\n",
            "    learn_throughput: 5298.368\n",
            "    learn_time_ms: 6.04\n",
            "    load_throughput: 171130.598\n",
            "    load_time_ms: 0.187\n",
            "    synch_weights_time_ms: 0.056\n",
            "    training_iteration_time_ms: 19.091\n",
            "  timestamp: 1656960942\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 53000\n",
            "  training_iteration: 53\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:42 (running for 00:04:08.74)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         239.707</td><td style=\"text-align: right;\">53000</td><td style=\"text-align: right;\">  160.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            160.62</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 55000\n",
            "  counters:\n",
            "    last_target_update_ts: 55000\n",
            "    num_agent_steps_sampled: 55000\n",
            "    num_agent_steps_trained: 432032\n",
            "    num_env_steps_sampled: 55000\n",
            "    num_env_steps_trained: 432032\n",
            "    num_target_updates: 109\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-51\n",
            "  done: false\n",
            "  episode_len_mean: 155.81\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 155.81\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 6\n",
            "  episodes_total: 499\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 55000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 71.68731689453125\n",
            "          mean_q: 62.9088134765625\n",
            "          mean_td_error: 5.885565757751465\n",
            "          min_q: 30.398914337158203\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.30060577392578125\n",
            "        - -0.3340644836425781\n",
            "        - 0.6151847839355469\n",
            "        - 0.10321807861328125\n",
            "        - 0.049835205078125\n",
            "        - -0.49549102783203125\n",
            "        - 0.05345916748046875\n",
            "        - 61.46342086791992\n",
            "        - 0.09041213989257812\n",
            "        - 0.8675308227539062\n",
            "        - 1.1252899169921875\n",
            "        - -0.18337631225585938\n",
            "        - -0.14286041259765625\n",
            "        - 0.229461669921875\n",
            "        - 0.29460906982421875\n",
            "        - -0.049968719482421875\n",
            "        - 0.1271514892578125\n",
            "        - -0.055999755859375\n",
            "        - 29.398914337158203\n",
            "        - 48.42390060424805\n",
            "        - 46.20426940917969\n",
            "        - 0.4898529052734375\n",
            "        - 0.2266082763671875\n",
            "        - -0.6481475830078125\n",
            "        - -0.5477294921875\n",
            "        - 0.33271026611328125\n",
            "        - -0.13547515869140625\n",
            "        - -0.3140678405761719\n",
            "        - 0.30278778076171875\n",
            "        - -0.07198333740234375\n",
            "        - 0.25043487548828125\n",
            "        - 0.3675994873046875\n",
            "    num_agent_steps_sampled: 55000\n",
            "    num_agent_steps_trained: 432032\n",
            "    num_env_steps_sampled: 55000\n",
            "    num_env_steps_trained: 432032\n",
            "    num_target_updates: 109\n",
            "  iterations_since_restore: 55\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 55000\n",
            "  num_agent_steps_trained: 432032\n",
            "  num_env_steps_sampled: 55000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 432032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.71666666666667\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11285653395376033\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08671840277415964\n",
            "    mean_inference_ms: 1.305480452441203\n",
            "    mean_raw_obs_processing_ms: 0.20488859796341746\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 155.81\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 155.81\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 6\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11285653395376033\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08671840277415964\n",
            "      mean_inference_ms: 1.305480452441203\n",
            "      mean_raw_obs_processing_ms: 0.20488859796341746\n",
            "  time_since_restore: 248.95562720298767\n",
            "  time_this_iter_s: 4.640922784805298\n",
            "  time_total_s: 248.95562720298767\n",
            "  timers:\n",
            "    learn_throughput: 4636.287\n",
            "    learn_time_ms: 6.902\n",
            "    load_throughput: 212875.064\n",
            "    load_time_ms: 0.15\n",
            "    synch_weights_time_ms: 0.06\n",
            "    training_iteration_time_ms: 19.404\n",
            "  timestamp: 1656960951\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 55000\n",
            "  training_iteration: 55\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:52 (running for 00:04:17.96)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         248.956</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  155.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            155.81</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:55:57 (running for 00:04:23.10)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         248.956</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  155.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            155.81</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 56000\n",
            "  counters:\n",
            "    last_target_update_ts: 56000\n",
            "    num_agent_steps_sampled: 56000\n",
            "    num_agent_steps_trained: 440032\n",
            "    num_env_steps_sampled: 56000\n",
            "    num_env_steps_trained: 440032\n",
            "    num_target_updates: 111\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-55-57\n",
            "  done: false\n",
            "  episode_len_mean: 157.16\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 157.16\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 504\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 56000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 72.32200622558594\n",
            "          mean_q: 65.47694396972656\n",
            "          mean_td_error: 5.028007507324219\n",
            "          min_q: 33.510807037353516\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 66.5550537109375\n",
            "        - 0.23281478881835938\n",
            "        - -0.3720550537109375\n",
            "        - -0.846435546875\n",
            "        - 0.02036285400390625\n",
            "        - -0.5220413208007812\n",
            "        - 0.00337982177734375\n",
            "        - -0.6021308898925781\n",
            "        - -0.13361358642578125\n",
            "        - -0.099517822265625\n",
            "        - 0.28357696533203125\n",
            "        - -0.09714508056640625\n",
            "        - 0.32994842529296875\n",
            "        - -0.3264617919921875\n",
            "        - -0.2833251953125\n",
            "        - -0.19586944580078125\n",
            "        - -0.31739044189453125\n",
            "        - -0.30390167236328125\n",
            "        - 0.35189056396484375\n",
            "        - 0.2899131774902344\n",
            "        - -0.1766357421875\n",
            "        - 0.0862274169921875\n",
            "        - -0.6480026245117188\n",
            "        - -0.1496734619140625\n",
            "        - 0.4491119384765625\n",
            "        - 69.01724243164062\n",
            "        - -0.282196044921875\n",
            "        - -0.45758819580078125\n",
            "        - -0.425384521484375\n",
            "        - -3.152801513671875\n",
            "        - 32.510807037353516\n",
            "        - 0.1580963134765625\n",
            "    num_agent_steps_sampled: 56000\n",
            "    num_agent_steps_trained: 440032\n",
            "    num_env_steps_sampled: 56000\n",
            "    num_env_steps_trained: 440032\n",
            "    num_target_updates: 111\n",
            "  iterations_since_restore: 56\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 56000\n",
            "  num_agent_steps_trained: 440032\n",
            "  num_env_steps_sampled: 56000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 440032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.64285714285714\n",
            "    ram_util_percent: 17.128571428571426\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1128684866643109\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08674384032517643\n",
            "    mean_inference_ms: 1.3058026513237946\n",
            "    mean_raw_obs_processing_ms: 0.20487470042609446\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 157.16\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 157.16\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1128684866643109\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08674384032517643\n",
            "      mean_inference_ms: 1.3058026513237946\n",
            "      mean_raw_obs_processing_ms: 0.20487470042609446\n",
            "  time_since_restore: 254.05143523216248\n",
            "  time_this_iter_s: 5.095808029174805\n",
            "  time_total_s: 254.05143523216248\n",
            "  timers:\n",
            "    learn_throughput: 2811.62\n",
            "    learn_time_ms: 11.381\n",
            "    load_throughput: 136330.856\n",
            "    load_time_ms: 0.235\n",
            "    synch_weights_time_ms: 0.075\n",
            "    training_iteration_time_ms: 34.863\n",
            "  timestamp: 1656960957\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 56000\n",
            "  training_iteration: 56\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:02 (running for 00:04:28.18)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         254.051</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">  157.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">            157.16</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 57000\n",
            "  counters:\n",
            "    last_target_update_ts: 57000\n",
            "    num_agent_steps_sampled: 57000\n",
            "    num_agent_steps_trained: 448032\n",
            "    num_env_steps_sampled: 57000\n",
            "    num_env_steps_trained: 448032\n",
            "    num_target_updates: 113\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-02\n",
            "  done: false\n",
            "  episode_len_mean: 156.48\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 156.48\n",
            "  episode_reward_min: 94.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 509\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 57000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 73.43328857421875\n",
            "          mean_q: 65.98601531982422\n",
            "          mean_td_error: 3.2957425117492676\n",
            "          min_q: 37.98388671875\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.8903312683105469\n",
            "        - 0.402008056640625\n",
            "        - 0.2620391845703125\n",
            "        - -2.2015228271484375\n",
            "        - -0.35317230224609375\n",
            "        - 0.2394256591796875\n",
            "        - 1.0888557434082031\n",
            "        - 0.6102218627929688\n",
            "        - 0.22747039794921875\n",
            "        - -0.0118408203125\n",
            "        - 0.1673431396484375\n",
            "        - 0.22545623779296875\n",
            "        - -0.45563507080078125\n",
            "        - 0.3624267578125\n",
            "        - 0.7698593139648438\n",
            "        - 0.7390518188476562\n",
            "        - 0.4133453369140625\n",
            "        - -2.6286163330078125\n",
            "        - 0.8713226318359375\n",
            "        - -0.8583335876464844\n",
            "        - 36.98388671875\n",
            "        - 64.7231674194336\n",
            "        - 1.6614456176757812\n",
            "        - -0.1936798095703125\n",
            "        - 0.2555389404296875\n",
            "        - 0.6532669067382812\n",
            "        - 0.7232589721679688\n",
            "        - 0.7832870483398438\n",
            "        - -0.18304443359375\n",
            "        - 0.7821578979492188\n",
            "        - -0.19220733642578125\n",
            "        - 0.48731231689453125\n",
            "    num_agent_steps_sampled: 57000\n",
            "    num_agent_steps_trained: 448032\n",
            "    num_env_steps_sampled: 57000\n",
            "    num_env_steps_trained: 448032\n",
            "    num_target_updates: 113\n",
            "  iterations_since_restore: 57\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 57000\n",
            "  num_agent_steps_trained: 448032\n",
            "  num_env_steps_sampled: 57000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 448032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 84.8375\n",
            "    ram_util_percent: 17.1\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11289269950291399\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08677594822907948\n",
            "    mean_inference_ms: 1.306303451879564\n",
            "    mean_raw_obs_processing_ms: 0.20489665129644266\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 156.48\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 156.48\n",
            "    episode_reward_min: 94.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 114\n",
            "      - 131\n",
            "      - 123\n",
            "      - 120\n",
            "      - 104\n",
            "      - 120\n",
            "      - 117\n",
            "      - 183\n",
            "      - 153\n",
            "      - 200\n",
            "      - 157\n",
            "      - 118\n",
            "      - 131\n",
            "      - 125\n",
            "      - 200\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 114.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 120.0\n",
            "      - 104.0\n",
            "      - 120.0\n",
            "      - 117.0\n",
            "      - 183.0\n",
            "      - 153.0\n",
            "      - 200.0\n",
            "      - 157.0\n",
            "      - 118.0\n",
            "      - 131.0\n",
            "      - 125.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11289269950291399\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08677594822907948\n",
            "      mean_inference_ms: 1.306303451879564\n",
            "      mean_raw_obs_processing_ms: 0.20489665129644266\n",
            "  time_since_restore: 259.52696919441223\n",
            "  time_this_iter_s: 5.475533962249756\n",
            "  time_total_s: 259.52696919441223\n",
            "  timers:\n",
            "    learn_throughput: 5681.751\n",
            "    learn_time_ms: 5.632\n",
            "    load_throughput: 228183.829\n",
            "    load_time_ms: 0.14\n",
            "    synch_weights_time_ms: 0.071\n",
            "    training_iteration_time_ms: 17.334\n",
            "  timestamp: 1656960962\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 57000\n",
            "  training_iteration: 57\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:07 (running for 00:04:33.41)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">          264.16</td><td style=\"text-align: right;\">58000</td><td style=\"text-align: right;\">   156.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  94</td><td style=\"text-align: right;\">             156.3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 59000\n",
            "  counters:\n",
            "    last_target_update_ts: 59000\n",
            "    num_agent_steps_sampled: 59000\n",
            "    num_agent_steps_trained: 464032\n",
            "    num_env_steps_sampled: 59000\n",
            "    num_env_steps_trained: 464032\n",
            "    num_target_updates: 117\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-12\n",
            "  done: false\n",
            "  episode_len_mean: 151.77\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 151.77\n",
            "  episode_reward_min: 89.0\n",
            "  episodes_this_iter: 10\n",
            "  episodes_total: 526\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 59000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 75.21270751953125\n",
            "          mean_q: 66.80458068847656\n",
            "          mean_td_error: 3.553307056427002\n",
            "          min_q: 44.3769416809082\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.2790985107421875\n",
            "        - 0.010772705078125\n",
            "        - -0.25380706787109375\n",
            "        - 0.20196533203125\n",
            "        - -0.06954193115234375\n",
            "        - -0.24990081787109375\n",
            "        - 0.5482101440429688\n",
            "        - 0.2763824462890625\n",
            "        - 0.22224044799804688\n",
            "        - 0.657379150390625\n",
            "        - -0.6654281616210938\n",
            "        - -0.22467803955078125\n",
            "        - -0.0333251953125\n",
            "        - 0.01636505126953125\n",
            "        - -0.14922332763671875\n",
            "        - 0.13315582275390625\n",
            "        - 0.73687744140625\n",
            "        - -0.0397186279296875\n",
            "        - 0.6127700805664062\n",
            "        - 3.4672584533691406\n",
            "        - 48.14978790283203\n",
            "        - -2.1462783813476562\n",
            "        - 0.0861968994140625\n",
            "        - -0.14447784423828125\n",
            "        - 0.16643524169921875\n",
            "        - 0.08625030517578125\n",
            "        - 63.37676239013672\n",
            "        - 0.0434112548828125\n",
            "        - -0.5697822570800781\n",
            "        - -0.0330810546875\n",
            "        - -0.3511695861816406\n",
            "        - -0.43508148193359375\n",
            "    num_agent_steps_sampled: 59000\n",
            "    num_agent_steps_trained: 464032\n",
            "    num_env_steps_sampled: 59000\n",
            "    num_env_steps_trained: 464032\n",
            "    num_target_updates: 117\n",
            "  iterations_since_restore: 59\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 59000\n",
            "  num_agent_steps_trained: 464032\n",
            "  num_env_steps_sampled: 59000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 464032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.82857142857144\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1129825119296173\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08688208447330294\n",
            "    mean_inference_ms: 1.3081479582903628\n",
            "    mean_raw_obs_processing_ms: 0.20500810950932682\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 151.77\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 151.77\n",
            "    episode_reward_min: 89.0\n",
            "    episodes_this_iter: 10\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 119\n",
            "      - 110\n",
            "      - 99\n",
            "      - 111\n",
            "      - 108\n",
            "      - 113\n",
            "      - 117\n",
            "      - 127\n",
            "      - 126\n",
            "      - 200\n",
            "      - 119\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 110.0\n",
            "      - 99.0\n",
            "      - 111.0\n",
            "      - 108.0\n",
            "      - 113.0\n",
            "      - 117.0\n",
            "      - 127.0\n",
            "      - 126.0\n",
            "      - 200.0\n",
            "      - 119.0\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1129825119296173\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08688208447330294\n",
            "      mean_inference_ms: 1.3081479582903628\n",
            "      mean_raw_obs_processing_ms: 0.20500810950932682\n",
            "  time_since_restore: 268.837459564209\n",
            "  time_this_iter_s: 4.677225589752197\n",
            "  time_total_s: 268.837459564209\n",
            "  timers:\n",
            "    learn_throughput: 4849.011\n",
            "    learn_time_ms: 6.599\n",
            "    load_throughput: 232492.167\n",
            "    load_time_ms: 0.138\n",
            "    synch_weights_time_ms: 0.051\n",
            "    training_iteration_time_ms: 19.492\n",
            "  timestamp: 1656960972\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 59000\n",
            "  training_iteration: 59\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:16 (running for 00:04:42.58)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         273.356</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  153.37</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            153.37</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 61000\n",
            "  counters:\n",
            "    last_target_update_ts: 61000\n",
            "    num_agent_steps_sampled: 61000\n",
            "    num_agent_steps_trained: 480032\n",
            "    num_env_steps_sampled: 61000\n",
            "    num_env_steps_trained: 480032\n",
            "    num_target_updates: 121\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-21\n",
            "  done: false\n",
            "  episode_len_mean: 155.82\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 155.82\n",
            "  episode_reward_min: 89.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 538\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 61000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 76.34526062011719\n",
            "          mean_q: 60.800148010253906\n",
            "          mean_td_error: 9.86234188079834\n",
            "          min_q: 18.25428581237793\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.546905517578125\n",
            "        - 1.8351058959960938\n",
            "        - 42.27212905883789\n",
            "        - 1.6139755249023438\n",
            "        - 34.03520965576172\n",
            "        - 0.1941070556640625\n",
            "        - 0.1190338134765625\n",
            "        - -0.24530029296875\n",
            "        - -0.38539886474609375\n",
            "        - 48.25788497924805\n",
            "        - -0.16768646240234375\n",
            "        - -0.6940765380859375\n",
            "        - 0.0775146484375\n",
            "        - -0.03247833251953125\n",
            "        - -0.45771026611328125\n",
            "        - 2.6712188720703125\n",
            "        - -0.8493766784667969\n",
            "        - 0.20278167724609375\n",
            "        - -0.38599395751953125\n",
            "        - -0.1829986572265625\n",
            "        - -0.1247100830078125\n",
            "        - 0.35552215576171875\n",
            "        - 0.23258590698242188\n",
            "        - -0.4746360778808594\n",
            "        - 70.6858901977539\n",
            "        - 50.862823486328125\n",
            "        - 0.5686187744140625\n",
            "        - 0.19295501708984375\n",
            "        - 64.6024169921875\n",
            "        - -0.9302711486816406\n",
            "        - 1.6079788208007812\n",
            "        - -0.4090728759765625\n",
            "    num_agent_steps_sampled: 61000\n",
            "    num_agent_steps_trained: 480032\n",
            "    num_env_steps_sampled: 61000\n",
            "    num_env_steps_trained: 480032\n",
            "    num_target_updates: 121\n",
            "  iterations_since_restore: 61\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 61000\n",
            "  num_agent_steps_trained: 480032\n",
            "  num_env_steps_sampled: 61000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 480032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.44285714285715\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1130350436941635\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08693291950036648\n",
            "    mean_inference_ms: 1.309345243774991\n",
            "    mean_raw_obs_processing_ms: 0.2050780811799916\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 155.82\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 155.82\n",
            "    episode_reward_min: 89.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 133\n",
            "      - 178\n",
            "      - 139\n",
            "      - 200\n",
            "      - 160\n",
            "      - 107\n",
            "      - 94\n",
            "      - 105\n",
            "      - 95\n",
            "      - 127\n",
            "      - 200\n",
            "      - 171\n",
            "      - 130\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 133.0\n",
            "      - 178.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 160.0\n",
            "      - 107.0\n",
            "      - 94.0\n",
            "      - 105.0\n",
            "      - 95.0\n",
            "      - 127.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 130.0\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1130350436941635\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08693291950036648\n",
            "      mean_inference_ms: 1.309345243774991\n",
            "      mean_raw_obs_processing_ms: 0.2050780811799916\n",
            "  time_since_restore: 278.2181234359741\n",
            "  time_this_iter_s: 4.861638307571411\n",
            "  time_total_s: 278.2181234359741\n",
            "  timers:\n",
            "    learn_throughput: 5474.945\n",
            "    learn_time_ms: 5.845\n",
            "    load_throughput: 232774.416\n",
            "    load_time_ms: 0.137\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 17.914\n",
            "  timestamp: 1656960981\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 61000\n",
            "  training_iteration: 61\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:26 (running for 00:04:52.07)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         282.783</td><td style=\"text-align: right;\">62000</td><td style=\"text-align: right;\">  156.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            156.98</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 63000\n",
            "  counters:\n",
            "    last_target_update_ts: 63000\n",
            "    num_agent_steps_sampled: 63000\n",
            "    num_agent_steps_trained: 496032\n",
            "    num_env_steps_sampled: 63000\n",
            "    num_env_steps_trained: 496032\n",
            "    num_target_updates: 125\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-30\n",
            "  done: false\n",
            "  episode_len_mean: 157.97\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 157.97\n",
            "  episode_reward_min: 89.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 551\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 63000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 78.91230773925781\n",
            "          mean_q: 69.85832214355469\n",
            "          mean_td_error: 0.07298034429550171\n",
            "          min_q: 22.074562072753906\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.12786102294921875\n",
            "        - 0.5078659057617188\n",
            "        - 0.44188690185546875\n",
            "        - -0.10186767578125\n",
            "        - 0.6073837280273438\n",
            "        - 0.5586090087890625\n",
            "        - -1.4180126190185547\n",
            "        - -1.5003662109375\n",
            "        - 0.198150634765625\n",
            "        - 0.743408203125\n",
            "        - 0.0769805908203125\n",
            "        - 0.02570343017578125\n",
            "        - 0.6052474975585938\n",
            "        - 0.36840057373046875\n",
            "        - -1.6652908325195312\n",
            "        - 0.6137008666992188\n",
            "        - 0.39203643798828125\n",
            "        - 0.5140914916992188\n",
            "        - -0.215179443359375\n",
            "        - 0.4406280517578125\n",
            "        - -0.06264495849609375\n",
            "        - 0.5659942626953125\n",
            "        - 0.45967864990234375\n",
            "        - -0.168609619140625\n",
            "        - 0.37131500244140625\n",
            "        - 0.16326904296875\n",
            "        - -1.1413726806640625\n",
            "        - 0.5633506774902344\n",
            "        - -0.17101287841796875\n",
            "        - 0.3494110107421875\n",
            "        - 0.33242034912109375\n",
            "        - -0.2476654052734375\n",
            "    num_agent_steps_sampled: 63000\n",
            "    num_agent_steps_trained: 496032\n",
            "    num_env_steps_sampled: 63000\n",
            "    num_env_steps_trained: 496032\n",
            "    num_target_updates: 125\n",
            "  iterations_since_restore: 63\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 63000\n",
            "  num_agent_steps_trained: 496032\n",
            "  num_env_steps_sampled: 63000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 496032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.5\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1130903690035749\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08698241013182434\n",
            "    mean_inference_ms: 1.3105315091136\n",
            "    mean_raw_obs_processing_ms: 0.20514633519979136\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 157.97\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 157.97\n",
            "    episode_reward_min: 89.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 151\n",
            "      - 163\n",
            "      - 134\n",
            "      - 156\n",
            "      - 135\n",
            "      - 167\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      episode_reward:\n",
            "      - 151.0\n",
            "      - 163.0\n",
            "      - 134.0\n",
            "      - 156.0\n",
            "      - 135.0\n",
            "      - 167.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1130903690035749\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08698241013182434\n",
            "      mean_inference_ms: 1.3105315091136\n",
            "      mean_raw_obs_processing_ms: 0.20514633519979136\n",
            "  time_since_restore: 287.4564447402954\n",
            "  time_this_iter_s: 4.673786163330078\n",
            "  time_total_s: 287.4564447402954\n",
            "  timers:\n",
            "    learn_throughput: 5766.605\n",
            "    learn_time_ms: 5.549\n",
            "    load_throughput: 200026.42\n",
            "    load_time_ms: 0.16\n",
            "    synch_weights_time_ms: 0.049\n",
            "    training_iteration_time_ms: 17.557\n",
            "  timestamp: 1656960990\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 63000\n",
            "  training_iteration: 63\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:35 (running for 00:05:01.45)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         292.031</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">  159.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            159.16</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 65000\n",
            "  counters:\n",
            "    last_target_update_ts: 65000\n",
            "    num_agent_steps_sampled: 65000\n",
            "    num_agent_steps_trained: 512032\n",
            "    num_env_steps_sampled: 65000\n",
            "    num_env_steps_trained: 512032\n",
            "    num_target_updates: 129\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-39\n",
            "  done: false\n",
            "  episode_len_mean: 158.61\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 158.61\n",
            "  episode_reward_min: 89.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 562\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 65000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 79.7099380493164\n",
            "          mean_q: 67.7513656616211\n",
            "          mean_td_error: 7.973019599914551\n",
            "          min_q: 3.3609280586242676\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.05572509765625\n",
            "        - 72.21643829345703\n",
            "        - -0.006805419921875\n",
            "        - 0.33355712890625\n",
            "        - 0.2740020751953125\n",
            "        - -0.38890981674194336\n",
            "        - -0.09564208984375\n",
            "        - 0.0691680908203125\n",
            "        - 6.270744323730469\n",
            "        - 57.977996826171875\n",
            "        - -0.00023651123046875\n",
            "        - 72.11425018310547\n",
            "        - -0.05944061279296875\n",
            "        - -0.0675048828125\n",
            "        - 0.6018600463867188\n",
            "        - 20.575929641723633\n",
            "        - 0.12526702880859375\n",
            "        - 0.36704254150390625\n",
            "        - -0.3673248291015625\n",
            "        - -0.3521728515625\n",
            "        - -0.092254638671875\n",
            "        - -0.01043701171875\n",
            "        - -1.0231475830078125\n",
            "        - -0.02516937255859375\n",
            "        - 26.797893524169922\n",
            "        - 0.01132965087890625\n",
            "        - -0.0298919677734375\n",
            "        - -0.3963623046875\n",
            "        - -0.0828704833984375\n",
            "        - -0.12396240234375\n",
            "        - 0.36102294921875\n",
            "        - 0.218017578125\n",
            "    num_agent_steps_sampled: 65000\n",
            "    num_agent_steps_trained: 512032\n",
            "    num_env_steps_sampled: 65000\n",
            "    num_env_steps_trained: 512032\n",
            "    num_target_updates: 129\n",
            "  iterations_since_restore: 65\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 65000\n",
            "  num_agent_steps_trained: 512032\n",
            "  num_env_steps_sampled: 65000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 512032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.65714285714286\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11314013109803947\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08701462639702338\n",
            "    mean_inference_ms: 1.3115065020467989\n",
            "    mean_raw_obs_processing_ms: 0.20519180952756158\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 158.61\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 158.61\n",
            "    episode_reward_min: 89.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 140\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 140.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11314013109803947\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08701462639702338\n",
            "      mean_inference_ms: 1.3115065020467989\n",
            "      mean_raw_obs_processing_ms: 0.20519180952756158\n",
            "  time_since_restore: 296.57233023643494\n",
            "  time_this_iter_s: 4.541430711746216\n",
            "  time_total_s: 296.57233023643494\n",
            "  timers:\n",
            "    learn_throughput: 4609.299\n",
            "    learn_time_ms: 6.942\n",
            "    load_throughput: 210142.051\n",
            "    load_time_ms: 0.152\n",
            "    synch_weights_time_ms: 0.055\n",
            "    training_iteration_time_ms: 20.315\n",
            "  timestamp: 1656960999\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 65000\n",
            "  training_iteration: 65\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:44 (running for 00:05:10.50)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         301.117</td><td style=\"text-align: right;\">66000</td><td style=\"text-align: right;\">  158.93</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            158.93</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 67000\n",
            "  counters:\n",
            "    last_target_update_ts: 67000\n",
            "    num_agent_steps_sampled: 67000\n",
            "    num_agent_steps_trained: 528032\n",
            "    num_env_steps_sampled: 67000\n",
            "    num_env_steps_trained: 528032\n",
            "    num_target_updates: 133\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-49\n",
            "  done: false\n",
            "  episode_len_mean: 159.48\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 159.48\n",
            "  episode_reward_min: 89.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 572\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 67000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 80.94062805175781\n",
            "          mean_q: 62.46343994140625\n",
            "          mean_td_error: 3.476306200027466\n",
            "          min_q: 7.471861839294434\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.483612060546875\n",
            "        - -0.15819549560546875\n",
            "        - 0.14067840576171875\n",
            "        - 0.09104156494140625\n",
            "        - 0.12384796142578125\n",
            "        - -1.3237037658691406\n",
            "        - 0.19292449951171875\n",
            "        - -1.4411802291870117\n",
            "        - -0.07440948486328125\n",
            "        - 0.29579925537109375\n",
            "        - 0.38067626953125\n",
            "        - 0.42807769775390625\n",
            "        - 0.10760498046875\n",
            "        - 0.24858856201171875\n",
            "        - -0.08761310577392578\n",
            "        - -1.2562446594238281\n",
            "        - 0.30068206787109375\n",
            "        - 0.5016937255859375\n",
            "        - 0.577606201171875\n",
            "        - 1.8821067810058594\n",
            "        - 0.44991302490234375\n",
            "        - 0.12234687805175781\n",
            "        - -0.348724365234375\n",
            "        - 0.04575538635253906\n",
            "        - 0.20534515380859375\n",
            "        - 37.20973587036133\n",
            "        - 0.37459564208984375\n",
            "        - 68.3455810546875\n",
            "        - 0.595550537109375\n",
            "        - 0.1790924072265625\n",
            "        - 2.0926742553710938\n",
            "        - 0.5563430786132812\n",
            "    num_agent_steps_sampled: 67000\n",
            "    num_agent_steps_trained: 528032\n",
            "    num_env_steps_sampled: 67000\n",
            "    num_env_steps_trained: 528032\n",
            "    num_target_updates: 133\n",
            "  iterations_since_restore: 67\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 67000\n",
            "  num_agent_steps_trained: 528032\n",
            "  num_env_steps_sampled: 67000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 528032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.91428571428573\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11316847813672475\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08703501987742764\n",
            "    mean_inference_ms: 1.3122013943793704\n",
            "    mean_raw_obs_processing_ms: 0.2052311567999018\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 159.48\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 159.48\n",
            "    episode_reward_min: 89.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 171\n",
            "      - 126\n",
            "      - 127\n",
            "      - 136\n",
            "      - 126\n",
            "      - 121\n",
            "      - 120\n",
            "      - 160\n",
            "      - 120\n",
            "      - 118\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 171.0\n",
            "      - 126.0\n",
            "      - 127.0\n",
            "      - 136.0\n",
            "      - 126.0\n",
            "      - 121.0\n",
            "      - 120.0\n",
            "      - 160.0\n",
            "      - 120.0\n",
            "      - 118.0\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11316847813672475\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08703501987742764\n",
            "      mean_inference_ms: 1.3122013943793704\n",
            "      mean_raw_obs_processing_ms: 0.2052311567999018\n",
            "  time_since_restore: 305.69829082489014\n",
            "  time_this_iter_s: 4.581073522567749\n",
            "  time_total_s: 305.69829082489014\n",
            "  timers:\n",
            "    learn_throughput: 4956.47\n",
            "    learn_time_ms: 6.456\n",
            "    load_throughput: 239162.024\n",
            "    load_time_ms: 0.134\n",
            "    synch_weights_time_ms: 0.049\n",
            "    training_iteration_time_ms: 18.421\n",
            "  timestamp: 1656961009\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 67000\n",
            "  training_iteration: 67\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:56:53 (running for 00:05:19.60)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         310.151</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">  160.51</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            160.51</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 69000\n",
            "  counters:\n",
            "    last_target_update_ts: 69000\n",
            "    num_agent_steps_sampled: 69000\n",
            "    num_agent_steps_trained: 544032\n",
            "    num_env_steps_sampled: 69000\n",
            "    num_env_steps_trained: 544032\n",
            "    num_target_updates: 137\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-56-58\n",
            "  done: false\n",
            "  episode_len_mean: 161.32\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 161.32\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 8\n",
            "  episodes_total: 585\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 69000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 82.59638977050781\n",
            "          mean_q: 65.83186340332031\n",
            "          mean_td_error: 7.751544952392578\n",
            "          min_q: 10.26429557800293\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.1756439208984375\n",
            "        - -1.6844205856323242\n",
            "        - -0.3958587646484375\n",
            "        - 71.00988006591797\n",
            "        - 1.4554176330566406\n",
            "        - -0.13964080810546875\n",
            "        - 18.925844192504883\n",
            "        - 0.086395263671875\n",
            "        - 0.32422637939453125\n",
            "        - -1.5131778717041016\n",
            "        - 0.28525543212890625\n",
            "        - -4.135292053222656\n",
            "        - -0.187103271484375\n",
            "        - -0.35411834716796875\n",
            "        - 0.124786376953125\n",
            "        - 0.1810302734375\n",
            "        - -3.26123046875\n",
            "        - 0.5887527465820312\n",
            "        - 0.46332550048828125\n",
            "        - 22.85348129272461\n",
            "        - 0.1334991455078125\n",
            "        - -0.34624481201171875\n",
            "        - 0.14369964599609375\n",
            "        - 0.506378173828125\n",
            "        - 0.263336181640625\n",
            "        - 70.6122817993164\n",
            "        - 74.09115600585938\n",
            "        - -0.8081169128417969\n",
            "        - 0.1374359130859375\n",
            "        - -1.7817630767822266\n",
            "        - 0.12023162841796875\n",
            "        - 0.174346923828125\n",
            "    num_agent_steps_sampled: 69000\n",
            "    num_agent_steps_trained: 544032\n",
            "    num_env_steps_sampled: 69000\n",
            "    num_env_steps_trained: 544032\n",
            "    num_target_updates: 137\n",
            "  iterations_since_restore: 69\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 69000\n",
            "  num_agent_steps_trained: 544032\n",
            "  num_env_steps_sampled: 69000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 544032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.94999999999999\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11319364374916717\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08704509020838717\n",
            "    mean_inference_ms: 1.312976157960331\n",
            "    mean_raw_obs_processing_ms: 0.20526207121122597\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 161.32\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 161.32\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 8\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 121\n",
            "      - 137\n",
            "      - 138\n",
            "      - 145\n",
            "      - 129\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 130\n",
            "      - 200\n",
            "      - 200\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      episode_reward:\n",
            "      - 121.0\n",
            "      - 137.0\n",
            "      - 138.0\n",
            "      - 145.0\n",
            "      - 129.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 130.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11319364374916717\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08704509020838717\n",
            "      mean_inference_ms: 1.312976157960331\n",
            "      mean_raw_obs_processing_ms: 0.20526207121122597\n",
            "  time_since_restore: 314.62490487098694\n",
            "  time_this_iter_s: 4.473560094833374\n",
            "  time_total_s: 314.62490487098694\n",
            "  timers:\n",
            "    learn_throughput: 4973.256\n",
            "    learn_time_ms: 6.434\n",
            "    load_throughput: 199580.265\n",
            "    load_time_ms: 0.16\n",
            "    synch_weights_time_ms: 0.056\n",
            "    training_iteration_time_ms: 18.667\n",
            "  timestamp: 1656961018\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 69000\n",
            "  training_iteration: 69\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:02 (running for 00:05:28.80)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">          319.22</td><td style=\"text-align: right;\">70000</td><td style=\"text-align: right;\">  162.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            162.46</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 71000\n",
            "  counters:\n",
            "    last_target_update_ts: 71000\n",
            "    num_agent_steps_sampled: 71000\n",
            "    num_agent_steps_trained: 560032\n",
            "    num_env_steps_sampled: 71000\n",
            "    num_env_steps_trained: 560032\n",
            "    num_target_updates: 141\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-57-07\n",
            "  done: false\n",
            "  episode_len_mean: 161.55\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 161.55\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 7\n",
            "  episodes_total: 598\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 71000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 82.41606140136719\n",
            "          mean_q: 69.37422180175781\n",
            "          mean_td_error: 4.383378028869629\n",
            "          min_q: 2.7348363399505615\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.40322113037109375\n",
            "        - -0.502685546875\n",
            "        - -0.04750823974609375\n",
            "        - 1.2272872924804688\n",
            "        - -0.29114532470703125\n",
            "        - 3.8907957077026367\n",
            "        - -0.03984832763671875\n",
            "        - -0.09987640380859375\n",
            "        - -0.264923095703125\n",
            "        - 0.5278472900390625\n",
            "        - 0.0021514892578125\n",
            "        - -0.40103912353515625\n",
            "        - 0.47979736328125\n",
            "        - -0.01985931396484375\n",
            "        - -0.31240081787109375\n",
            "        - -0.0467529296875\n",
            "        - 1.4671965837478638\n",
            "        - -0.25441741943359375\n",
            "        - -0.02742767333984375\n",
            "        - 2.0131263732910156\n",
            "        - -0.22544097900390625\n",
            "        - 0.215484619140625\n",
            "        - -0.17419052124023438\n",
            "        - -0.23046112060546875\n",
            "        - -0.21154022216796875\n",
            "        - 0.209014892578125\n",
            "        - -0.18402099609375\n",
            "        - 68.39251708984375\n",
            "        - 65.85401153564453\n",
            "        - -0.1998138427734375\n",
            "        - -0.18810272216796875\n",
            "        - 0.113555908203125\n",
            "    num_agent_steps_sampled: 71000\n",
            "    num_agent_steps_trained: 560032\n",
            "    num_env_steps_sampled: 71000\n",
            "    num_env_steps_trained: 560032\n",
            "    num_target_updates: 141\n",
            "  iterations_since_restore: 71\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 71000\n",
            "  num_agent_steps_trained: 560032\n",
            "  num_env_steps_sampled: 71000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 560032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.53333333333333\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11320156556887344\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08704680024652302\n",
            "    mean_inference_ms: 1.3136406422512996\n",
            "    mean_raw_obs_processing_ms: 0.20529096108720413\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 161.55\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 161.55\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 7\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 146\n",
            "      - 200\n",
            "      - 200\n",
            "      - 187\n",
            "      - 130\n",
            "      - 127\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 187.0\n",
            "      - 130.0\n",
            "      - 127.0\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11320156556887344\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08704680024652302\n",
            "      mean_inference_ms: 1.3136406422512996\n",
            "      mean_raw_obs_processing_ms: 0.20529096108720413\n",
            "  time_since_restore: 323.7284109592438\n",
            "  time_this_iter_s: 4.508586406707764\n",
            "  time_total_s: 323.7284109592438\n",
            "  timers:\n",
            "    learn_throughput: 4669.433\n",
            "    learn_time_ms: 6.853\n",
            "    load_throughput: 227564.815\n",
            "    load_time_ms: 0.141\n",
            "    synch_weights_time_ms: 0.056\n",
            "    training_iteration_time_ms: 19.669\n",
            "  timestamp: 1656961027\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 71000\n",
            "  training_iteration: 71\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:11 (running for 00:05:37.81)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         328.255</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">  155.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            155.84</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 73000\n",
            "  counters:\n",
            "    last_target_update_ts: 73000\n",
            "    num_agent_steps_sampled: 73000\n",
            "    num_agent_steps_trained: 576032\n",
            "    num_env_steps_sampled: 73000\n",
            "    num_env_steps_trained: 576032\n",
            "    num_target_updates: 145\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-57-16\n",
            "  done: false\n",
            "  episode_len_mean: 155.56\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 155.56\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 6\n",
            "  episodes_total: 612\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 73000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 83.33466339111328\n",
            "          mean_q: 62.79780578613281\n",
            "          mean_td_error: 7.058549880981445\n",
            "          min_q: 3.171785831451416\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.23777008056640625\n",
            "        - 2.370636463165283\n",
            "        - -1.2186508178710938\n",
            "        - -0.107421875\n",
            "        - -0.086181640625\n",
            "        - -0.02655029296875\n",
            "        - -4.683315753936768\n",
            "        - -0.8868255615234375\n",
            "        - -0.33164215087890625\n",
            "        - 74.29684448242188\n",
            "        - 0.17797088623046875\n",
            "        - -0.23537445068359375\n",
            "        - 0.0168304443359375\n",
            "        - -0.36893463134765625\n",
            "        - 0.15435028076171875\n",
            "        - 78.83941650390625\n",
            "        - -0.5168991088867188\n",
            "        - -0.14725494384765625\n",
            "        - -0.21695709228515625\n",
            "        - 0.25463104248046875\n",
            "        - -0.08553695678710938\n",
            "        - -0.116973876953125\n",
            "        - -3.9369277954101562\n",
            "        - 0.6435775756835938\n",
            "        - -0.3829498291015625\n",
            "        - -0.275177001953125\n",
            "        - -0.390869140625\n",
            "        - 79.89830017089844\n",
            "        - 1.1904945373535156\n",
            "        - 2.1088218688964844\n",
            "        - -0.2592658996582031\n",
            "        - -0.0423583984375\n",
            "    num_agent_steps_sampled: 73000\n",
            "    num_agent_steps_trained: 576032\n",
            "    num_env_steps_sampled: 73000\n",
            "    num_env_steps_trained: 576032\n",
            "    num_target_updates: 145\n",
            "  iterations_since_restore: 73\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 73000\n",
            "  num_agent_steps_trained: 576032\n",
            "  num_env_steps_sampled: 73000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 576032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.6\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11317635568965181\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0870280633237077\n",
            "    mean_inference_ms: 1.313441082402596\n",
            "    mean_raw_obs_processing_ms: 0.2052415006378521\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 155.56\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 155.56\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 6\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 135\n",
            "      - 119\n",
            "      - 149\n",
            "      - 127\n",
            "      - 158\n",
            "      - 98\n",
            "      - 94\n",
            "      - 89\n",
            "      - 89\n",
            "      - 100\n",
            "      - 101\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      episode_reward:\n",
            "      - 135.0\n",
            "      - 119.0\n",
            "      - 149.0\n",
            "      - 127.0\n",
            "      - 158.0\n",
            "      - 98.0\n",
            "      - 94.0\n",
            "      - 89.0\n",
            "      - 89.0\n",
            "      - 100.0\n",
            "      - 101.0\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11317635568965181\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.0870280633237077\n",
            "      mean_inference_ms: 1.313441082402596\n",
            "      mean_raw_obs_processing_ms: 0.2052415006378521\n",
            "  time_since_restore: 332.7950687408447\n",
            "  time_this_iter_s: 4.539783716201782\n",
            "  time_total_s: 332.7950687408447\n",
            "  timers:\n",
            "    learn_throughput: 5015.629\n",
            "    learn_time_ms: 6.38\n",
            "    load_throughput: 138183.597\n",
            "    load_time_ms: 0.232\n",
            "    synch_weights_time_ms: 0.058\n",
            "    training_iteration_time_ms: 18.739\n",
            "  timestamp: 1656961036\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 73000\n",
            "  training_iteration: 73\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:21 (running for 00:05:47.04)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         337.437</td><td style=\"text-align: right;\">74000</td><td style=\"text-align: right;\">  158.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            158.44</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 75000\n",
            "  counters:\n",
            "    last_target_update_ts: 75000\n",
            "    num_agent_steps_sampled: 75000\n",
            "    num_agent_steps_trained: 592032\n",
            "    num_env_steps_sampled: 75000\n",
            "    num_env_steps_trained: 592032\n",
            "    num_target_updates: 149\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-57-25\n",
            "  done: false\n",
            "  episode_len_mean: 163.71\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 163.71\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 623\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 75000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 83.72594451904297\n",
            "          mean_q: 77.90846252441406\n",
            "          mean_td_error: 4.3538360595703125\n",
            "          min_q: 57.134708404541016\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.18317413330078125\n",
            "        - -0.5385208129882812\n",
            "        - 0.0522613525390625\n",
            "        - 0.0150909423828125\n",
            "        - 0.2898101806640625\n",
            "        - 0.7786140441894531\n",
            "        - -0.6668014526367188\n",
            "        - -0.6017227172851562\n",
            "        - -0.1587677001953125\n",
            "        - -0.592681884765625\n",
            "        - -0.5763168334960938\n",
            "        - -0.167083740234375\n",
            "        - -0.455474853515625\n",
            "        - 1.0568389892578125\n",
            "        - -0.2933349609375\n",
            "        - -0.18505859375\n",
            "        - -0.5190658569335938\n",
            "        - 71.92984008789062\n",
            "        - -0.25331878662109375\n",
            "        - -0.4521942138671875\n",
            "        - 0.34987640380859375\n",
            "        - 0.30694580078125\n",
            "        - -0.8865280151367188\n",
            "        - -0.36711883544921875\n",
            "        - -0.08777618408203125\n",
            "        - 0.1256561279296875\n",
            "        - 72.96635437011719\n",
            "        - -0.6512222290039062\n",
            "        - -0.420745849609375\n",
            "        - -0.5603179931640625\n",
            "        - -0.17079925537109375\n",
            "        - 0.23947906494140625\n",
            "    num_agent_steps_sampled: 75000\n",
            "    num_agent_steps_trained: 592032\n",
            "    num_env_steps_sampled: 75000\n",
            "    num_env_steps_trained: 592032\n",
            "    num_target_updates: 149\n",
            "  iterations_since_restore: 75\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 75000\n",
            "  num_agent_steps_trained: 592032\n",
            "  num_env_steps_sampled: 75000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 592032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.49999999999999\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1131322233538555\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08699783797023429\n",
            "    mean_inference_ms: 1.3130243738129956\n",
            "    mean_raw_obs_processing_ms: 0.2051547780917337\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 163.71\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 163.71\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 118\n",
            "      - 104\n",
            "      - 100\n",
            "      - 115\n",
            "      - 168\n",
            "      - 148\n",
            "      - 131\n",
            "      - 123\n",
            "      - 200\n",
            "      - 135\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 118.0\n",
            "      - 104.0\n",
            "      - 100.0\n",
            "      - 115.0\n",
            "      - 168.0\n",
            "      - 148.0\n",
            "      - 131.0\n",
            "      - 123.0\n",
            "      - 200.0\n",
            "      - 135.0\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1131322233538555\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08699783797023429\n",
            "      mean_inference_ms: 1.3130243738129956\n",
            "      mean_raw_obs_processing_ms: 0.2051547780917337\n",
            "  time_since_restore: 342.04737639427185\n",
            "  time_this_iter_s: 4.610832691192627\n",
            "  time_total_s: 342.04737639427185\n",
            "  timers:\n",
            "    learn_throughput: 4510.126\n",
            "    learn_time_ms: 7.095\n",
            "    load_throughput: 233584.629\n",
            "    load_time_ms: 0.137\n",
            "    synch_weights_time_ms: 0.063\n",
            "    training_iteration_time_ms: 20.072\n",
            "  timestamp: 1656961045\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 75000\n",
            "  training_iteration: 75\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:30 (running for 00:05:56.30)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         346.574</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">  167.66</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            167.66</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 77000\n",
            "  counters:\n",
            "    last_target_update_ts: 77000\n",
            "    num_agent_steps_sampled: 77000\n",
            "    num_agent_steps_trained: 608032\n",
            "    num_env_steps_sampled: 77000\n",
            "    num_env_steps_trained: 608032\n",
            "    num_target_updates: 153\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-57-34\n",
            "  done: false\n",
            "  episode_len_mean: 170.29\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 170.29\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 633\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 77000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 85.36351776123047\n",
            "          mean_q: 61.137447357177734\n",
            "          mean_td_error: 5.643158912658691\n",
            "          min_q: 1.471008539199829\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.6509628295898438\n",
            "        - 0.5820693969726562\n",
            "        - 0.802581787109375\n",
            "        - 0.33269500732421875\n",
            "        - 0.37268829345703125\n",
            "        - 0.0158538818359375\n",
            "        - 1.25799560546875\n",
            "        - 0.22512054443359375\n",
            "        - 0.5078811645507812\n",
            "        - 0.25252532958984375\n",
            "        - -0.643223762512207\n",
            "        - -0.17232513427734375\n",
            "        - 84.17842864990234\n",
            "        - 0.5834274291992188\n",
            "        - -0.32743072509765625\n",
            "        - -0.5551872253417969\n",
            "        - -2.2956247329711914\n",
            "        - 1.150221824645996\n",
            "        - 0.6216964721679688\n",
            "        - -1.1837005615234375\n",
            "        - 73.88955688476562\n",
            "        - 0.6464614868164062\n",
            "        - 0.28864288330078125\n",
            "        - 0.4710085391998291\n",
            "        - 0.536468505859375\n",
            "        - 0.8334732055664062\n",
            "        - -0.25518035888671875\n",
            "        - 21.011987686157227\n",
            "        - 1.0845069885253906\n",
            "        - 0.527252197265625\n",
            "        - 0.422882080078125\n",
            "        - -3.930713653564453\n",
            "    num_agent_steps_sampled: 77000\n",
            "    num_agent_steps_trained: 608032\n",
            "    num_env_steps_sampled: 77000\n",
            "    num_env_steps_trained: 608032\n",
            "    num_target_updates: 153\n",
            "  iterations_since_restore: 77\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 77000\n",
            "  num_agent_steps_trained: 608032\n",
            "  num_env_steps_sampled: 77000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 608032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 67.24285714285715\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11309369085623314\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08696820972008763\n",
            "    mean_inference_ms: 1.3126452897074576\n",
            "    mean_raw_obs_processing_ms: 0.20506689465777445\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 170.29\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 170.29\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 134\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 149\n",
            "      - 141\n",
            "      - 169\n",
            "      - 174\n",
            "      - 200\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 134.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 149.0\n",
            "      - 141.0\n",
            "      - 169.0\n",
            "      - 174.0\n",
            "      - 200.0\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11309369085623314\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08696820972008763\n",
            "      mean_inference_ms: 1.3126452897074576\n",
            "      mean_raw_obs_processing_ms: 0.20506689465777445\n",
            "  time_since_restore: 351.08488035202026\n",
            "  time_this_iter_s: 4.511177062988281\n",
            "  time_total_s: 351.08488035202026\n",
            "  timers:\n",
            "    learn_throughput: 5574.59\n",
            "    learn_time_ms: 5.74\n",
            "    load_throughput: 207382.151\n",
            "    load_time_ms: 0.154\n",
            "    synch_weights_time_ms: 0.051\n",
            "    training_iteration_time_ms: 17.568\n",
            "  timestamp: 1656961054\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 77000\n",
            "  training_iteration: 77\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:39 (running for 00:06:05.25)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         355.544</td><td style=\"text-align: right;\">78000</td><td style=\"text-align: right;\">     170</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">               170</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 79000\n",
            "  counters:\n",
            "    last_target_update_ts: 79000\n",
            "    num_agent_steps_sampled: 79000\n",
            "    num_agent_steps_trained: 624032\n",
            "    num_env_steps_sampled: 79000\n",
            "    num_env_steps_trained: 624032\n",
            "    num_target_updates: 157\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-57-43\n",
            "  done: false\n",
            "  episode_len_mean: 170.25\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 170.25\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 6\n",
            "  episodes_total: 644\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 79000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 86.66525268554688\n",
            "          mean_q: 78.46823120117188\n",
            "          mean_td_error: 2.8062920570373535\n",
            "          min_q: 32.7952995300293\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.55706787109375\n",
            "        - 0.4897499084472656\n",
            "        - 0.16715240478515625\n",
            "        - 0.5474472045898438\n",
            "        - -0.20246124267578125\n",
            "        - 0.2600555419921875\n",
            "        - -0.295654296875\n",
            "        - 0.28630828857421875\n",
            "        - 0.36431884765625\n",
            "        - 0.5943222045898438\n",
            "        - 77.70877075195312\n",
            "        - 0.5491180419921875\n",
            "        - -0.078125\n",
            "        - -0.32842254638671875\n",
            "        - 0.2619476318359375\n",
            "        - 0.3812103271484375\n",
            "        - 0.3860015869140625\n",
            "        - 0.508148193359375\n",
            "        - 0.6420135498046875\n",
            "        - 0.4192047119140625\n",
            "        - -0.288482666015625\n",
            "        - 0.42099761962890625\n",
            "        - 0.54229736328125\n",
            "        - 2.3598175048828125\n",
            "        - 0.46891021728515625\n",
            "        - 0.531829833984375\n",
            "        - 0.375213623046875\n",
            "        - 0.7379684448242188\n",
            "        - 0.09624481201171875\n",
            "        - 0.7970352172851562\n",
            "        - 0.2279205322265625\n",
            "        - 0.31341552734375\n",
            "    num_agent_steps_sampled: 79000\n",
            "    num_agent_steps_trained: 624032\n",
            "    num_env_steps_sampled: 79000\n",
            "    num_env_steps_trained: 624032\n",
            "    num_target_updates: 157\n",
            "  iterations_since_restore: 79\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 79000\n",
            "  num_agent_steps_trained: 624032\n",
            "  num_env_steps_sampled: 79000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 624032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.92857142857143\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.113046283563918\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08693286625863389\n",
            "    mean_inference_ms: 1.3122006254262386\n",
            "    mean_raw_obs_processing_ms: 0.20496764214260485\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 170.25\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 170.25\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 6\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 170\n",
            "      - 126\n",
            "      - 153\n",
            "      - 131\n",
            "      - 95\n",
            "      - 200\n",
            "      - 146\n",
            "      - 143\n",
            "      - 143\n",
            "      - 200\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 170.0\n",
            "      - 126.0\n",
            "      - 153.0\n",
            "      - 131.0\n",
            "      - 95.0\n",
            "      - 200.0\n",
            "      - 146.0\n",
            "      - 143.0\n",
            "      - 143.0\n",
            "      - 200.0\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.113046283563918\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08693286625863389\n",
            "      mean_inference_ms: 1.3122006254262386\n",
            "      mean_raw_obs_processing_ms: 0.20496764214260485\n",
            "  time_since_restore: 360.0889563560486\n",
            "  time_this_iter_s: 4.544735431671143\n",
            "  time_total_s: 360.0889563560486\n",
            "  timers:\n",
            "    learn_throughput: 5273.615\n",
            "    learn_time_ms: 6.068\n",
            "    load_throughput: 216410.397\n",
            "    load_time_ms: 0.148\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 18.016\n",
            "  timestamp: 1656961063\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 79000\n",
            "  training_iteration: 79\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:48 (running for 00:06:14.47)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         364.718</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">   173.5</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">             173.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 81000\n",
            "  counters:\n",
            "    last_target_update_ts: 81000\n",
            "    num_agent_steps_sampled: 81000\n",
            "    num_agent_steps_trained: 640032\n",
            "    num_env_steps_sampled: 81000\n",
            "    num_env_steps_trained: 640032\n",
            "    num_target_updates: 161\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-57-53\n",
            "  done: false\n",
            "  episode_len_mean: 175.18\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 175.18\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 654\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 81000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 87.49579620361328\n",
            "          mean_q: 70.10609436035156\n",
            "          mean_td_error: 6.339645862579346\n",
            "          min_q: 24.874563217163086\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.486175537109375\n",
            "        - 41.70927810668945\n",
            "        - 0.08899688720703125\n",
            "        - -0.3235435485839844\n",
            "        - -0.31632232666015625\n",
            "        - 0.01361846923828125\n",
            "        - -2.245494842529297\n",
            "        - 0.147003173828125\n",
            "        - -0.26802825927734375\n",
            "        - 0.5532283782958984\n",
            "        - -0.36978912353515625\n",
            "        - -0.15897369384765625\n",
            "        - 0.3532257080078125\n",
            "        - -0.03903961181640625\n",
            "        - -0.16239166259765625\n",
            "        - -0.04608917236328125\n",
            "        - 78.25812530517578\n",
            "        - -0.08612060546875\n",
            "        - 0.8341026306152344\n",
            "        - 23.874563217163086\n",
            "        - -2.2786331176757812\n",
            "        - 0.12157440185546875\n",
            "        - 2.4363479614257812\n",
            "        - 59.424591064453125\n",
            "        - 0.119873046875\n",
            "        - -0.02400970458984375\n",
            "        - 0.16574859619140625\n",
            "        - 0.048431396484375\n",
            "        - 0.258880615234375\n",
            "        - 0.37107086181640625\n",
            "        - -0.13228607177734375\n",
            "        - 0.05455780029296875\n",
            "    num_agent_steps_sampled: 81000\n",
            "    num_agent_steps_trained: 640032\n",
            "    num_env_steps_sampled: 81000\n",
            "    num_env_steps_trained: 640032\n",
            "    num_target_updates: 161\n",
            "  iterations_since_restore: 81\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 81000\n",
            "  num_agent_steps_trained: 640032\n",
            "  num_env_steps_sampled: 81000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 640032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.12857142857142\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11300367163200996\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08690095329399919\n",
            "    mean_inference_ms: 1.3117771604547597\n",
            "    mean_raw_obs_processing_ms: 0.20488898549888762\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 175.18\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 175.18\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 139\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 145\n",
            "      - 200\n",
            "      - 200\n",
            "      - 172\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 139.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 145.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 172.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11300367163200996\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08690095329399919\n",
            "      mean_inference_ms: 1.3117771604547597\n",
            "      mean_raw_obs_processing_ms: 0.20488898549888762\n",
            "  time_since_restore: 369.28935623168945\n",
            "  time_this_iter_s: 4.571461915969849\n",
            "  time_total_s: 369.28935623168945\n",
            "  timers:\n",
            "    learn_throughput: 5278.759\n",
            "    learn_time_ms: 6.062\n",
            "    load_throughput: 222878.99\n",
            "    load_time_ms: 0.144\n",
            "    synch_weights_time_ms: 0.053\n",
            "    training_iteration_time_ms: 17.897\n",
            "  timestamp: 1656961073\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 81000\n",
            "  training_iteration: 81\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:57:57 (running for 00:06:23.87)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         373.987</td><td style=\"text-align: right;\">82000</td><td style=\"text-align: right;\">  175.79</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            175.79</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 83000\n",
            "  counters:\n",
            "    last_target_update_ts: 83000\n",
            "    num_agent_steps_sampled: 83000\n",
            "    num_agent_steps_trained: 656032\n",
            "    num_env_steps_sampled: 83000\n",
            "    num_env_steps_trained: 656032\n",
            "    num_target_updates: 165\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-02\n",
            "  done: false\n",
            "  episode_len_mean: 176.62\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 176.62\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 664\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 83000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 87.87278747558594\n",
            "          mean_q: 73.82772064208984\n",
            "          mean_td_error: 14.268775939941406\n",
            "          min_q: 28.876049041748047\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 74.37753295898438\n",
            "        - 0.0062103271484375\n",
            "        - -0.15877532958984375\n",
            "        - 80.7261734008789\n",
            "        - 39.0081672668457\n",
            "        - -0.10767364501953125\n",
            "        - -0.04286956787109375\n",
            "        - 27.876049041748047\n",
            "        - 0.18145751953125\n",
            "        - 78.1828842163086\n",
            "        - -0.286712646484375\n",
            "        - 0.10961151123046875\n",
            "        - -0.15834808349609375\n",
            "        - 1.3163986206054688\n",
            "        - -0.20612335205078125\n",
            "        - 1.9385643005371094\n",
            "        - -0.167510986328125\n",
            "        - 72.04791259765625\n",
            "        - -0.00274658203125\n",
            "        - -0.7831649780273438\n",
            "        - 0.08002471923828125\n",
            "        - 0.03189849853515625\n",
            "        - 79.60389709472656\n",
            "        - -0.00621795654296875\n",
            "        - 2.022411346435547\n",
            "        - -0.002044677734375\n",
            "        - -0.111541748046875\n",
            "        - -0.172882080078125\n",
            "        - 0.024749755859375\n",
            "        - 1.4484634399414062\n",
            "        - -0.1470184326171875\n",
            "        - -0.0279541015625\n",
            "    num_agent_steps_sampled: 83000\n",
            "    num_agent_steps_trained: 656032\n",
            "    num_env_steps_sampled: 83000\n",
            "    num_env_steps_trained: 656032\n",
            "    num_target_updates: 165\n",
            "  iterations_since_restore: 83\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 83000\n",
            "  num_agent_steps_trained: 656032\n",
            "  num_env_steps_sampled: 83000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 656032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.42857142857143\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11296753413430323\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08687384709312074\n",
            "    mean_inference_ms: 1.3114623968770858\n",
            "    mean_raw_obs_processing_ms: 0.20482625983356612\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 176.62\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 176.62\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11296753413430323\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08687384709312074\n",
            "      mean_inference_ms: 1.3114623968770858\n",
            "      mean_raw_obs_processing_ms: 0.20482625983356612\n",
            "  time_since_restore: 378.5693202018738\n",
            "  time_this_iter_s: 4.582049608230591\n",
            "  time_total_s: 378.5693202018738\n",
            "  timers:\n",
            "    learn_throughput: 5145.951\n",
            "    learn_time_ms: 6.218\n",
            "    load_throughput: 213111.667\n",
            "    load_time_ms: 0.15\n",
            "    synch_weights_time_ms: 0.055\n",
            "    training_iteration_time_ms: 18.547\n",
            "  timestamp: 1656961082\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 83000\n",
            "  training_iteration: 83\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:07 (running for 00:06:33.07)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         383.208</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">  176.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            176.62</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 85000\n",
            "  counters:\n",
            "    last_target_update_ts: 85000\n",
            "    num_agent_steps_sampled: 85000\n",
            "    num_agent_steps_trained: 672032\n",
            "    num_env_steps_sampled: 85000\n",
            "    num_env_steps_trained: 672032\n",
            "    num_target_updates: 169\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-11\n",
            "  done: false\n",
            "  episode_len_mean: 176.62\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 176.62\n",
            "  episode_reward_min: 44.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 674\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 85000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 88.09513092041016\n",
            "          mean_q: 72.56663513183594\n",
            "          mean_td_error: 8.071166038513184\n",
            "          min_q: 10.37610149383545\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.036712646484375\n",
            "        - 2.8315000534057617\n",
            "        - 3.1461181640625\n",
            "        - -0.25818634033203125\n",
            "        - 0.12987518310546875\n",
            "        - -0.0559234619140625\n",
            "        - 82.64024353027344\n",
            "        - -0.6401138305664062\n",
            "        - 0.269317626953125\n",
            "        - 0.29602813720703125\n",
            "        - 0.1085357666015625\n",
            "        - -0.27008819580078125\n",
            "        - 0.0518951416015625\n",
            "        - 0.12887191772460938\n",
            "        - 0.000823974609375\n",
            "        - -0.1253204345703125\n",
            "        - -0.479095458984375\n",
            "        - -2.0529117584228516\n",
            "        - -0.18241119384765625\n",
            "        - 0.23564910888671875\n",
            "        - -0.0452117919921875\n",
            "        - -0.215179443359375\n",
            "        - 84.45504760742188\n",
            "        - -0.37650299072265625\n",
            "        - -0.1718597412109375\n",
            "        - -0.13722991943359375\n",
            "        - -0.2552490234375\n",
            "        - 81.76110076904297\n",
            "        - 9.451011657714844\n",
            "        - -0.4730987548828125\n",
            "        - -1.5214519500732422\n",
            "        - -0.00559234619140625\n",
            "    num_agent_steps_sampled: 85000\n",
            "    num_agent_steps_trained: 672032\n",
            "    num_env_steps_sampled: 85000\n",
            "    num_env_steps_trained: 672032\n",
            "    num_target_updates: 169\n",
            "  iterations_since_restore: 85\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 85000\n",
            "  num_agent_steps_trained: 672032\n",
            "  num_env_steps_sampled: 85000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 672032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.75000000000001\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11294402012305933\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08685889321834765\n",
            "    mean_inference_ms: 1.311263403608806\n",
            "    mean_raw_obs_processing_ms: 0.20477933110605637\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 176.62\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 176.62\n",
            "    episode_reward_min: 44.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 185\n",
            "      - 131\n",
            "      - 115\n",
            "      - 44\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 185.0\n",
            "      - 131.0\n",
            "      - 115.0\n",
            "      - 44.0\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11294402012305933\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08685889321834765\n",
            "      mean_inference_ms: 1.311263403608806\n",
            "      mean_raw_obs_processing_ms: 0.20477933110605637\n",
            "  time_since_restore: 387.7344808578491\n",
            "  time_this_iter_s: 4.526102304458618\n",
            "  time_total_s: 387.7344808578491\n",
            "  timers:\n",
            "    learn_throughput: 5626.021\n",
            "    learn_time_ms: 5.688\n",
            "    load_throughput: 232290.98\n",
            "    load_time_ms: 0.138\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 17.494\n",
            "  timestamp: 1656961091\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 85000\n",
            "  training_iteration: 85\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:16 (running for 00:06:42.28)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         392.366</td><td style=\"text-align: right;\">86000</td><td style=\"text-align: right;\">  176.37</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  44</td><td style=\"text-align: right;\">            176.37</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 87000\n",
            "  counters:\n",
            "    last_target_update_ts: 87000\n",
            "    num_agent_steps_sampled: 87000\n",
            "    num_agent_steps_trained: 688032\n",
            "    num_env_steps_sampled: 87000\n",
            "    num_env_steps_trained: 688032\n",
            "    num_target_updates: 173\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-20\n",
            "  done: false\n",
            "  episode_len_mean: 179.76\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 179.76\n",
            "  episode_reward_min: 48.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 684\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 87000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 88.47746276855469\n",
            "          mean_q: 73.65678405761719\n",
            "          mean_td_error: 7.356432914733887\n",
            "          min_q: 4.155690670013428\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.062408447265625\n",
            "        - 0.0762939453125\n",
            "        - -0.09658050537109375\n",
            "        - -0.03894805908203125\n",
            "        - -0.130340576171875\n",
            "        - -0.657440185546875\n",
            "        - 0.0274505615234375\n",
            "        - 79.968994140625\n",
            "        - -0.0562896728515625\n",
            "        - -3.549713134765625\n",
            "        - 0.18441009521484375\n",
            "        - 0.44378662109375\n",
            "        - 0.0084075927734375\n",
            "        - -0.00733184814453125\n",
            "        - 0.4877967834472656\n",
            "        - 81.2021713256836\n",
            "        - -0.17132568359375\n",
            "        - 0.33875465393066406\n",
            "        - 0.053497314453125\n",
            "        - -0.5282211303710938\n",
            "        - 0.0029144287109375\n",
            "        - -0.0849609375\n",
            "        - 83.13420867919922\n",
            "        - 0.12952423095703125\n",
            "        - 3.1556906700134277\n",
            "        - 0.23902130126953125\n",
            "        - 0.13491058349609375\n",
            "        - 0.22374725341796875\n",
            "        - 0.21605682373046875\n",
            "        - -4.3838958740234375\n",
            "        - 0.5399932861328125\n",
            "        - -5.394355773925781\n",
            "    num_agent_steps_sampled: 87000\n",
            "    num_agent_steps_trained: 688032\n",
            "    num_env_steps_sampled: 87000\n",
            "    num_env_steps_trained: 688032\n",
            "    num_target_updates: 173\n",
            "  iterations_since_restore: 87\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 87000\n",
            "  num_agent_steps_trained: 688032\n",
            "  num_env_steps_sampled: 87000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 688032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.15\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11293017415243152\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08685606342246074\n",
            "    mean_inference_ms: 1.3111701451585915\n",
            "    mean_raw_obs_processing_ms: 0.20474286279513645\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 179.76\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 179.76\n",
            "    episode_reward_min: 48.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 48\n",
            "      - 135\n",
            "      - 200\n",
            "      - 200\n",
            "      - 125\n",
            "      - 119\n",
            "      - 132\n",
            "      - 105\n",
            "      - 200\n",
            "      - 200\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 48.0\n",
            "      - 135.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 125.0\n",
            "      - 119.0\n",
            "      - 132.0\n",
            "      - 105.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11293017415243152\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08685606342246074\n",
            "      mean_inference_ms: 1.3111701451585915\n",
            "      mean_raw_obs_processing_ms: 0.20474286279513645\n",
            "  time_since_restore: 396.9038646221161\n",
            "  time_this_iter_s: 4.538245677947998\n",
            "  time_total_s: 396.9038646221161\n",
            "  timers:\n",
            "    learn_throughput: 5686.517\n",
            "    learn_time_ms: 5.627\n",
            "    load_throughput: 209159.62\n",
            "    load_time_ms: 0.153\n",
            "    synch_weights_time_ms: 0.05\n",
            "    training_iteration_time_ms: 17.145\n",
            "  timestamp: 1656961100\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 87000\n",
            "  training_iteration: 87\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:25 (running for 00:06:51.61)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         401.574</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">  182.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            182.68</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 89000\n",
            "  counters:\n",
            "    last_target_update_ts: 89000\n",
            "    num_agent_steps_sampled: 89000\n",
            "    num_agent_steps_trained: 704032\n",
            "    num_env_steps_sampled: 89000\n",
            "    num_env_steps_trained: 704032\n",
            "    num_target_updates: 177\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-30\n",
            "  done: false\n",
            "  episode_len_mean: 185.12\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 185.12\n",
            "  episode_reward_min: 89.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 694\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 89000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 86.86541748046875\n",
            "          mean_q: 79.76942443847656\n",
            "          mean_td_error: 6.514219284057617\n",
            "          min_q: 31.26267433166504\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.426544189453125\n",
            "        - -0.35765838623046875\n",
            "        - -0.29987335205078125\n",
            "        - -0.1980743408203125\n",
            "        - -0.6194381713867188\n",
            "        - -0.1732635498046875\n",
            "        - -1.964895248413086\n",
            "        - -0.47830963134765625\n",
            "        - -0.038116455078125\n",
            "        - -0.26502227783203125\n",
            "        - 0.2875823974609375\n",
            "        - -0.269622802734375\n",
            "        - -0.443389892578125\n",
            "        - -0.6081771850585938\n",
            "        - 78.68140411376953\n",
            "        - 0.508758544921875\n",
            "        - -0.4764404296875\n",
            "        - 0.0160675048828125\n",
            "        - 0.07712554931640625\n",
            "        - -0.0901947021484375\n",
            "        - -0.6708145141601562\n",
            "        - -0.10660552978515625\n",
            "        - 76.4775390625\n",
            "        - -0.46453094482421875\n",
            "        - 1.0849838256835938\n",
            "        - -0.26818084716796875\n",
            "        - -0.2674560546875\n",
            "        - 59.18375015258789\n",
            "        - 2.2152976989746094\n",
            "        - -0.69122314453125\n",
            "        - -0.6170425415039062\n",
            "        - -0.2826080322265625\n",
            "    num_agent_steps_sampled: 89000\n",
            "    num_agent_steps_trained: 704032\n",
            "    num_env_steps_sampled: 89000\n",
            "    num_env_steps_trained: 704032\n",
            "    num_target_updates: 177\n",
            "  iterations_since_restore: 89\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 89000\n",
            "  num_agent_steps_trained: 704032\n",
            "  num_env_steps_sampled: 89000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 704032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.8142857142857\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1129166559942733\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08685546395143696\n",
            "    mean_inference_ms: 1.3111847000609016\n",
            "    mean_raw_obs_processing_ms: 0.20469747354432283\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 185.12\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 185.12\n",
            "    episode_reward_min: 89.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 148\n",
            "      - 153\n",
            "      - 111\n",
            "      - 111\n",
            "      - 118\n",
            "      - 123\n",
            "      - 167\n",
            "      - 129\n",
            "      - 142\n",
            "      - 89\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 148.0\n",
            "      - 153.0\n",
            "      - 111.0\n",
            "      - 111.0\n",
            "      - 118.0\n",
            "      - 123.0\n",
            "      - 167.0\n",
            "      - 129.0\n",
            "      - 142.0\n",
            "      - 89.0\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.1129166559942733\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08685546395143696\n",
            "      mean_inference_ms: 1.3111847000609016\n",
            "      mean_raw_obs_processing_ms: 0.20469747354432283\n",
            "  time_since_restore: 406.20993089675903\n",
            "  time_this_iter_s: 4.635944843292236\n",
            "  time_total_s: 406.20993089675903\n",
            "  timers:\n",
            "    learn_throughput: 5614.888\n",
            "    learn_time_ms: 5.699\n",
            "    load_throughput: 240533.563\n",
            "    load_time_ms: 0.133\n",
            "    synch_weights_time_ms: 0.052\n",
            "    training_iteration_time_ms: 17.615\n",
            "  timestamp: 1656961110\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 89000\n",
            "  training_iteration: 89\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:34 (running for 00:07:00.76)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         410.754</td><td style=\"text-align: right;\">90000</td><td style=\"text-align: right;\">  188.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            188.71</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 91000\n",
            "  counters:\n",
            "    last_target_update_ts: 91000\n",
            "    num_agent_steps_sampled: 91000\n",
            "    num_agent_steps_trained: 720032\n",
            "    num_env_steps_sampled: 91000\n",
            "    num_env_steps_trained: 720032\n",
            "    num_target_updates: 181\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-39\n",
            "  done: false\n",
            "  episode_len_mean: 192.21\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 192.21\n",
            "  episode_reward_min: 103.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 704\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 91000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 89.90547180175781\n",
            "          mean_q: 79.09740447998047\n",
            "          mean_td_error: 3.8559443950653076\n",
            "          min_q: 44.06196975708008\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.2546539306640625\n",
            "        - -0.1498565673828125\n",
            "        - 0.1105194091796875\n",
            "        - 0.14475250244140625\n",
            "        - -0.32947540283203125\n",
            "        - 0.7389984130859375\n",
            "        - -0.5573196411132812\n",
            "        - 81.82362365722656\n",
            "        - -0.02166748046875\n",
            "        - 0.39141845703125\n",
            "        - -1.55059814453125\n",
            "        - 0.4216156005859375\n",
            "        - 0.16791534423828125\n",
            "        - -0.4632720947265625\n",
            "        - -1.5537605285644531\n",
            "        - -8.549285888671875\n",
            "        - 0.3640632629394531\n",
            "        - 0.31640625\n",
            "        - 0.14444732666015625\n",
            "        - 0.0748138427734375\n",
            "        - 1.0902099609375\n",
            "        - 0.0841064453125\n",
            "        - -1.2278709411621094\n",
            "        - 0.05115509033203125\n",
            "        - -0.4965667724609375\n",
            "        - -1.2737960815429688\n",
            "        - 49.40595626831055\n",
            "        - 4.602012634277344\n",
            "        - 0.2405242919921875\n",
            "        - -0.09722900390625\n",
            "        - -0.17885589599609375\n",
            "        - -0.0781097412109375\n",
            "    num_agent_steps_sampled: 91000\n",
            "    num_agent_steps_trained: 720032\n",
            "    num_env_steps_sampled: 91000\n",
            "    num_env_steps_trained: 720032\n",
            "    num_target_updates: 181\n",
            "  iterations_since_restore: 91\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 91000\n",
            "  num_agent_steps_trained: 720032\n",
            "  num_env_steps_sampled: 91000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 720032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.47142857142858\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11290354316883462\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08685712340888296\n",
            "    mean_inference_ms: 1.3112703380040795\n",
            "    mean_raw_obs_processing_ms: 0.2046521883460621\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 192.21\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 192.21\n",
            "    episode_reward_min: 103.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 132\n",
            "      - 115\n",
            "      - 128\n",
            "      - 200\n",
            "      - 103\n",
            "      - 200\n",
            "      - 200\n",
            "      - 131\n",
            "      - 122\n",
            "      - 152\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 132.0\n",
            "      - 115.0\n",
            "      - 128.0\n",
            "      - 200.0\n",
            "      - 103.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 131.0\n",
            "      - 122.0\n",
            "      - 152.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11290354316883462\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08685712340888296\n",
            "      mean_inference_ms: 1.3112703380040795\n",
            "      mean_raw_obs_processing_ms: 0.2046521883460621\n",
            "  time_since_restore: 415.7029640674591\n",
            "  time_this_iter_s: 4.948760032653809\n",
            "  time_total_s: 415.7029640674591\n",
            "  timers:\n",
            "    learn_throughput: 5045.779\n",
            "    learn_time_ms: 6.342\n",
            "    load_throughput: 235263.327\n",
            "    load_time_ms: 0.136\n",
            "    synch_weights_time_ms: 0.057\n",
            "    training_iteration_time_ms: 18.361\n",
            "  timestamp: 1656961119\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 91000\n",
            "  training_iteration: 91\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:39 (running for 00:07:05.84)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         415.703</td><td style=\"text-align: right;\">91000</td><td style=\"text-align: right;\">  192.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            192.21</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 93000\n",
            "  counters:\n",
            "    last_target_update_ts: 93000\n",
            "    num_agent_steps_sampled: 93000\n",
            "    num_agent_steps_trained: 736032\n",
            "    num_env_steps_sampled: 93000\n",
            "    num_env_steps_trained: 736032\n",
            "    num_target_updates: 185\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-49\n",
            "  done: false\n",
            "  episode_len_mean: 197.38\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 197.38\n",
            "  episode_reward_min: 126.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 714\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 93000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 92.78752136230469\n",
            "          mean_q: 78.11799621582031\n",
            "          mean_td_error: 5.38942813873291\n",
            "          min_q: 1.4079179763793945\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 0.22613525390625\n",
            "        - -1.0039901733398438\n",
            "        - -0.1557769775390625\n",
            "        - 82.3526611328125\n",
            "        - 1.69415283203125\n",
            "        - 0.2619171142578125\n",
            "        - 0.283233642578125\n",
            "        - 0.46926116943359375\n",
            "        - 0.18051910400390625\n",
            "        - -0.9925460815429688\n",
            "        - -0.0705108642578125\n",
            "        - 5.974081993103027\n",
            "        - -0.7832107543945312\n",
            "        - -1.1466121673583984\n",
            "        - 0.4829254150390625\n",
            "        - 0.051849365234375\n",
            "        - -0.47057342529296875\n",
            "        - 83.30195617675781\n",
            "        - -0.34685516357421875\n",
            "        - 0.12896728515625\n",
            "        - 0.17078399658203125\n",
            "        - 0.64825439453125\n",
            "        - -0.7822341918945312\n",
            "        - 2.0080337524414062\n",
            "        - 0.01012420654296875\n",
            "        - -0.6675872802734375\n",
            "        - 0.129974365234375\n",
            "        - -0.1660308837890625\n",
            "        - -0.3021087646484375\n",
            "        - 0.44014739990234375\n",
            "        - 0.0966339111328125\n",
            "        - 0.4381103515625\n",
            "    num_agent_steps_sampled: 93000\n",
            "    num_agent_steps_trained: 736032\n",
            "    num_env_steps_sampled: 93000\n",
            "    num_env_steps_trained: 736032\n",
            "    num_target_updates: 185\n",
            "  iterations_since_restore: 93\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 93000\n",
            "  num_agent_steps_trained: 736032\n",
            "  num_env_steps_sampled: 93000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 736032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.3\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11289254938299104\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0868621770172214\n",
            "    mean_inference_ms: 1.311382012642878\n",
            "    mean_raw_obs_processing_ms: 0.2046042957855839\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 197.38\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 197.38\n",
            "    episode_reward_min: 126.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11289254938299104\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.0868621770172214\n",
            "      mean_inference_ms: 1.311382012642878\n",
            "      mean_raw_obs_processing_ms: 0.2046042957855839\n",
            "  time_since_restore: 424.95637011528015\n",
            "  time_this_iter_s: 4.659712076187134\n",
            "  time_total_s: 424.95637011528015\n",
            "  timers:\n",
            "    learn_throughput: 5542.843\n",
            "    learn_time_ms: 5.773\n",
            "    load_throughput: 209453.383\n",
            "    load_time_ms: 0.153\n",
            "    synch_weights_time_ms: 0.061\n",
            "    training_iteration_time_ms: 17.616\n",
            "  timestamp: 1656961129\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 93000\n",
            "  training_iteration: 93\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:49 (running for 00:07:15.06)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         424.956</td><td style=\"text-align: right;\">93000</td><td style=\"text-align: right;\">  197.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            197.38</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 95000\n",
            "  counters:\n",
            "    last_target_update_ts: 95000\n",
            "    num_agent_steps_sampled: 95000\n",
            "    num_agent_steps_trained: 752032\n",
            "    num_env_steps_sampled: 95000\n",
            "    num_env_steps_trained: 752032\n",
            "    num_target_updates: 189\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-58-58\n",
            "  done: false\n",
            "  episode_len_mean: 197.01\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 197.01\n",
            "  episode_reward_min: 126.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 724\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 95000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 92.77581024169922\n",
            "          mean_q: 78.14344024658203\n",
            "          mean_td_error: 17.945789337158203\n",
            "          min_q: 36.36147689819336\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -1.7143630981445312\n",
            "        - 0.3818359375\n",
            "        - 0.33573150634765625\n",
            "        - -0.25150299072265625\n",
            "        - 89.04138946533203\n",
            "        - -0.3680877685546875\n",
            "        - -2.256641387939453\n",
            "        - 85.33758544921875\n",
            "        - 84.99816131591797\n",
            "        - 83.9097671508789\n",
            "        - 83.5318374633789\n",
            "        - -0.2461700439453125\n",
            "        - 0.00931549072265625\n",
            "        - -0.41175079345703125\n",
            "        - 0.25272369384765625\n",
            "        - 0.27728271484375\n",
            "        - 81.18620300292969\n",
            "        - -0.25896453857421875\n",
            "        - 0.32718658447265625\n",
            "        - -2.9717788696289062\n",
            "        - -0.10567474365234375\n",
            "        - 84.6294174194336\n",
            "        - -0.201995849609375\n",
            "        - -1.3604240417480469\n",
            "        - -1.7201461791992188\n",
            "        - -3.4980545043945312\n",
            "        - -0.28391265869140625\n",
            "        - -0.13214874267578125\n",
            "        - -0.2166748046875\n",
            "        - -0.7900390625\n",
            "        - -0.27355194091796875\n",
            "        - -2.891326904296875\n",
            "    num_agent_steps_sampled: 95000\n",
            "    num_agent_steps_trained: 752032\n",
            "    num_env_steps_sampled: 95000\n",
            "    num_env_steps_trained: 752032\n",
            "    num_target_updates: 189\n",
            "  iterations_since_restore: 95\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 95000\n",
            "  num_agent_steps_trained: 752032\n",
            "  num_env_steps_sampled: 95000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 752032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.94285714285715\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11289243433781487\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08687579641139827\n",
            "    mean_inference_ms: 1.3115204280914625\n",
            "    mean_raw_obs_processing_ms: 0.2045663837042229\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 197.01\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 197.01\n",
            "    episode_reward_min: 126.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 186\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 163\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 163.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11289243433781487\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08687579641139827\n",
            "      mean_inference_ms: 1.3115204280914625\n",
            "      mean_raw_obs_processing_ms: 0.2045663837042229\n",
            "  time_since_restore: 434.2414755821228\n",
            "  time_this_iter_s: 4.651371240615845\n",
            "  time_total_s: 434.2414755821228\n",
            "  timers:\n",
            "    learn_throughput: 5083.138\n",
            "    learn_time_ms: 6.295\n",
            "    load_throughput: 214851.494\n",
            "    load_time_ms: 0.149\n",
            "    synch_weights_time_ms: 0.057\n",
            "    training_iteration_time_ms: 18.554\n",
            "  timestamp: 1656961138\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 95000\n",
            "  training_iteration: 95\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:58:58 (running for 00:07:24.40)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         434.241</td><td style=\"text-align: right;\">95000</td><td style=\"text-align: right;\">  197.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            197.01</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 97000\n",
            "  counters:\n",
            "    last_target_update_ts: 97000\n",
            "    num_agent_steps_sampled: 97000\n",
            "    num_agent_steps_trained: 768032\n",
            "    num_env_steps_sampled: 97000\n",
            "    num_env_steps_trained: 768032\n",
            "    num_target_updates: 193\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-59-07\n",
            "  done: false\n",
            "  episode_len_mean: 197.15\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 197.15\n",
            "  episode_reward_min: 126.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 734\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 97000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 93.28987121582031\n",
            "          mean_q: 75.13285827636719\n",
            "          mean_td_error: 8.113643646240234\n",
            "          min_q: 13.623038291931152\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.6698837280273438\n",
            "        - -0.09262847900390625\n",
            "        - 0.19399261474609375\n",
            "        - 0.00424957275390625\n",
            "        - -0.7344512939453125\n",
            "        - -3.209888458251953\n",
            "        - -0.37412261962890625\n",
            "        - 0.297576904296875\n",
            "        - -0.27101898193359375\n",
            "        - -0.44635009765625\n",
            "        - -0.4636688232421875\n",
            "        - -0.43549346923828125\n",
            "        - 0.5391006469726562\n",
            "        - 0.084442138671875\n",
            "        - -8.547574043273926\n",
            "        - -2.8178205490112305\n",
            "        - 84.94280242919922\n",
            "        - -0.21047210693359375\n",
            "        - -0.20432281494140625\n",
            "        - 81.97196960449219\n",
            "        - 0.0689544677734375\n",
            "        - 0.13824462890625\n",
            "        - 0.0721588134765625\n",
            "        - -0.22934722900390625\n",
            "        - 84.93323516845703\n",
            "        - 0.02752685546875\n",
            "        - -3.4264259338378906\n",
            "        - 0.47679901123046875\n",
            "        - 22.18146514892578\n",
            "        - 0.17498016357421875\n",
            "        - 5.806240081787109\n",
            "        - -0.1436767578125\n",
            "    num_agent_steps_sampled: 97000\n",
            "    num_agent_steps_trained: 768032\n",
            "    num_env_steps_sampled: 97000\n",
            "    num_env_steps_trained: 768032\n",
            "    num_target_updates: 193\n",
            "  iterations_since_restore: 97\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 97000\n",
            "  num_agent_steps_trained: 768032\n",
            "  num_env_steps_sampled: 97000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 768032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 65.48571428571428\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11288760967395\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08689115260210936\n",
            "    mean_inference_ms: 1.3116657490641785\n",
            "    mean_raw_obs_processing_ms: 0.20452710345045588\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 197.15\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 197.15\n",
            "    episode_reward_min: 126.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 133\n",
            "      - 186\n",
            "      - 200\n",
            "      - 126\n",
            "      - 132\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 163\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 133.0\n",
            "      - 186.0\n",
            "      - 200.0\n",
            "      - 126.0\n",
            "      - 132.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 163.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11288760967395\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08689115260210936\n",
            "      mean_inference_ms: 1.3116657490641785\n",
            "      mean_raw_obs_processing_ms: 0.20452710345045588\n",
            "  time_since_restore: 443.2210557460785\n",
            "  time_this_iter_s: 4.482591867446899\n",
            "  time_total_s: 443.2210557460785\n",
            "  timers:\n",
            "    learn_throughput: 5149.446\n",
            "    learn_time_ms: 6.214\n",
            "    load_throughput: 108144.169\n",
            "    load_time_ms: 0.296\n",
            "    synch_weights_time_ms: 0.06\n",
            "    training_iteration_time_ms: 19.087\n",
            "  timestamp: 1656961147\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 97000\n",
            "  training_iteration: 97\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:59:07 (running for 00:07:33.51)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         443.221</td><td style=\"text-align: right;\">97000</td><td style=\"text-align: right;\">  197.15</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            197.15</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 99000\n",
            "  counters:\n",
            "    last_target_update_ts: 99000\n",
            "    num_agent_steps_sampled: 99000\n",
            "    num_agent_steps_trained: 784032\n",
            "    num_env_steps_sampled: 99000\n",
            "    num_env_steps_trained: 784032\n",
            "    num_target_updates: 197\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-59-16\n",
            "  done: false\n",
            "  episode_len_mean: 197.4\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 197.4\n",
            "  episode_reward_min: 95.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 745\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 99000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 92.92155456542969\n",
            "          mean_q: 79.13558959960938\n",
            "          mean_td_error: 12.089059829711914\n",
            "          min_q: -0.45050370693206787\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - -0.0528106689453125\n",
            "        - 14.73452377319336\n",
            "        - -0.7651138305664062\n",
            "        - 0.00257110595703125\n",
            "        - 0.09283447265625\n",
            "        - 32.65944290161133\n",
            "        - 13.992837905883789\n",
            "        - 0.8615341186523438\n",
            "        - -0.055755615234375\n",
            "        - 91.92155456542969\n",
            "        - -0.12805938720703125\n",
            "        - 3.1985931396484375\n",
            "        - 0.473876953125\n",
            "        - 0.40822601318359375\n",
            "        - -0.04290008544921875\n",
            "        - 0.8619537353515625\n",
            "        - -0.02863311767578125\n",
            "        - 1.679351806640625\n",
            "        - 64.99723052978516\n",
            "        - 0.18932342529296875\n",
            "        - -0.18671417236328125\n",
            "        - 85.6733169555664\n",
            "        - 0.20989990234375\n",
            "        - 0.13407135009765625\n",
            "        - -0.3081207275390625\n",
            "        - 0.07571792602539062\n",
            "        - -0.26525115966796875\n",
            "        - 0.0887603759765625\n",
            "        - 77.9476089477539\n",
            "        - -0.1211090087890625\n",
            "        - 0.0516510009765625\n",
            "        - -1.4505037069320679\n",
            "    num_agent_steps_sampled: 99000\n",
            "    num_agent_steps_trained: 784032\n",
            "    num_env_steps_sampled: 99000\n",
            "    num_env_steps_trained: 784032\n",
            "    num_target_updates: 197\n",
            "  iterations_since_restore: 99\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 99000\n",
            "  num_agent_steps_trained: 784032\n",
            "  num_env_steps_sampled: 99000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 784032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.28571428571429\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11287820099627809\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08690478384694383\n",
            "    mean_inference_ms: 1.3118284609520758\n",
            "    mean_raw_obs_processing_ms: 0.20448792295346144\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 197.4\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 197.4\n",
            "    episode_reward_min: 95.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 163\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 95\n",
            "      - 107\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 163.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 95.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11287820099627809\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08690478384694383\n",
            "      mean_inference_ms: 1.3118284609520758\n",
            "      mean_raw_obs_processing_ms: 0.20448792295346144\n",
            "  time_since_restore: 452.1764965057373\n",
            "  time_this_iter_s: 4.445012331008911\n",
            "  time_total_s: 452.1764965057373\n",
            "  timers:\n",
            "    learn_throughput: 5123.088\n",
            "    learn_time_ms: 6.246\n",
            "    load_throughput: 219453.447\n",
            "    load_time_ms: 0.146\n",
            "    synch_weights_time_ms: 0.054\n",
            "    training_iteration_time_ms: 18.062\n",
            "  timestamp: 1656961156\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 99000\n",
            "  training_iteration: 99\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:59:16 (running for 00:07:42.45)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>RUNNING </td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         452.176</td><td style=\"text-align: right;\">99000</td><td style=\"text-align: right;\">   197.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">             197.4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for DQN_CartPole-v0_533fc_00000:\n",
            "  agent_timesteps_total: 100000\n",
            "  counters:\n",
            "    last_target_update_ts: 100000\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 792032\n",
            "    num_env_steps_sampled: 100000\n",
            "    num_env_steps_trained: 792032\n",
            "    num_target_updates: 199\n",
            "  custom_metrics: {}\n",
            "  date: 2022-07-04_18-59-20\n",
            "  done: true\n",
            "  episode_len_mean: 197.4\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 200.0\n",
            "  episode_reward_mean: 197.4\n",
            "  episode_reward_min: 95.0\n",
            "  episodes_this_iter: 5\n",
            "  episodes_total: 750\n",
            "  experiment_id: eb08c85f58f746b3a6a595e2b8cb0063\n",
            "  hostname: a0e5015b1b0d\n",
            "  info:\n",
            "    last_target_update_ts: 100000\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          cur_lr: 0.0005000000237487257\n",
            "          max_q: 93.25099182128906\n",
            "          mean_q: 79.8328857421875\n",
            "          mean_td_error: 7.2804718017578125\n",
            "          min_q: 1.804019808769226\n",
            "          model: {}\n",
            "        num_agent_steps_trained: 32.0\n",
            "        td_error:\n",
            "        - 79.65446472167969\n",
            "        - 0.1602935791015625\n",
            "        - 0.19158172607421875\n",
            "        - 0.23529052734375\n",
            "        - -0.30680084228515625\n",
            "        - 0.15004730224609375\n",
            "        - 0.19400787353515625\n",
            "        - 0.397369384765625\n",
            "        - 0.094696044921875\n",
            "        - 0.8040198087692261\n",
            "        - 0.36629486083984375\n",
            "        - -0.03998565673828125\n",
            "        - 0.22797393798828125\n",
            "        - -0.07341766357421875\n",
            "        - -0.5240936279296875\n",
            "        - 0.9499092102050781\n",
            "        - -0.307586669921875\n",
            "        - 84.7948226928711\n",
            "        - 0.317901611328125\n",
            "        - 0.01308441162109375\n",
            "        - 0.38475799560546875\n",
            "        - 0.6242141723632812\n",
            "        - 2.623046875\n",
            "        - -0.210113525390625\n",
            "        - 0.13611602783203125\n",
            "        - 61.03431701660156\n",
            "        - 0.224029541015625\n",
            "        - 0.3183135986328125\n",
            "        - 0.035137176513671875\n",
            "        - 0.06459808349609375\n",
            "        - 0.0029449462890625\n",
            "        - 0.4378471374511719\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 792032\n",
            "    num_env_steps_sampled: 100000\n",
            "    num_env_steps_trained: 792032\n",
            "    num_target_updates: 199\n",
            "  iterations_since_restore: 100\n",
            "  node_ip: 172.28.0.2\n",
            "  num_agent_steps_sampled: 100000\n",
            "  num_agent_steps_trained: 792032\n",
            "  num_env_steps_sampled: 100000\n",
            "  num_env_steps_sampled_this_iter: 1000\n",
            "  num_env_steps_trained: 792032\n",
            "  num_env_steps_trained_this_iter: 8000\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 66.21666666666665\n",
            "    ram_util_percent: 17.099999999999998\n",
            "  pid: 1867\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.11287113665701398\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.08690909132934958\n",
            "    mean_inference_ms: 1.3118621126267755\n",
            "    mean_raw_obs_processing_ms: 0.20446526504950824\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 197.4\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 200.0\n",
            "    episode_reward_mean: 197.4\n",
            "    episode_reward_min: 95.0\n",
            "    episodes_this_iter: 5\n",
            "    hist_stats:\n",
            "      episode_lengths:\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 175\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 163\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 95\n",
            "      - 107\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      - 200\n",
            "      episode_reward:\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 175.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 163.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 95.0\n",
            "      - 107.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "      - 200.0\n",
            "    off_policy_estimator: {}\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.11287113665701398\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.08690909132934958\n",
            "      mean_inference_ms: 1.3118621126267755\n",
            "      mean_raw_obs_processing_ms: 0.20446526504950824\n",
            "  time_since_restore: 456.6778347492218\n",
            "  time_this_iter_s: 4.501338243484497\n",
            "  time_total_s: 456.6778347492218\n",
            "  timers:\n",
            "    learn_throughput: 5239.667\n",
            "    learn_time_ms: 6.107\n",
            "    load_throughput: 226987.533\n",
            "    load_time_ms: 0.141\n",
            "    synch_weights_time_ms: 0.051\n",
            "    training_iteration_time_ms: 18.615\n",
            "  timestamp: 1656961160\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 100\n",
            "  trial_id: 533fc_00000\n",
            "  warmup_time: 1.692857027053833\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-04 18:59:21 (running for 00:07:47.16)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/80 CPUs, 0/2 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/DQN<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_CartPole-v0_533fc_00000</td><td>TERMINATED</td><td>172.28.0.2:1867</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         456.678</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">   197.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">             197.4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-04 18:59:21,463\tINFO tune.py:748 -- Total run time: 467.57 seconds (467.13 seconds for the tuning loop).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OYalgm35mII4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(dfs.values())[0])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "a0VTtEx6mJQs",
        "outputId": "ea231cf9-6ee2-4deb-8f84-1c77c49c99af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
              "0                 51.0                 9.0            20.479167   \n",
              "1                 51.0                 9.0            19.550000   \n",
              "2                 64.0                 9.0            19.730000   \n",
              "3                121.0                 9.0            24.630000   \n",
              "4                200.0                 9.0            33.110000   \n",
              "..                 ...                 ...                  ...   \n",
              "95               200.0               126.0           197.010000   \n",
              "96               200.0               126.0           197.150000   \n",
              "97               200.0                95.0           196.720000   \n",
              "98               200.0                95.0           197.400000   \n",
              "99               200.0                95.0           197.400000   \n",
              "\n",
              "    episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
              "0          20.479167                  48                    0   \n",
              "1          19.550000                  55                    0   \n",
              "2          19.730000                  45                    0   \n",
              "3          24.630000                  23                    0   \n",
              "4          33.110000                  14                    0   \n",
              "..               ...                 ...                  ...   \n",
              "95        197.010000                   5                    0   \n",
              "96        197.150000                   5                    0   \n",
              "97        196.720000                   6                    0   \n",
              "98        197.400000                   5                    0   \n",
              "99        197.400000                   5                    0   \n",
              "\n",
              "    num_agent_steps_sampled  num_agent_steps_trained  num_env_steps_sampled  \\\n",
              "0                      1000                       32                   1000   \n",
              "1                      2000                     8032                   2000   \n",
              "2                      3000                    16032                   3000   \n",
              "3                      4000                    24032                   4000   \n",
              "4                      5000                    32032                   5000   \n",
              "..                      ...                      ...                    ...   \n",
              "95                    96000                   760032                  96000   \n",
              "96                    97000                   768032                  97000   \n",
              "97                    98000                   776032                  98000   \n",
              "98                    99000                   784032                  99000   \n",
              "99                   100000                   792032                 100000   \n",
              "\n",
              "    num_env_steps_trained  ...  \\\n",
              "0                      32  ...   \n",
              "1                    8032  ...   \n",
              "2                   16032  ...   \n",
              "3                   24032  ...   \n",
              "4                   32032  ...   \n",
              "..                    ...  ...   \n",
              "95                 760032  ...   \n",
              "96                 768032  ...   \n",
              "97                 776032  ...   \n",
              "98                 784032  ...   \n",
              "99                 792032  ...   \n",
              "\n",
              "    sampler_results/sampler_perf/mean_action_processing_ms  \\\n",
              "0                                            0.100385        \n",
              "1                                            0.108699        \n",
              "2                                            0.118206        \n",
              "3                                            0.119462        \n",
              "4                                            0.119809        \n",
              "..                                                ...        \n",
              "95                                           0.112891        \n",
              "96                                           0.112888        \n",
              "97                                           0.112883        \n",
              "98                                           0.112878        \n",
              "99                                           0.112871        \n",
              "\n",
              "    sampler_results/sampler_perf/mean_env_wait_ms  \\\n",
              "0                                        0.074802   \n",
              "1                                        0.080779   \n",
              "2                                        0.088701   \n",
              "3                                        0.090144   \n",
              "4                                        0.090668   \n",
              "..                                            ...   \n",
              "95                                       0.086883   \n",
              "96                                       0.086891   \n",
              "97                                       0.086900   \n",
              "98                                       0.086905   \n",
              "99                                       0.086909   \n",
              "\n",
              "    sampler_results/sampler_perf/mean_env_render_ms  \\\n",
              "0                                               0.0   \n",
              "1                                               0.0   \n",
              "2                                               0.0   \n",
              "3                                               0.0   \n",
              "4                                               0.0   \n",
              "..                                              ...   \n",
              "95                                              0.0   \n",
              "96                                              0.0   \n",
              "97                                              0.0   \n",
              "98                                              0.0   \n",
              "99                                              0.0   \n",
              "\n",
              "                 info/learner/default_policy/td_error  \\\n",
              "0   [-0.43530735  0.12601888 -0.98192716 -0.750787...   \n",
              "1   [-0.5219774   0.10700607 -0.04102826 -0.069259...   \n",
              "2   [ 1.6525812   1.7657387  -0.23691511 -0.282293...   \n",
              "3   [-2.7474403e-02 -4.9130917e-02  7.0571899e-04 ...   \n",
              "4   [-0.15053749 -0.23163795  0.25291824  4.702332...   \n",
              "..                                                ...   \n",
              "95  [ 1.2714386e-01  1.5078735e-01  1.4138794e-01 ...   \n",
              "96  [-6.6988373e-01 -9.2628479e-02  1.9399261e-01 ...   \n",
              "97  [-5.2116394e-02  8.5784767e+01 -4.6514130e-01 ...   \n",
              "98  [-5.2810669e-02  1.4734524e+01 -7.6511383e-01 ...   \n",
              "99  [ 7.9654465e+01  1.6029358e-01  1.9158173e-01 ...   \n",
              "\n",
              "    info/learner/default_policy/num_agent_steps_trained  \\\n",
              "0                                                32.0     \n",
              "1                                                32.0     \n",
              "2                                                32.0     \n",
              "3                                                32.0     \n",
              "4                                                32.0     \n",
              "..                                                ...     \n",
              "95                                               32.0     \n",
              "96                                               32.0     \n",
              "97                                               32.0     \n",
              "98                                               32.0     \n",
              "99                                               32.0     \n",
              "\n",
              "    info/learner/default_policy/learner_stats/cur_lr  \\\n",
              "0                                             0.0005   \n",
              "1                                             0.0005   \n",
              "2                                             0.0005   \n",
              "3                                             0.0005   \n",
              "4                                             0.0005   \n",
              "..                                               ...   \n",
              "95                                            0.0005   \n",
              "96                                            0.0005   \n",
              "97                                            0.0005   \n",
              "98                                            0.0005   \n",
              "99                                            0.0005   \n",
              "\n",
              "    info/learner/default_policy/learner_stats/mean_q  \\\n",
              "0                                           0.357841   \n",
              "1                                           3.050566   \n",
              "2                                           4.126381   \n",
              "3                                           6.141634   \n",
              "4                                           8.075910   \n",
              "..                                               ...   \n",
              "95                                         82.240100   \n",
              "96                                         75.132860   \n",
              "97                                         86.257645   \n",
              "98                                         79.135590   \n",
              "99                                         79.832886   \n",
              "\n",
              "   info/learner/default_policy/learner_stats/min_q  \\\n",
              "0                                        -0.079650   \n",
              "1                                         1.902294   \n",
              "2                                         2.318976   \n",
              "3                                         0.444409   \n",
              "4                                         3.534071   \n",
              "..                                             ...   \n",
              "95                                       19.792244   \n",
              "96                                       13.623038   \n",
              "97                                       29.451403   \n",
              "98                                       -0.450504   \n",
              "99                                        1.804020   \n",
              "\n",
              "   info/learner/default_policy/learner_stats/max_q  \\\n",
              "0                                         1.215289   \n",
              "1                                         4.588746   \n",
              "2                                         7.650724   \n",
              "3                                         8.366299   \n",
              "4                                         9.969917   \n",
              "..                                             ...   \n",
              "95                                       93.298410   \n",
              "96                                       93.289870   \n",
              "97                                       93.821396   \n",
              "98                                       92.921555   \n",
              "99                                       93.250990   \n",
              "\n",
              "   info/learner/default_policy/learner_stats/mean_td_error  \n",
              "0                                           -0.556405       \n",
              "1                                           -0.039685       \n",
              "2                                            0.185382       \n",
              "3                                            0.149313       \n",
              "4                                            0.487113       \n",
              "..                                                ...       \n",
              "95                                          14.494576       \n",
              "96                                           8.113644       \n",
              "97                                           8.721436       \n",
              "98                                          12.089060       \n",
              "99                                           7.280472       \n",
              "\n",
              "[100 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d6e90bc-df18-4a31-8ca5-3765bb3ce2b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_reward_max</th>\n",
              "      <th>episode_reward_min</th>\n",
              "      <th>episode_reward_mean</th>\n",
              "      <th>episode_len_mean</th>\n",
              "      <th>episodes_this_iter</th>\n",
              "      <th>num_healthy_workers</th>\n",
              "      <th>num_agent_steps_sampled</th>\n",
              "      <th>num_agent_steps_trained</th>\n",
              "      <th>num_env_steps_sampled</th>\n",
              "      <th>num_env_steps_trained</th>\n",
              "      <th>...</th>\n",
              "      <th>sampler_results/sampler_perf/mean_action_processing_ms</th>\n",
              "      <th>sampler_results/sampler_perf/mean_env_wait_ms</th>\n",
              "      <th>sampler_results/sampler_perf/mean_env_render_ms</th>\n",
              "      <th>info/learner/default_policy/td_error</th>\n",
              "      <th>info/learner/default_policy/num_agent_steps_trained</th>\n",
              "      <th>info/learner/default_policy/learner_stats/cur_lr</th>\n",
              "      <th>info/learner/default_policy/learner_stats/mean_q</th>\n",
              "      <th>info/learner/default_policy/learner_stats/min_q</th>\n",
              "      <th>info/learner/default_policy/learner_stats/max_q</th>\n",
              "      <th>info/learner/default_policy/learner_stats/mean_td_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.479167</td>\n",
              "      <td>20.479167</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>32</td>\n",
              "      <td>1000</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100385</td>\n",
              "      <td>0.074802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-0.43530735  0.12601888 -0.98192716 -0.750787...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.357841</td>\n",
              "      <td>-0.079650</td>\n",
              "      <td>1.215289</td>\n",
              "      <td>-0.556405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.550000</td>\n",
              "      <td>19.550000</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>8032</td>\n",
              "      <td>2000</td>\n",
              "      <td>8032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.108699</td>\n",
              "      <td>0.080779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-0.5219774   0.10700607 -0.04102826 -0.069259...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>3.050566</td>\n",
              "      <td>1.902294</td>\n",
              "      <td>4.588746</td>\n",
              "      <td>-0.039685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.730000</td>\n",
              "      <td>19.730000</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3000</td>\n",
              "      <td>16032</td>\n",
              "      <td>3000</td>\n",
              "      <td>16032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.118206</td>\n",
              "      <td>0.088701</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[ 1.6525812   1.7657387  -0.23691511 -0.282293...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>4.126381</td>\n",
              "      <td>2.318976</td>\n",
              "      <td>7.650724</td>\n",
              "      <td>0.185382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>121.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>24.630000</td>\n",
              "      <td>24.630000</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>4000</td>\n",
              "      <td>24032</td>\n",
              "      <td>4000</td>\n",
              "      <td>24032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.119462</td>\n",
              "      <td>0.090144</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-2.7474403e-02 -4.9130917e-02  7.0571899e-04 ...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6.141634</td>\n",
              "      <td>0.444409</td>\n",
              "      <td>8.366299</td>\n",
              "      <td>0.149313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>33.110000</td>\n",
              "      <td>33.110000</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>5000</td>\n",
              "      <td>32032</td>\n",
              "      <td>5000</td>\n",
              "      <td>32032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.119809</td>\n",
              "      <td>0.090668</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-0.15053749 -0.23163795  0.25291824  4.702332...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>8.075910</td>\n",
              "      <td>3.534071</td>\n",
              "      <td>9.969917</td>\n",
              "      <td>0.487113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>200.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>197.010000</td>\n",
              "      <td>197.010000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>96000</td>\n",
              "      <td>760032</td>\n",
              "      <td>96000</td>\n",
              "      <td>760032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112891</td>\n",
              "      <td>0.086883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[ 1.2714386e-01  1.5078735e-01  1.4138794e-01 ...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>82.240100</td>\n",
              "      <td>19.792244</td>\n",
              "      <td>93.298410</td>\n",
              "      <td>14.494576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>200.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>197.150000</td>\n",
              "      <td>197.150000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>97000</td>\n",
              "      <td>768032</td>\n",
              "      <td>97000</td>\n",
              "      <td>768032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112888</td>\n",
              "      <td>0.086891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-6.6988373e-01 -9.2628479e-02  1.9399261e-01 ...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>75.132860</td>\n",
              "      <td>13.623038</td>\n",
              "      <td>93.289870</td>\n",
              "      <td>8.113644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>200.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>196.720000</td>\n",
              "      <td>196.720000</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>98000</td>\n",
              "      <td>776032</td>\n",
              "      <td>98000</td>\n",
              "      <td>776032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112883</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-5.2116394e-02  8.5784767e+01 -4.6514130e-01 ...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>86.257645</td>\n",
              "      <td>29.451403</td>\n",
              "      <td>93.821396</td>\n",
              "      <td>8.721436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>200.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>197.400000</td>\n",
              "      <td>197.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>99000</td>\n",
              "      <td>784032</td>\n",
              "      <td>99000</td>\n",
              "      <td>784032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112878</td>\n",
              "      <td>0.086905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[-5.2810669e-02  1.4734524e+01 -7.6511383e-01 ...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>79.135590</td>\n",
              "      <td>-0.450504</td>\n",
              "      <td>92.921555</td>\n",
              "      <td>12.089060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>200.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>197.400000</td>\n",
              "      <td>197.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>100000</td>\n",
              "      <td>792032</td>\n",
              "      <td>100000</td>\n",
              "      <td>792032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112871</td>\n",
              "      <td>0.086909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[ 7.9654465e+01  1.6029358e-01  1.9158173e-01 ...</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>79.832886</td>\n",
              "      <td>1.804020</td>\n",
              "      <td>93.250990</td>\n",
              "      <td>7.280472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  76 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d6e90bc-df18-4a31-8ca5-3765bb3ce2b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d6e90bc-df18-4a31-8ca5-3765bb3ce2b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d6e90bc-df18-4a31-8ca5-3765bb3ce2b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('dqn2.csv')"
      ],
      "metadata": {
        "id": "si6K4m0NmSfL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = analysis.get_best_checkpoint(\n",
        "    metric=\"episode_reward_mean\", \n",
        "    mode=\"max\", \n",
        "    trial=analysis.trials[0]\n",
        ")"
      ],
      "metadata": {
        "id": "sDAAAXzqmfRo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ray.rllib.agents.dqn as dqn"
      ],
      "metadata": {
        "id": "WcYjsEoy4lYF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = dqn.DQNTrainer(config={\"env\":\"CartPole-v0\"})\n",
        "agent.restore(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDJRCOak4u8z",
        "outputId": "b7abc9cd-ff7c-433c-a26b-963dee51aa1d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-04 19:04:45,669\tWARNING logger.py:337 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.\n",
            "2022-07-04 19:04:45,675\tINFO trainer.py:2333 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
            "2022-07-04 19:04:45,683\tINFO simple_q.py:188 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
            "2022-07-04 19:04:45,686\tINFO trainer.py:906 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "2022-07-04 19:04:47,332\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/ray/rllib/utils/exploration/epsilon_greedy.py:241: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-04 19:04:47,440\tINFO trainable.py:589 -- Restored on 172.28.0.2 from checkpoint: /root/ray_results/DQN/DQN_CartPole-v0_533fc_00000_0_2022-07-04_18-51-34/checkpoint_000100/checkpoint-100\n",
            "2022-07-04 19:04:47,443\tINFO trainable.py:597 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 456.6778347492218, '_episodes_total': 750}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "metadata": {
        "id": "1yh2PoDQFJZ_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "FCeEKsp28XZv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rendering Dependencies\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "# Gym Dependencies\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!pip install gym[box2d] > /dev/null 2>&1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "U8F1uySVNwyx",
        "outputId": "c5c1aa36-182f-4419-fed3-c470ec8e412a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-63.1.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     || 1.2 MB 4.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed setuptools-63.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "# Google Colab needs to render the environment to a virtual display\n",
        "# we will record this as a video and play it after the training has finished\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[-1]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "metadata": {
        "id": "WFZsZXtDN8HO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game = \"CartPole-v0\"\n",
        "\n",
        "nr_of_runs = 10\n",
        "current_run = 1\n",
        "\n",
        "if current_run == nr_of_runs:\n",
        "  env = wrap_env(gym.make(game))\n",
        "else:\n",
        "  env = gym.make(game)\n",
        "observation = env.reset()\n",
        "timestep = 0\n",
        "\n",
        "while current_run < nr_of_runs+1:\n",
        "    # render the current frame to the video recorder of Google Colab\n",
        "    if current_run == nr_of_runs:\n",
        "      env.render()\n",
        "    \n",
        "    # your agent goes here \n",
        "    # action_space.sample() results in a random action being picked\n",
        "    action = agent.compute_action(observation)\n",
        "    \n",
        "    # apply the action to the real environment and forward the game\n",
        "    observation, reward, done, info = env.step(action) \n",
        "    timestep += 1\n",
        "    \n",
        "    if done:\n",
        "      # for Monte Carlo Method you will need to update your value matrix here\n",
        "      # Temporal Difference Learning updates the value matrix in every step\n",
        "      \n",
        "      # this test ends after 'nr_of_runs' (default = 10)\n",
        "      # change the variable at the top if you want to train longer (recommended) \n",
        "      print(\"run: \"+ str(current_run) + \" took \" + str(timestep) + \" timesteps\")\n",
        "      current_run += 1\n",
        "      timestep = 0\n",
        "      if current_run == nr_of_runs:\n",
        "        # record the last run\n",
        "        env.close()\n",
        "        env = wrap_env(gym.make(game))\n",
        "      else:\n",
        "        env.close()\n",
        "        env = gym.make(game)\n",
        "      \n",
        "      observation = env.reset()\n",
        "show_video()  #only shows the last run\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "oA0Ffb4CPEME",
        "outputId": "15dc2861-92d7-4c39-8b86-a92c0428231c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-04 19:06:12,209\tWARNING deprecation.py:47 -- DeprecationWarning: `compute_action` has been deprecated. Use `Trainer.compute_single_action()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run: 1 took 200 timesteps\n",
            "run: 2 took 200 timesteps\n",
            "run: 3 took 200 timesteps\n",
            "run: 4 took 200 timesteps\n",
            "run: 5 took 200 timesteps\n",
            "run: 6 took 200 timesteps\n",
            "run: 7 took 200 timesteps\n",
            "run: 8 took 200 timesteps\n",
            "run: 9 took 200 timesteps\n",
            "run: 10 took 200 timesteps\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAK7dtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAABfWWIhAAz//727L4FNf2f0JcRLMXaSnA+KqSAgHc0wAAAAwAAAwAAFgn0I7DkqgN3QAAAHGAFBCwCPCVC2EhH2OkN/wYuFAAV8CVxMpfCj66ivCHKzKS6x12qJE3IJQs05DBjAJTekQ7gsIFlRIhzLeDD5XJmppWat9yZZmAa+WFe7swpfeYQ+bQxLSRaRR3KO75q8iQD+gItJm2IPA9t4HhLjBXcK3daTdbZaLavJLzjMsa3nJ/y0hZF/rHCageirQCKLmkqx6W3UVVASFlly2+2uZ+98Bt2TmSTIe4VTHI0ENfd0QKOPTal8uhpPom//f43ebGfaXRrXGUc2Grfudcov0s8iu3jGpwz03vt9SMzZleu+EEVz4m2o3YLXwpUkycKYuOJdSDV4VwRkfsSKgM7PrCQAOgg5aa1YCSCOD/cswMJCrkFeQGYr4ZCQI+3VWvzcnrgiBcc7rC9CGAx6liCv/JI+1hqOYZw386WGfAFhyE7AAADAAADAAAW8QAAAI1BmiRsQz/+nhAAAEWNOnlUgByij6XxrxlKxj7SRQM2eFRzSEIIGEUgW/uISGAtbmMpVXjRjMKx80Pd7M/UOdYwSCnlk/4zEQ8UlLmubnFMHUhQYChSz/k3v9FTrxlL/Fwv+fXPvpWjmis8FadcgWLDjAfqBmPdnIIQAAAQSCA9cNDyB1TRv8zOUShJOr4AAAAnQZ5CeIR/AAAWvl3Cu83b3ufB4q9Quq4Y9MJgAAADAEp38HAjLAfNAAAAJgGeYXRH/wAAAwAKP404/BKkaiZqhCNQqWAAAAMAAFvu/NQywLiAAAAAFwGeY2pH/wAAI78b2ruEiziFSFkc6hcRAAAAYEGaaEmoQWiZTAhn//6eEAAAAwAT2zayWc4AaqINZ69KtR/p1F5+sDnwriPy+x36/PJsXxSiexhShTICJxoSHAlhmWnBZK/K/99ykLPqd5S+siQHP3t1TearsPXC2KPZ1wAAACBBnoZFESwj/wAAAwAGm3cGlnDRr+vEnOktJE94TpgJUQAAACoBnqV0R/8AACOf+t8mAG5mBWRUJUVcJQnVHq2+oCBgRnFuhMS32bOmUPEAAAAYAZ6nakf/AAADAAqGYSDPpH3/1ZQfD+XAAAAAdkGarEmoQWyZTAhn//6eEAAARW1nfCSgD5yntKbd85QMQQF7zYk2RFRL14LjNjoPINkhaLAwOIGhvVrZv5JTcxYoFlcuhIlFeRGld7cf8stwNcEtUpiBdy8v8MrB2QwRuKuZF8nhw0Vx0ZikLgkyY92HpignuXoAAAAgQZ7KRRUsI/8AABa8TvgpOzSp+RIYkgMMM5SprfF3kmEAAAAZAZ7pdEf/AAADAAqArg05Olo1bI8HpHZVigAAAB4BnutqR/8AACOyMTr9stRztr1y4BACa283fV1WkQEAAAB3QZrwSahBbJlMCGf//p4QAABFRQqDgBz7VdGpe7wID0EGLiTRj4HBc2z5Cb+ky0uApuP2aTxfDr36c42g9qCGBbueQDwqzh4lRCy1TiZc2hAUhI5hGLWixlL2vmJYu5fwQtMG1m9Zo1sTRp4gGChuZ4rvISmGnsEAAAArQZ8ORRUsI/8AABa1UR8zWZACu1gYbZu0ZjLsNHWC7bXTJoxBJHmR2pGtmQAAACUBny10R/8AACOsOlFyOsda1SaURMyrodIKxPORcoDLPFF/LOWzAAAAHgGfL2pH/wAADXlLBVcWt3mXg1rYAWsnNl8S93ChgAAAAFxBmzRJqEFsmUwIZ//+nhAAAEVVMOQCaUuFo/+NM0GwPfWL+7yfS3E2m2geABasgPxMBv1ncsVEnKj04rOGTRgu+yeacMbW7jaT701E4PnlSIRWXtjTMmpa9McngAAAADRBn1JFFSwj/wAAFr6mhteu47uldu2RfCYHxJIALqNmaxfeKdObQ54/DL/xRcDmH2n7NMgJAAAAMAGfcXRH/wAAI6w5BrXA1NAkL90nXvEAF1AIXCSvarUHoVvmD9joEa2ycVkCxf97MAAAABwBn3NqR/8AACO/HAhWh2kQ4M4de1sM9gNWL5W3AAAAO0GbeEmoQWyZTAhn//6eEAAARYFH/dwCKjtsk6BzDchyE8Vj1ZV9DUg7/v7Bl9bF2qJziSLLCBoBm4uJAAAAJUGflkUVLCP/AAAWvE74IEyLgzBOotABbNNfUCahWFao2bINJWAAAAAUAZ+1dEf/AAADALqTOeYUSR2rIj8AAAAXAZ+3akf/AAAjsixgXOl4VTzrEt6uZ8EAAABeQZu8SahBbJlMCGf//p4QAAAaVjergBJy6Z8Rqfy4fGUu+Hrk7ScCMK6OEBhKAp20a2V3+ZyBoI1GQcotfzQ2/8VVF98mzcWu5fY5aI19tbtTvnPtmU8gA/HcI6wwIAAAACdBn9pFFSwj/wAACGw94NRSvWg8wqICe560hevMyk+tA1kRrSTWSYEAAAAbAZ/5dEf/AAANf09/nEECwxj5Yo0Os2/v2duAAAAAKgGf+2pH/wAABR2QAAEtU6q9Wq8M4GcZsGzaNzPu6rVqcFFW37EXX1+fTQAAAGRBm+BJqEFsmUwIZ//+nhAAAEVIlyAOTarozp+ASP/SnQCXds9Q2B5z+6q2SbBfupzCXCle6zbsASyxX7u/dw2IlAbbVSp6vtx5dkx289AfeirBxQRKXmUjn46EVJSzkO2VhfzhAAAAMEGeHkUVLCP/AAAWtVr+FklgumVgA/nUVhCdocsIG2xEHh0ilDYt46/YwNBuyYjZgAAAACEBnj10R/8AACPDQKqX4XFBUAFwwhMd90Pa7wRUwo+Tl5AAAAAcAZ4/akf/AAADAEWEfn8mAlNH+D3fU+RQ8oNtwQAAADFBmiRJqEFsmUwIZ//+nhAAAEVUvr3rCT4U8bfINgSvLokIGLbed9q4AQf8oSNkasrYAAAAE0GeQkUVLCP/AAAIbyc2YW5ADmkAAAArAZ5hdEf/AAAjwz+1UzrfYQAP52kPBwZCrTC0zhnFOMB03Z1mvrXB4dl9mAAAAB0BnmNqR/8AACOyKwUnQqAFkI2etm+xTDMu+sAZUQAAADdBmmhJqEFsmUwIZ//+nhAAAEVUvr4+fTdzb1sn/EPC1sToYApjeddMZSV1S1hu7jhGnHL9O1xxAAAALEGehkUVLCP/AAAWtVqQGwg3VV48a/+sAGqQrpMnVOxh5/A4jUTNZRujmf6RAAAAIQGepXRH/wAAI6w8nKXHyRqJhgBbwPbx4m88dDthpVUQ8QAAACMBnqdqR/8AAAMACoZ6s4XYAHvWm5aZTxTD1kdYGcvuRvukJgAAAD5BmqxJqEFsmUwIZ//+nhAAAEVFCDQAuKtnAWyZzX1RNqyNCWyySbchsYrPK4BbE5BkEbd2e9buVG4irYOScAAAABpBnspFFSwj/wAAFr51tCEuZlFhf4hmGDD7oQAAABwBnul0R/8AACOsOSHgAEsU/Nu84lj/LAtPoA2YAAAAIAGe62pH/wAAI7IyO+rFgOABaMt/WsH3/+fzw9C2nxxwAAAAU0Ga8EmoQWyZTAhn//6eEAAARVE//UAXKnFpK5tx5Aa608UL38N9WzdLX/WEeHSlqH0IB/lWW0Swrxreq7s0ICzuv31C+B0+4afGbMKqIrfTEJOhAAAAPUGfDkUVLCP/AAAWvE5ssysyUX1vzmS1qpQqtCtzihuv3VZ0ccqCPkTJJn4tenpuZ1cOMYmmJ9GNTyLwVYsAAAAaAZ8tdEf/AAADABpvoQwDkM83ny9FAAilwIEAAAAWAZ8vakf/AAAjsisICZ65bF6nYPkCPgAAAGVBmzRJqEFsmUwIX//+jLAAAEh6b0Lw4j4p8pQv07e5sVGsqo01YrvR1QvHEwOflquLltO5ntkGXEiZmC3Bfc0DzzBpEhwn+yZSuGvlokGFufo+UF0mfD1EvjiPBudyyXl8R6TsogAAACxBn1JFFSwj/wAAFsBWklAervde4QlF4AaoirLlCQEGbXoigVLXaxBn1y8e4QAAACIBn3F0R/8AACOsPR3Oc5HwALRnzZneQufPBBrPahl7eupoAAAAGwGfc2pH/wAAI78azqjXqHxHneYoU89CjvlQ9wAAAD9Bm3dJqEFsmUwIZ//+nhAAAEVlQVHla1QAX18axJobdSAPORMXTVDb2hzMwv9a9BDWQOPW88BTGbFxaN/mAJMAAAAgQZ+VRRUsI/8AABa1WQxhENzDrnoJz/TUigDaOYzm5yoAAAA9AZ+2akf/AAAjlKJXcQIAODNToOjkgmYm/Ljdg5oYLlfW+N25a2n+sPcDKB7Ystwoy6u8vMnPGxl/cpy3uQAAAEBBm7tJqEFsmUwIZ//+nhAAAEdFBPccYb/aC5P1B3lgAQ3y/jPB78QL4lnfx6J7iCtQooARhnX55K/tGdvA5JOBAAAAI0Gf2UUVLCP/AAAXTEPNtxXS9vC3hGW7cUal8yeWFYgV4mhAAAAALAGf+HRH/wAAI54GLbigA43YSsjk2feNnMfw4DpaySsXHr9Dhbl1xADZ8bf/AAAAJgGf+mpH/wAAJLHMCW+pbi1aYAVvoU/YUPMYruTmGwUyNxjxJhgQAAAAVkGb/0moQWyZTAhn//6eEAAAR1EJaKR/mgCPUqVkSwwHSemtajKVjXqeB8gSz1GET/WWMJzD8X09H8jRtVNVyruekumkuY0w3SkTCkbaJLdIXhs91MR5AAAAJkGeHUUVLCP/AAAXTEPNtyaAAblVXv+IxaJLKrEsIlkRJlY+Y/uBAAAAGQGePHRH/wAAAwBHV/C28E8ktrn2fLs8teAAAAAmAZ4+akf/AAAkscv8juUAEZEtP6NBFzPDlTTsg8mc2lEsZ1G+TuAAAABUQZojSahBbJlMCGf//p4QAABHRQUU3owtdGmWAANG8CTD2RvEUOHotumITOeMuucUVJYaEKRAUFyvAFBYqxEdJBvxbwYDt+Mg1W0y80jcotRSmtmBAAAAO0GeQUUVLCP/AAAXTd3GwNmwwAcYFNZC5vJtqoDV/k+l1oj26JItrWiH5QXaW4ZXJ/LeegXMlwNDS7iwAAAALAGeYHRH/wAAJMMCMU/qAOjEX6HcAFs0vm3bJojVonCa36SFdX6OJILsNrXhAAAAHQGeYmpH/wAAJL8EJxXCetqF4UawwATUgNcRwLyAAAAASEGaZ0moQWyZTAhn//6eEAAAR1SpbcAMJqVGd7pA9NR0sk+N6SWCd+1/ezOylYPTiAzFX7kMdvsB29K9B1z/pjka77JStZ9IWQAAACdBnoVFFSwj/wAAF0xDzbcVdD5IcN0e4XxdqrcjNG2IHfzZ+uej2pEAAAAyAZ6kdEf/AAAkyGGmOfQAOK30yaHtYn61SfEl6oRsfMwI6iL0YUi81Zlx+bWjB+7ps68AAAAeAZ6makf/AAAkscv8e1XWdhjdR9z/d3MyFZRMYjghAAAAY0Gaq0moQWyZTAhn//6eEAAAR05WgfB+4sAX4lZhxtf1Xb43tstHmDvlyc6wR8D/L2fqzqQmTOJpHxqjJiUN4WX/NlRXr4I7Pgun4KmeTSxDYQ1UjT5JS+5DT6wRgXnSFV0msAAAAC5BnslFFSwj/wAAF0xG398fP4w/M9KzcDjyABOMSwkr3SobTSL3Mv5v9GBOavqQAAAANwGe6HRH/wAAI8NCabpEqBGAAXE+npCblQrmIF7coYErJz9lkjEEkdLr87OUUJpXtx06t/M33uEAAAAbAZ7qakf/AAAkvwQrwys7m/OVvXu4AzR00NqQAAAAWEGa70moQWyZTAhn//6eEAAAR0UE9zTEAlbgVKqA1bnaSsO87wxT0hGMJQsDXKIyjKrEiAehlMbRINckF65MEfzMs2PdS8kFkfVwFm1GM1rXL05VIc4oxOQAAAAnQZ8NRRUsI/8AABdQVoIIy9/f1ClVOYW/rNDGa+NUjFnjkaIrMS15AAAAIAGfLHRH/wAAJLiv3MUezLAy1/NM5PnHGuA/Pxq9LtSBAAAAHgGfLmpH/wAAJL74p/VUJtk6O5StErcIOV3Z2Iwe4QAAAEJBmzNJqEFsmUwIZ//+nhAAAEdUqT7j/IFvpnbnLe+u/g3GwAAC3sB9p/uAvOLch9vCJ0vnCZfLAjYOA1Fl1DKMh2AAAAAgQZ9RRRUsI/8AABdFKzdrWl644ZiH/80z+JSizKX4HuAAAAAhAZ9wdEf/AAAkusgjqDgAlim33twBHPo/o6n+Ku4MgEPBAAAAJQGfcmpH/wAAAwBHfghMUAwAWjPnZq9Ro+2obdUTMVZnoQ0W2pAAAABMQZt3SahBbJlMCF///oywAABIAvCln0Acw1UWKS3Wp+gLDAYB96FNZJBbCqk8c9ux/rCRIMcTpzLMRMXzibI2dPtsGZlAuLKCKQp7lQAAABxBn5VFFSwj/wAAF0UrN2taXriig86oqQDBjzR9AAAAGwGftHRH/wAAJMCZ3ehGDX19dKHDCMOjvLbQgAAAABcBn7ZqR/8AACTHK9VsWEt1pwu1apecIQAAAFVBm7pJqEFsmUwIZ//+nhAAAEdo8UWP6BLQMJR0Q7x3gkjounfSxq7keFKKyZSnPQZADWnPVAsDqOA4SwrA+8pPZBNhH7d+sJRwxzyQu23YQ++WezZ/AAAAIEGf2EUVLCP/AAAXRSs3a1peuKKDwjCwOh9RmYai+rKAAAAAJQGf+WpH/wAAAwAKiP2alQcAEHgz3K9x1NWXXcu4STvGq1DpHXkAAABWQZv+SahBbJlMCGf//p4QAABHloJJZQAQ6nL4eU482lRiA9qPo+ckjRZUlJm12JEnrkoFdvYP1hJXT6AInqsok9nI9OjhLDBBSBeal0uwdEsxlAcQiDMAAAA3QZ4cRRUsI/8AABc0+y5FCs1wAH86lY3WnbxpolyPN/BbT1AgoAbLruz4375LSkeoLsUI4bL9wQAAACkBnjt0R/8AACS3/vQ0mNiqqyTcTSk0EAIXm/kr9cPBrJcGbuUeY6Bu4QAAABUBnj1qR/8AACSxzAlwV6qQjXGVOmAAAABSQZoiSahBbJlMCF///oywAABIFFtXMIHx7WrAJzBoh8mPbnZu8GxDOalwOm2tHiP1eaE5aLyyXvVoTfzgaox7j6nMlGX8+nfD4qTnhcZhVtLMSgAAACZBnkBFFSwj/wAAF0uKflpwVeHlufXb8tcinEgybuyFzPgx+e5T5wAAACQBnn90R/8AACS3/uERPXJCVL0Pf4zkooERuQVmJod+DmzuRYAAAAATAZ5hakf/AAAksjCjTT4UEMLIPQAAAEtBmmZJqEFsmUwIX//+jLAAAEhc0TN36xZoxRAB28pQHkZmqg9mCRD7177O90tFbajHjvPgskbp9mgrfonYM3PfHpBr0gPC9NXdKYAAAAAyQZ6ERRUsI/8AABdQn3HKOLBABOLxsx/5fiJkV5SkhBfwo2rTFp1SAtCeZBIav8XdZUEAAAAeAZ6jdEf/AAAkrD5uO8dkez59N5vPolIwEGKf1c+ZAAAAEwGepWpH/wAAJLIrBxTBHenH53sAAABQQZqoSahBbJlMFEwz//6eEAAAR0iXIAiQ3d15S+EzieusNTn/h8Z6Xg5hK3t20SLrmbHXYclAZLB2u8t22Vl5z2QGHPEAxa7CvVDWFOiGrs0AAAAcAZ7Hakf/AAAkvxxVmPVxuYwZIvqiLZMNL1h0iwAAAElBmsxJ4QpSZTAhn/6eEAAAR2VRFUsjcAIwN4JHCq+Rxm9p07ipnoL0RupdgeeMuA3DBzWOAUveu7kd2PsiZb0JWpPYyHyFYefAAAAAGUGe6kU0TCP/AAAXUFaRfy2e9zvjpHkqH3UAAAAXAZ8JdEf/AAAkuME7Pbdx6vjuMHqD7oAAAAAQAZ8Lakf/AAAksjCjI9Xh/gAAAE5BmxBJqEFomUwIZ//+nhAAAEdUqU51hKYMr0mmuQ8mABbmXDnREpVL0Y9HX1oZmsIEDYSurX5KCmyTB3rPmsiBSxtBHG7MsRnJr92fnEEAAAAnQZ8uRREsI/8AABdLitCEuXI5zuF+687mif31/SxDTjeFBFpxCGpBAAAAJwGfTXRH/wAAJKw5Ba5PIWeABLH5q0pxtZWp+5Kbiy4z/CZH+vfugQAAAC4Bn09qR/8AACSTMKfWSDjvT2BJUXzud7FGK56AD3rphHGNyt/YBFs6bKDzIjUgAAAANEGbVEmoQWyZTAhn//6eEAAAR0UNNYAHG1VDmTtUaAjtF2IHSV23JPVbi/bg4lhqSyEHQ/wAAAAZQZ9yRRUsI/8AABdFWFWKzvIjFyl7EV8lYQAAACIBn5F0R/8AACSp6vlj0AFz+7fWKrigddjOQruAof+chEm9AAAAEgGfk2pH/wAAAwDESeR5CvBgQAAAAF1Bm5hJqEFsmUwIZ//+nhAAAEdlURVLg2wARkbWq+47z705yHHXjss2MJLi341TQNVwXG70e45y6rChz9yGU7l3vKevRKGQjG7aU66RL2Jwji5CpH51dSMK7vv0yOEAAAAfQZ+2RRUsI/8AABdLitCEuXGcGmAh+PFYmd+wFLrhtwAAAB0Bn9V0R/8AACS3/0LZKLZAmkxcIs5TlSv5C5WQYQAAABIBn9dqR/8AACSyMKiv3Y3FjbMAAABcQZvcSahBbJlMCGf//p4QAABJum88TwaoUOBDUIcry+TMkAyLv3k7UgCrGl8XNLT37JXBL38rtYfIWzv8BA2lMwOfc00qUubSyl5Fk+pXxTMI4bFlFQCBZ/YsBXgAAAAgQZ/6RRUsI/8AABdLitCEuXFwMmhDCetht08u91nVFJkAAAAUAZ4ZdEf/AAAkrDsPHv95mmKAZNwAAAAeAZ4bakf/AAAksjE6vThRjUAO4WHWw0UjlGJ1KxHbAAAAKkGaAEmoQWyZTAhn//6eEAAASUUE9xxhv9oLk/SGCS2asuX0u1ACWnE5nwAAACVBnj5FFSwj/wAAF+lVzijhv0ZIa84Ah7ng2b4YFq71ZnUPZERMAAAAPAGeXXRH/wAAJMNAshwjWw3XZEcd8PGQxu26MAi7iAK3n5vsDjAQfLZT0OOeNnxKF0gZmhWdoEQLBks2fAAAABQBnl9qR/8AACWxzAlvqW+zUIDAgQAAAHBBmkRJqEFsmUwIZ//+nhAAAElRDZBXckxYAcYwYtnDgMpOEwzhdux+4rhZP8MM4Mv1jvhlDDjdq9h54GoszyMgtu5Lxjjnp2OikUB/fPPDMkem6FgZ7f30KZOXedn92ZzFK4Q8AEYzubXfXlvyEHgsAAAAH0GeYkUVLCP/AAAX6YPNtxXMrJlJPgdCisuHnv/Ucg0AAAAnAZ6BdEf/AAAlyGrK9rP6ABxr32WOOYDkXR1tJHwD2IPIHxMg5LriAAAAQAGeg2pH/wAAJbHeuosAHFg2lgksNrvTtCMgz/udJ7H5T2BRgu5GryKNEXiiK3jX1SNwKh28ERE46mLbca92LTkAAABKQZqISahBbJlMCGf//p4QAABJRQWgx1XYAHFoqvrN/K2JBBZQgq4iQaZldEmbEKtnhjs9dvJ3gxTUCpUe/LFYbKL4V5mimS/10EEAAAAoQZ6mRRUsI/8AABfrHd5S1YAHxt3uYp3MpZl1QMW+Vylc3kN4OsndYQAAACYBnsV0R/8AACWr+GeQockPAsCSvphABCmlzwHFOu0h5n4OhZZacQAAACoBnsdqR/8AACW/BCcSyWmauK2bAAbZWoALENGCy3lNwoqOTUD9Xmy024AAAABQQZrMSahBbJlMCGf//p4QAABJUT6grhJYBaTcP1tHRH/9AotJ/AtgLtsXrH2He5F5Rsujmt3qvBsog7/SsZ9MlKtWbw4/LwY2mhOdun1sJrAAAAAiQZ7qRRUsI/8AABfpg8+aWc3IahkhfifQx6CKtNMkmqpVmQAAACgBnwl0R/8AAAMASIueQAtF9M53rK6naywC76KiZI3MfOd0YJ2p8dOAAAAALgGfC2pH/wAAJbHMK/nAZLUNU2YGgLGGqP8UiABdRfBir98r7OIGVVXY9PDOnTgAAABuQZsQSahBbJlMCGf//p4QAABJRQg0AKr5S58mpE1+4AL0CO1cCeOTnNTs5ZFSSVN1WakTKULHsM1bfPBnbntk10dvzJ8f6pp7XnkcoMFmVvlnq44fl73V7/mleug81TGvdU8xgfMCxjlttF6dQHMAAAApQZ8uRRUsI/8AABfibc1QByhxdl9KbqzT80kA6OiDGZYl+1u+DAnM+9MAAAAXAZ9NdEf/AAAlq/hbgdyr2I5YJrh75IEAAAAfAZ9Pakf/AAAkvxwJkGqrtYvEH5GeKOh5BmEcoFRnwAAAADpBm1RJqEFsmUwIZ//+nhAAAElRRyLIABx7qMQJ6RaZX13NDpFzaK6F4J/GGa5tqBP88MZOOlxAziuIAAAAHUGfckUVLCP/AAAX5nOf8SrxltwYuZYrJc1R4Bo3AAAAJwGfkXRH/wAAJcMXaKmlU71SggAXQAwcNjKg07weU9d++yxHo2d44AAAABYBn5NqR/8AACWx3k9mhyVUnlg2xODaAAAAZkGbmEmoQWyZTAhn//6eEAAASVS/JAAFWBKiI30YZ1fXGvcL7jRUpFYmYjchGcgPG+EvHHzEAY+ucykZHVn9iuLUkIovtEY6Uqbco1/tWF9vX4T6eRaJyyCo1ZYKzHCKtmj7SIL8wQAAACVBn7ZFFSwj/wAAF+mBWmLzSiX6IM5nRPmeMiRHFPL89N2Wyql3AAAAEgGf1XRH/wAAJKw8UZGd3hz+bQAAACUBn9dqR/8AACWxzBBES0pX7PbdyV+baoYVKDEO36XNJm1v9bJBAAAAUkGb3EmoQWyZTAhn//6eEAAASVEJTwU2Rc4wcFwASkNNGbOrHu1Ql2HtBzRzA9NaFiaDB9QQPlE2Is/LJG0i/grnlRPOlz+aQ2U9Pwx49H4aKqgAAAAwQZ/6RRUsI/8AABfgh7cNwTQPSdNeC5PWM4efoxRVWemu9zGMLQZK3UemlOHHgoOfAAAALgGeGXRH/wAAJcDbLfCs/FO0oXSO6CFfYACdSoX3QhveziUP3D77vC+iyxrG8kAAAAAdAZ4bakf/AAAk2FzAESCSMtCokZGmzEmTNuaRbssAAABIQZoASahBbJlMCGf//p4QAAAKj+EUAKS2yy6lMMt+n9nFphOvHe/g5CSmSXswAQZk5/xqIWdtgNKK36BEUYedrr8ryedundOBAAAAPEGePkUVLCP/AAAX66vjplHz39H3rJshFDszLGP7YLaqEyc0TGaUDACaYRpoGlQrIOTrtJXmYj97Ap3XJAAAADQBnl10R/8AACWqQwxCcqoALH+4BxEsqEXZ2qk8Ty3mnbyGVMUpoo7ZLJf7WsOyjfbu5vSAAAAAHQGeX2pH/wAAJb8ELFjpmX2jQm7VY1kI/yMSRPoJAAAAbkGaREmoQWyZTAhn//6eEAAASXCIIjgE0WHM1SRe4tzts1zui+rTaItJBxssxlh82S+J3b1Qqkj+JbzK+DpJt6VlVbaKdDRtBuK6TMN73hRWhggOwDk6tr88opN0LVMb3Lw3iLMYde8YySxprmz4AAAAMEGeYkUVLCP/AAAX6MxqQA48BQYQ5VGXp9OdQ+H+dXbdgGXEiJ1ZYABgfMzUA9p0wQAAAB0BnoF0R/8AACWr+Ft4F8aieNZawuzM7xWALTXqgAAAAB8BnoNqR/8AACWxzCv5FtsqtBt8wrRO3gewMvPzzaphAAAAN0GaiEmoQWyZTAhf//6MsAAASimUUzv185HOfDH0aoXDkIacU+yLbMT3iSMagEH2lto2jFGjx3kAAAA3QZ6mRRUsI/8AABfpjmvC/7dWsUwfKOAUHF7WnIMeLPdAdOhNg3vMhFvo63lpGENFuDoC6MA2YQAAABwBnsV0R/8AAAMAG6u6a0kIoP1c2iYI0bY4uKMXAAAAHwGex2pH/wAAJb8azB/xNx1MOD9TTPBIBDDHCkCEkQ8AAABqQZrMSahBbJlMCF///oywAABKEPPQFtWFnQ9r1uNxg8EXNYA5htLYZTsDyGz7CBpfZSBQ/7Ccxy9RpFwMN/G/KWeDyFQogl/HRv8u4IEmavU1lYppT8jGvGN/DLj4+Po3DQNKKTHd67OFwAAAACFBnupFFSwj/wAAF+JrN2uJWgO6+Uynqm40l9P8xJPZSsEAAAAVAZ8JdEf/AAAlq/hbeCLRWCSV3rhAAAAAGwGfC2pH/wAAAwAKzmEgmtcq0S5G2kbO/SO/wAAAAFdBmw5JqEFsmUwUTDP//p4QAABJRQXmutewMdAB88ye8eIXTVpQ8cVxTwSiZDkw9Ul8h7418XSOdf5hVJoQW2iVH4EpqnaS8nsESNJUpdJEtsXtJ2gvs+EAAAA4AZ8takf/AAAlN+GHakAHE3twnNkl7LteL59S3Zph6o1pGFvwkf4/iL8T2Hmo+dE2l5wY5vlQCXkAAABQQZsySeEKUmUwIZ/+nhAAAElIlyAOUbwWjTApfoXYuW2/FOPHr4pXajBcJDAuBc1+XZRLdTBtCrJ65pA/JHZjvRM1GxU7ZLs4PJ/r5e2T2CEAAAAhQZ9QRTRMI/8AABfpjvgpNe4/HpNnSJeshlVaqBNi5uLAAAAAKgGfb3RH/wAAJZSiutxMANbaA22mVLy4HOMSTPuZOk8wI/sEoQow7oC2gAAAACgBn3FqR/8AACW/HAhQpUQj4AF1AEgGcLyfeNeoVneaeMbr3KxMvb9JAAAAJ0GbdkmoQWiZTAhn//6eEAAASVE+9IW3xE8bfIkOLO965TlHdvxzQAAAABdBn5RFESwj/wAAF+KYVYrOhO45nDFlwAAAAB0Bn7N0R/8AACXDPg54d+YigAunN7+9njhYuSAVMQAAACUBn7VqR/8AACWaWprTgAWAAyrTucsJFKMiLIqYjF8mS59kJTNCAAAASUGbukmoQWyZTAhf//6MsAAAAwGAu6dEHrCN4AV2Hh5nG9LOTqAgKQuejiFDr3uFIK6n4BA3qJXEzC0e+kWxkW61kejuS1F8zn8AAAAhQZ/YRRUsI/8AABfrtbVIEyxj17mC/gfN5zmkgb39H1nxAAAAJgGf93RH/wAAJcNAEK85fvFyNjaAC6ZcpA2RjdoVGo5DHn9ybnsWAAAAFQGf+WpH/wAAJb8cCEUJgfoWtm+WpQAAAEBBm/5JqEFsmUwIX//+jLAAAEoC0PmdOYAlsSDLJfxo4eejbxDM2hcbKzLxTfCTA4deYlWl90l8TVcz1xtEoYPWAAAAGkGeHEUVLCP/AAAX4phVis5AIA6XMIyrGw/JAAAAMAGeO3RH/wAAJZjmprjAAGpOnkop/LcLK6XaQ8SXlNr7RVrO4yLfYRVxiPrhN5Qk4QAAAB4Bnj1qR/8AACWaWs3bULPC4PV3B4AHuPEn9xWxPmAAAABBQZoiSahBbJlMCF///oywAABKJdEpgq9wBEhoOyoMV8m09YmTt99h/pju7HEXPQq1ctlwTnEqlVZH0ZEsL+xboYAAAAAzQZ5ARRUsI/8AABfHHEiTnF9vsSLATe/oWADUgW+ymQr3U6f7bDW4iSdktcw2JzjeUYIFAAAAJQGef3RH/wAAJZMx78508BPYaehGJJS+wATJeJP7izkl7k7yXnwAAAAcAZ5hakf/AAAlx8bYvqpCHdO5tWB6BH80/9v7aQAAADZBmmZJqEFsmUwIT//98QAAAwLD7vn00idiwLNhVqznXQtA5VCBeD0RLlZfDr3Z9bjAbVQvB4AAAAAqQZ6ERRUsI/8AABfpjx67flI0XgAEyPJFGupPN//AKI/OvnjILT/pBAtpAAAAIwGeo3RH/wAAAwH3OF8kahnoAW8D28eQx0MQLAhzSiLjaUKDAAAAGwGepWpH/wAAJbIw21PNrDluQiwUlkmvUH1s+QAAABtBmqhJqEFsmUwUTH/8hAAAENHVLdgfAJrlVbUAAAARAZ7Hakf/AAAlvxvY9bL8PmAAAAxvbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAD7QAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC5l0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAD7QAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAlgAAAGQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAA+0AAACAAABAAAAAAsRbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAAAyQBVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKvG1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACnxzdGJsAAAAmHN0c2QAAAAAAAAAAQAAAIhhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAlgBkABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMmF2Y0MBZAAf/+EAGWdkAB+s2UCYM+XhAAADAAEAAAMAZA8YMZYBAAZo6+PLIsAAAAAYc3R0cwAAAAAAAAABAAAAyQAAAQAAAAAUc3RzcwAAAAAAAAABAAAAAQAABkhjdHRzAAAAAAAAAMcAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAyQAAAAEAAAM4c3RzegAAAAAAAAAAAAAAyQAABDMAAACRAAAAKwAAACoAAAAbAAAAZAAAACQAAAAuAAAAHAAAAHoAAAAkAAAAHQAAACIAAAB7AAAALwAAACkAAAAiAAAAYAAAADgAAAA0AAAAIAAAAD8AAAApAAAAGAAAABsAAABiAAAAKwAAAB8AAAAuAAAAaAAAADQAAAAlAAAAIAAAADUAAAAXAAAALwAAACEAAAA7AAAAMAAAACUAAAAnAAAAQgAAAB4AAAAgAAAAJAAAAFcAAABBAAAAHgAAABoAAABpAAAAMAAAACYAAAAfAAAAQwAAACQAAABBAAAARAAAACcAAAAwAAAAKgAAAFoAAAAqAAAAHQAAACoAAABYAAAAPwAAADAAAAAhAAAATAAAACsAAAA2AAAAIgAAAGcAAAAyAAAAOwAAAB8AAABcAAAAKwAAACQAAAAiAAAARgAAACQAAAAlAAAAKQAAAFAAAAAgAAAAHwAAABsAAABZAAAAJAAAACkAAABaAAAAOwAAAC0AAAAZAAAAVgAAACoAAAAoAAAAFwAAAE8AAAA2AAAAIgAAABcAAABUAAAAIAAAAE0AAAAdAAAAGwAAABQAAABSAAAAKwAAACsAAAAyAAAAOAAAAB0AAAAmAAAAFgAAAGEAAAAjAAAAIQAAABYAAABgAAAAJAAAABgAAAAiAAAALgAAACkAAABAAAAAGAAAAHQAAAAjAAAAKwAAAEQAAABOAAAALAAAACoAAAAuAAAAVAAAACYAAAAsAAAAMgAAAHIAAAAtAAAAGwAAACMAAAA+AAAAIQAAACsAAAAaAAAAagAAACkAAAAWAAAAKQAAAFYAAAA0AAAAMgAAACEAAABMAAAAQAAAADgAAAAhAAAAcgAAADQAAAAhAAAAIwAAADsAAAA7AAAAIAAAACMAAABuAAAAJQAAABkAAAAfAAAAWwAAADwAAABUAAAAJQAAAC4AAAAsAAAAKwAAABsAAAAhAAAAKQAAAE0AAAAlAAAAKgAAABkAAABEAAAAHgAAADQAAAAiAAAARQAAADcAAAApAAAAIAAAADoAAAAuAAAAJwAAAB8AAAAfAAAAFQAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This Section is only for resources**"
      ],
      "metadata": {
        "id": "7jYQszBvXXwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game = 'CartPole-v1'\n",
        "# other interesting and simple environments: Pong-v0, MsPacman-v0, CarRacing-v0\n",
        "\n",
        "nr_of_runs = 10\n",
        "current_run = 1\n",
        "\n",
        "if current_run == nr_of_runs:\n",
        "  env = wrap_env(gym.make(game))\n",
        "else:\n",
        "  env = gym.make(game)\n",
        "observation = env.reset()\n",
        "timestep = 0\n",
        "\n",
        "while current_run < nr_of_runs+1:\n",
        "    # render the current frame to the video recorder of Google Colab\n",
        "    if current_run == nr_of_runs:\n",
        "      env.render()\n",
        "    \n",
        "    # your agent goes here \n",
        "    # action_space.sample() results in a random action being picked\n",
        "    action = env.action_space.sample()\n",
        "    \n",
        "    # apply the action to the real environment and forward the game\n",
        "    observation, reward, done, info = env.step(action) \n",
        "    timestep += 1\n",
        "    \n",
        "    if done:\n",
        "      # for Monte Carlo Method you will need to update your value matrix here\n",
        "      # Temporal Difference Learning updates the value matrix in every step\n",
        "      \n",
        "      # this test ends after 'nr_of_runs' (default = 10)\n",
        "      # change the variable at the top if you want to train longer (recommended) \n",
        "      print(\"run: \"+ str(current_run) + \" took \" + str(timestep) + \" timesteps\")\n",
        "      current_run += 1\n",
        "      timestep = 0\n",
        "      if current_run == nr_of_runs:\n",
        "        # record the last run\n",
        "        env.close()\n",
        "        env = wrap_env(gym.make(game))\n",
        "      else:\n",
        "        env.close()\n",
        "        env = gym.make(game)\n",
        "      \n",
        "      observation = env.reset()\n",
        "      show_video()  #only shows the last run\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "L8TgVzWCOWVH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}